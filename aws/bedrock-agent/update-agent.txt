UPDATE-AGENT()                                                  UPDATE-AGENT()



NAME
       update-agent -

DESCRIPTION
       Updates the configuration of an agent.

       See also: AWS API Documentation

SYNOPSIS
            update-agent
          --agent-id <value>
          --agent-name <value>
          --agent-resource-role-arn <value>
          [--custom-orchestration <value>]
          [--customer-encryption-key-arn <value>]
          [--description <value>]
          --foundation-model <value>
          [--guardrail-configuration <value>]
          [--idle-session-ttl-in-seconds <value>]
          [--instruction <value>]
          [--memory-configuration <value>]
          [--orchestration-type <value>]
          [--prompt-override-configuration <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --agent-id (string)
          The unique identifier of the agent.

       --agent-name (string)
          Specifies a new name for the agent.

       --agent-resource-role-arn (string)
          The  Amazon  Resource Name (ARN) of the IAM role with permissions to
          invoke API operations on the agent.

       --custom-orchestration (structure)
          Contains details of the  custom  orchestration  configured  for  the
          agent.

          executor -> (tagged union structure)
              The structure of the executor invoking the actions in custom or-
              chestration.

              NOTE:
                 This is a Tagged Union structure. Only one of  the  following
                 top level keys can be set: lambda.

              lambda -> (string)
                 The  Amazon  Resource  Name (ARN) of the Lambda function con-
                 taining the business logic that is carried out upon  invoking
                 the action.

       Shorthand Syntax:

          executor={lambda=string}

       JSON Syntax:

          {
            "executor": {
              "lambda": "string"
            }
          }

       --customer-encryption-key-arn (string)
          The  Amazon Resource Name (ARN) of the KMS key with which to encrypt
          the agent.

       --description (string)
          Specifies a new description of the agent.

       --foundation-model (string)
          The identifier for the model that you want to be used for orchestra-
          tion by the agent you create.

          The  modelId  to  provide depends on the type of model or throughput
          that you use:

          o If you use a base model, specify the model ID or its  ARN.  For  a
            list  of  model IDs for base models, see Amazon Bedrock base model
            IDs (on-demand throughput) in the Amazon Bedrock User Guide.

          o If you use an inference profile, specify the inference profile  ID
            or its ARN. For a list of inference profile IDs, see Supported Re-
            gions and models for cross-region inference in the Amazon  Bedrock
            User Guide.

          o If you use a provisioned model, specify the ARN of the Provisioned
            Throughput. For more information, see Run inference using a Provi-
            sioned Throughput in the Amazon Bedrock User Guide.

          o If  you  use a custom model, first purchase Provisioned Throughput
            for it. Then specify the ARN of the resulting  provisioned  model.
            For  more information, see Use a custom model in Amazon Bedrock in
            the Amazon Bedrock User Guide.

          o If you use an imported model , specify the  ARN  of  the  imported
            model.  You  can  get  the  model  ARN  from  a successful call to
            CreateModelImportJob or from the Imported models page in the  Ama-
            zon Bedrock console.

       --guardrail-configuration (structure)
          The  unique Guardrail configuration assigned to the agent when it is
          updated.

          guardrailIdentifier -> (string)
              The unique identifier of the guardrail.

          guardrailVersion -> (string)
              The version of the guardrail.

       Shorthand Syntax:

          guardrailIdentifier=string,guardrailVersion=string

       JSON Syntax:

          {
            "guardrailIdentifier": "string",
            "guardrailVersion": "string"
          }

       --idle-session-ttl-in-seconds (integer)
          The number of seconds for which  Amazon  Bedrock  keeps  information
          about a user's conversation with the agent.

          A  user interaction remains active for the amount of time specified.
          If no conversation occurs during this time, the session expires  and
          Amazon Bedrock deletes any data provided before the timeout.

       --instruction (string)
          Specifies new instructions that tell the agent what it should do and
          how it should interact with users.

       --memory-configuration (structure)
          Specifies the new memory configuration for the agent.

          enabledMemoryTypes -> (list)
              The type of memory that is stored.

              (string)

          storageDays -> (integer)
              The number of days the agent is configured to retain the conver-
              sational context.

       Shorthand Syntax:

          enabledMemoryTypes=string,string,storageDays=integer

       JSON Syntax:

          {
            "enabledMemoryTypes": ["SESSION_SUMMARY", ...],
            "storageDays": integer
          }

       --orchestration-type (string)
          Specifies  the type of orchestration strategy for the agent. This is
          set to DEFAULT orchestration type, by default.

          Possible values:

          o DEFAULT

          o CUSTOM_ORCHESTRATION

       --prompt-override-configuration (structure)
          Contains configurations to override prompts in different parts of an
          agent sequence. For more information, see Advanced prompts .

          overrideLambda -> (string)
              The ARN of the Lambda function to use when parsing the raw foun-
              dation model output in parts of the agent sequence. If you spec-
              ify  this  field,  at least one of the promptConfigurations must
              contain a parserMode value that is set to OVERRIDDEN . For  more
              information, see Parser Lambda function in Amazon Bedrock Agents
              .

          promptConfigurations -> (list)
              Contains configurations to override a  prompt  template  in  one
              part  of  an  agent sequence. For more information, see Advanced
              prompts .

              (structure)
                 Contains configurations to override a prompt template in  one
                 part of an agent sequence. For more information, see Advanced
                 prompts .

                 basePromptTemplate -> (string)
                     Defines the prompt template with which to replace the de-
                     fault  prompt template. You can use placeholder variables
                     in the base prompt template to customize the prompt.  For
                     more  information,  see Prompt template placeholder vari-
                     ables . For more information, see  Configure  the  prompt
                     templates .

                 inferenceConfiguration -> (structure)
                     Contains  inference  parameters to use when the agent in-
                     vokes a foundation model in the part  of  the  agent  se-
                     quence  defined by the promptType . For more information,
                     see Inference parameters for foundation models .

                     maximumLength -> (integer)
                        The maximum number of tokens to allow in the generated
                        response.

                     stopSequences -> (list)
                        A  list  of  stop  sequences. A stop sequence is a se-
                        quence of characters that causes  the  model  to  stop
                        generating the response.

                        (string)

                     temperature -> (float)
                        The likelihood of the model selecting higher-probabil-
                        ity options while generating a response. A lower value
                        makes the model more likely to choose higher-probabil-
                        ity options, while a higher value makes the model more
                        likely to choose lower-probability options.

                     topK -> (integer)
                        While  generating a response, the model determines the
                        probability of the following token at  each  point  of
                        generation.  The  value  that  you set for topK is the
                        number of most-likely candidates from which the  model
                        chooses  the  next token in the sequence. For example,
                        if you set topK to 50, the model selects the next  to-
                        ken from among the top 50 most likely choices.

                     topP -> (float)
                        While  generating a response, the model determines the
                        probability of the following token at  each  point  of
                        generation.  The  value  that you set for Top P deter-
                        mines the number of most-likely candidates from  which
                        the  model chooses the next token in the sequence. For
                        example, if you set topP to 80, the model only selects
                        the  next  token  from  the top 80% of the probability
                        distribution of next tokens.

                 parserMode -> (string)
                     Specifies whether to override the default  parser  Lambda
                     function  when parsing the raw foundation model output in
                     the part of the agent sequence defined by the  promptType
                     .  If you set the field as OVERRIDEN , the overrideLambda
                     field in the PromptOverrideConfiguration must  be  speci-
                     fied with the ARN of a Lambda function.

                 promptCreationMode -> (string)
                     Specifies whether to override the default prompt template
                     for this promptType . Set this value to OVERRIDDEN to use
                     the  prompt  that you provide in the basePromptTemplate .
                     If you leave it as DEFAULT , the  agent  uses  a  default
                     prompt template.

                 promptState -> (string)
                     Specifies  whether  to  allow  the agent to carry out the
                     step specified in the promptType . If you set this  value
                     to  DISABLED  ,  the  agent  skips that step. The default
                     state for each promptType is as follows.

                     o PRE_PROCESSING  ENABLED

                     o ORCHESTRATION  ENABLED

                     o KNOWLEDGE_BASE_RESPONSE_GENERATION  ENABLED

                     o POST_PROCESSING  DISABLED

                 promptType -> (string)
                     The step in the agent sequence that this prompt  configu-
                     ration applies to.

       JSON Syntax:

          {
            "overrideLambda": "string",
            "promptConfigurations": [
              {
                "basePromptTemplate": "string",
                "inferenceConfiguration": {
                  "maximumLength": integer,
                  "stopSequences": ["string", ...],
                  "temperature": float,
                  "topK": integer,
                  "topP": float
                },
                "parserMode": "DEFAULT"|"OVERRIDDEN",
                "promptCreationMode": "DEFAULT"|"OVERRIDDEN",
                "promptState": "ENABLED"|"DISABLED",
                "promptType": "PRE_PROCESSING"|"ORCHESTRATION"|"POST_PROCESSING"|"KNOWLEDGE_BASE_RESPONSE_GENERATION"
              }
              ...
            ]
          }

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination. If automatic pagination is disabled,  the
       AWS CLI will only make one call, for the first page of results.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

OUTPUT
       agent -> (structure)
          Contains details about the agent that was updated.

          agentArn -> (string)
              The Amazon Resource Name (ARN) of the agent.

          agentId -> (string)
              The unique identifier of the agent.

          agentName -> (string)
              The name of the agent.

          agentResourceRoleArn -> (string)
              The  Amazon Resource Name (ARN) of the IAM role with permissions
              to invoke API operations on the agent.

          agentStatus -> (string)
              The status of the agent and whether it is  ready  for  use.  The
              following statuses are possible:

              o CREATING  The agent is being created.

              o PREPARING  The agent is being prepared.

              o PREPARED  The agent is prepared and ready to be invoked.

              o NOT_PREPARED  The agent has been created but not yet prepared.

              o FAILED  The agent API operation failed.

              o UPDATING  The agent is being updated.

              o DELETING  The agent is being deleted.

          agentVersion -> (string)
              The version of the agent.

          clientToken -> (string)
              A  unique,  case-sensitive identifier to ensure that the API re-
              quest completes no more than one time. If this token  matches  a
              previous  request,  Amazon Bedrock ignores the request, but does
              not return an error. For more information, see Ensuring  idempo-
              tency .

          createdAt -> (timestamp)
              The time at which the agent was created.

          customOrchestration -> (structure)
              Contains custom orchestration configurations for the agent.

              executor -> (tagged union structure)
                 The  structure of the executor invoking the actions in custom
                 orchestration.

                 NOTE:
                     This is a Tagged Union structure. Only one of the follow-
                     ing top level keys can be set: lambda.

                 lambda -> (string)
                     The  Amazon  Resource  Name  (ARN) of the Lambda function
                     containing the business logic that is  carried  out  upon
                     invoking the action.

          customerEncryptionKeyArn -> (string)
              The  Amazon Resource Name (ARN) of the KMS key that encrypts the
              agent.

          description -> (string)
              The description of the agent.

          failureReasons -> (list)
              Contains reasons that the agent-related  API  that  you  invoked
              failed.

              (string)

          foundationModel -> (string)
              The foundation model used for orchestration by the agent.

          guardrailConfiguration -> (structure)
              Details about the guardrail associated with the agent.

              guardrailIdentifier -> (string)
                 The unique identifier of the guardrail.

              guardrailVersion -> (string)
                 The version of the guardrail.

          idleSessionTTLInSeconds -> (integer)
              The number of seconds for which Amazon Bedrock keeps information
              about a user's conversation with the agent.

              A user interaction remains active for the amount of time  speci-
              fied.  If  no  conversation occurs during this time, the session
              expires and Amazon Bedrock deletes any data provided before  the
              timeout.

          instruction -> (string)
              Instructions  that  tell  the agent what it should do and how it
              should interact with users.

          memoryConfiguration -> (structure)
              Contains memory configuration for the agent.

              enabledMemoryTypes -> (list)
                 The type of memory that is stored.

                 (string)

              storageDays -> (integer)
                 The number of days the agent is configured to retain the con-
                 versational context.

          orchestrationType -> (string)
              Specifies the orchestration strategy for the agent.

          preparedAt -> (timestamp)
              The time at which the agent was last prepared.

          promptOverrideConfiguration -> (structure)
              Contains  configurations to override prompt templates in differ-
              ent parts of  an  agent  sequence.  For  more  information,  see
              Advanced prompts .

              overrideLambda -> (string)
                 The  ARN  of  the Lambda function to use when parsing the raw
                 foundation model output in parts of the  agent  sequence.  If
                 you  specify this field, at least one of the promptConfigura-
                 tions must contain a parserMode value that is set to OVERRID-
                 DEN  .  For  more  information, see Parser Lambda function in
                 Amazon Bedrock Agents .

              promptConfigurations -> (list)
                 Contains configurations to override a prompt template in  one
                 part of an agent sequence. For more information, see Advanced
                 prompts .

                 (structure)
                     Contains configurations to override a prompt template  in
                     one  part of an agent sequence. For more information, see
                     Advanced prompts .

                     basePromptTemplate -> (string)
                        Defines the prompt template with which to replace  the
                        default prompt template. You can use placeholder vari-
                        ables in the base prompt  template  to  customize  the
                        prompt.  For  more  information,  see  Prompt template
                        placeholder variables  .  For  more  information,  see
                        Configure the prompt templates .

                     inferenceConfiguration -> (structure)
                        Contains  inference  parameters  to use when the agent
                        invokes a foundation model in the part  of  the  agent
                        sequence defined by the promptType . For more informa-
                        tion, see Inference parameters for foundation models .

                        maximumLength -> (integer)
                            The maximum number of tokens to allow in the  gen-
                            erated response.

                        stopSequences -> (list)
                            A list of stop sequences. A stop sequence is a se-
                            quence of characters that causes the model to stop
                            generating the response.

                            (string)

                        temperature -> (float)
                            The likelihood of the model selecting higher-prob-
                            ability options while  generating  a  response.  A
                            lower  value makes the model more likely to choose
                            higher-probability options, while a  higher  value
                            makes the model more likely to choose lower-proba-
                            bility options.

                        topK -> (integer)
                            While generating a response, the model  determines
                            the  probability  of  the  following token at each
                            point of generation. The value that  you  set  for
                            topK  is the number of most-likely candidates from
                            which the model chooses the next token in the  se-
                            quence.  For  example,  if you set topK to 50, the
                            model selects the next token from among the top 50
                            most likely choices.

                        topP -> (float)
                            While  generating a response, the model determines
                            the probability of the  following  token  at  each
                            point  of  generation.  The value that you set for
                            Top P determines the number of most-likely  candi-
                            dates  from which the model chooses the next token
                            in the sequence. For example, if you set  topP  to
                            80, the model only selects the next token from the
                            top 80% of the probability  distribution  of  next
                            tokens.

                     parserMode -> (string)
                        Specifies  whether  to  override  the  default  parser
                        Lambda function when parsing the raw foundation  model
                        output  in  the  part of the agent sequence defined by
                        the promptType . If you set the field as  OVERRIDEN  ,
                        the       overrideLambda       field       in      the
                        PromptOverrideConfiguration must be specified with the
                        ARN of a Lambda function.

                     promptCreationMode -> (string)
                        Specifies  whether to override the default prompt tem-
                        plate for this promptType . Set this value to OVERRID-
                        DEN  to  use  the prompt that you provide in the base-
                        PromptTemplate . If you leave  it  as  DEFAULT  ,  the
                        agent uses a default prompt template.

                     promptState -> (string)
                        Specifies  whether to allow the agent to carry out the
                        step specified in the promptType .  If  you  set  this
                        value to DISABLED , the agent skips that step. The de-
                        fault state for each promptType is as follows.

                        o PRE_PROCESSING  ENABLED

                        o ORCHESTRATION  ENABLED

                        o KNOWLEDGE_BASE_RESPONSE_GENERATION  ENABLED

                        o POST_PROCESSING  DISABLED

                     promptType -> (string)
                        The step in the agent sequence that this  prompt  con-
                        figuration applies to.

          recommendedActions -> (list)
              Contains  recommended  actions to take for the agent-related API
              that you invoked to succeed.

              (string)

          updatedAt -> (timestamp)
              The time at which the agent was last updated.



                                                                UPDATE-AGENT()
