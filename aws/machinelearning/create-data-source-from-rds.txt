CREATE-DATA-SOURCE-FROM-RDS()                    CREATE-DATA-SOURCE-FROM-RDS()



NAME
       create-data-source-from-rds -

DESCRIPTION
       Creates  a DataSource object from an Amazon Relational Database Service
       (Amazon RDS). A DataSource references data that can be used to  perform
       CreateMLModel , CreateEvaluation , or CreateBatchPrediction operations.
          CreateDataSourceFromRDS is an asynchronous operation. In response to
          CreateDataSourceFromRDS , Amazon Machine Learning (Amazon ML)  imme-
          diately  returns  and  sets the DataSource status to PENDING . After
          the DataSource is created and ready for use, Amazon ML sets the Sta-
          tus  parameter to COMPLETED . DataSource in the COMPLETED or PENDING
          state can be used only to perform >CreateMLModel >, CreateEvaluation
          , or CreateBatchPrediction operations.

       If Amazon ML cannot accept the input source, it sets the Status parame-
       ter to FAILED and includes an error message in the Message attribute of
       the GetDataSource operation response.

       See also: AWS API Documentation

SYNOPSIS
            create-data-source-from-rds
          --data-source-id <value>
          [--data-source-name <value>]
          --rds-data <value>
          --role-arn <value>
          [--compute-statistics | --no-compute-statistics]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --data-source-id (string)
          A  user-supplied  ID that uniquely identifies the DataSource . Typi-
          cally, an Amazon Resource Number (ARN) becomes the ID  for  a  Data-
          Source .

       --data-source-name (string)
          A user-supplied name or description of the DataSource .

       --rds-data (structure)
          The data specification of an Amazon RDS DataSource :

          o DatabaseInformation -

            o DatabaseName - The name of the Amazon RDS database.

            o InstanceIdentifier  -  A  unique  identifier  for the Amazon RDS
              database instance.

          o DatabaseCredentials - AWS Identity  and  Access  Management  (IAM)
            credentials that are used to connect to the Amazon RDS database.

          o ResourceRole - A role (DataPipelineDefaultResourceRole) assumed by
            an EC2 instance to carry out the copy task from Amazon RDS to Ama-
            zon  Simple Storage Service (Amazon S3). For more information, see
            Role templates for data pipelines.

          o ServiceRole - A role (DataPipelineDefaultRole) assumed by the  AWS
            Data  Pipeline  service  to  monitor the progress of the copy task
            from Amazon RDS to Amazon S3. For more information, see Role  tem-
            plates for data pipelines.

          o SecurityInfo - The security information to use to access an RDS DB
            instance. You need to set up appropriate ingress rules for the se-
            curity  entity  IDs provided to allow access to the Amazon RDS in-
            stance. Specify a  [SubnetId  ,  SecurityGroupIds  ]  pair  for  a
            VPC-based RDS DB instance.

          o SelectSqlQuery  - A query that is used to retrieve the observation
            data for the Datasource .

          o S3StagingLocation - The Amazon S3 location for staging Amazon  RDS
            data.  The  data retrieved from Amazon RDS using SelectSqlQuery is
            stored in this location.

          o DataSchemaUri - The Amazon S3 location of the DataSchema .

          o DataSchema - A JSON string representing the schema.  This  is  not
            required if DataSchemaUri is specified.

          o DataRearrangement  -  A  JSON string that represents the splitting
            and rearrangement requirements for  the  Datasource  .   Sample  -
            "{\"splitting\":{\"percentBegin\":10,\"percentEnd\":60}}"

          DatabaseInformation -> (structure)
              Describes  the  DatabaseName and InstanceIdentifier of an Amazon
              RDS database.

              InstanceIdentifier -> (string)
                 The ID of an RDS DB instance.

              DatabaseName -> (string)
                 The name of a database hosted on an RDS DB instance.

          SelectSqlQuery -> (string)
              The query that is used to retrieve the observation data for  the
              DataSource .

          DatabaseCredentials -> (structure)
              The  AWS  Identity  and Access Management (IAM) credentials that
              are used connect to the Amazon RDS database.

              Username -> (string)
                 The username to be used by Amazon ML to connect  to  database
                 on  an  Amazon  RDS instance. The username should have suffi-
                 cient permissions to execute an RDSSelectSqlQuery query.

              Password -> (string)
                 The password to be used by Amazon ML to connect to a database
                 on  an  RDS  DB instance. The password should have sufficient
                 permissions to execute the RDSSelectQuery query.

          S3StagingLocation -> (string)
              The Amazon S3 location for staging Amazon RDS data. The data re-
              trieved  from  Amazon RDS using SelectSqlQuery is stored in this
              location.

          DataRearrangement -> (string)
              A JSON string that represents the  splitting  and  rearrangement
              processing to be applied to a DataSource . If the DataRearrange-
              ment parameter is not provided, all of the input data is used to
              create the Datasource .

              There  are multiple parameters that control what data is used to
              create a datasource:

              o

                **
                percentBegin **   Use percentBegin to indicate  the  beginning
                of the range of the data used to create the Datasource. If you
                do not include percentBegin and percentEnd  ,  Amazon  ML  in-
                cludes all of the data when creating the datasource.

              System Message: WARNING/2 (<string>:, line 213)
                Inline strong start-string without end-string.

              o

                **
                percentEnd  **    Use  percentEnd  to  indicate the end of the
                range of the data used to create the Datasource. If you do not
                include  percentBegin  and percentEnd , Amazon ML includes all
                of the data when creating the datasource.

              System Message: WARNING/2 (<string>:, line 215)
                Inline strong start-string without end-string.

              o

                **
                complement **   The complement parameter instructs  Amazon  ML
                to  use the data that is not included in the range of percent-
                Begin to percentEnd to create a datasource. The complement pa-
                rameter  is  useful  if you need to create complementary data-
                sources for training and evaluation. To create a complementary
                datasource,  use  the  same  values  for percentBegin and per-
                centEnd , along with the complement  parameter.  For  example,
                the  following  two datasources do not share any data, and can
                be used to train and evaluate a model.  The  first  datasource
                has  25 percent of the data, and the second one has 75 percent
                of the data. Datasource  for  evaluation:  {"splitting":{"per-
                centBegin":0,  "percentEnd":25}}    Datasource  for  training:
                {"splitting":{"percentBegin":0,   "percentEnd":25,    "comple-
                ment":"true"}}

              System Message: WARNING/2 (<string>:, line 217)
                Inline strong start-string without end-string.

              o

                **
                strategy  **    To  change how Amazon ML splits the data for a
                datasource, use the strategy parameter. The default value  for
                the  strategy parameter is sequential , meaning that Amazon ML
                takes all of the data records  between  the  percentBegin  and
                percentEnd  parameters  for  the datasource, in the order that
                the records appear  in  the  input  data.  The  following  two
                DataRearrangement  lines  are examples of sequentially ordered
                training and evaluation datasources:  Datasource  for  evalua-
                tion:    {"splitting":{"percentBegin":70,    "percentEnd":100,
                "strategy":"sequential"}}   Datasource for training:  {"split-
                ting":{"percentBegin":70,   "percentEnd":100,  "strategy":"se-
                quential", "complement":"true"}}   To randomly split the input
                data  into  the  proportions indicated by the percentBegin and
                percentEnd parameters, set the strategy  parameter  to  random
                and  provide  a  string that is used as the seed value for the
                random data splitting (for example, you can use the S3 path to
                your data as the random seed string). If you choose the random
                split  strategy,  Amazon  ML  assigns  each  row  of  data   a
                pseudo-random  number  between 0 and 100, and then selects the
                rows that have an assigned  number  between  percentBegin  and
                percentEnd . Pseudo-random numbers are assigned using both the
                input seed string value and the byte  offset  as  a  seed,  so
                changing  the  data results in a different split. Any existing
                ordering is preserved. The random splitting  strategy  ensures
                that  variables  in  the training and evaluation data are dis-
                tributed similarly. It is useful in the cases where the  input
                data  may  have  an implicit sort order, which would otherwise
                result  in  training  and  evaluation  datasources  containing
                non-similar  data records. The following two DataRearrangement
                lines are examples of non-sequentially  ordered  training  and
                evaluation  datasources:  Datasource  for evaluation: {"split-
                ting":{"percentBegin":70,  "percentEnd":100,  "strategy":"ran-
                dom", "randomSeed"="s3://my_s3_path/bucket/file.csv"}}   Data-
                source for  training:  {"splitting":{"percentBegin":70,  "per-
                centEnd":100,           "strategy":"random",          "random-
                Seed"="s3://my_s3_path/bucket/file.csv", "complement":"true"}}

              System Message: WARNING/2 (<string>:, line 219)
                Inline strong start-string without end-string.

          DataSchema -> (string)
              A JSON string that represents the schema for an Amazon RDS Data-
              Source . The DataSchema defines the structure of the observation
              data in the data file(s) referenced in the DataSource .

              A DataSchema is not required if you specify a DataSchemaUri

              Define your DataSchema as  a  series  of  key-value  pairs.  at-
              tributes  and  excludedVariableNames  have an array of key-value
              pairs for their value. Use the following format to  define  your
              DataSchema .

              { "version": "1.0",

              "recordAnnotationFieldName": "F1",

              "recordWeightFieldName": "F2",

              "targetFieldName": "F3",

              "dataFormat": "CSV",

              "dataFileContainsHeader": true,

              "attributes": [

              { "fieldName": "F1", "fieldType": "TEXT" }, { "fieldName": "F2",
              "fieldType": "NUMERIC"  },  {  "fieldName":  "F3",  "fieldType":
              "CATEGORICAL"  }, { "fieldName": "F4", "fieldType": "NUMERIC" },
              { "fieldName": "F5", "fieldType":  "CATEGORICAL"  },  {  "field-
              Name": "F6", "fieldType": "TEXT" }, { "fieldName": "F7", "field-
              Type": "WEIGHTED_INT_SEQUENCE" }, { "fieldName":  "F8",  "field-
              Type": "WEIGHTED_STRING_SEQUENCE" } ],

              "excludedVariableNames": [ "F6" ] }

          DataSchemaUri -> (string)
              The Amazon S3 location of the DataSchema .

          ResourceRole -> (string)
              The  role (DataPipelineDefaultResourceRole) assumed by an Amazon
              Elastic Compute Cloud (Amazon EC2) instance  to  carry  out  the
              copy  operation  from  Amazon RDS to an Amazon S3 task. For more
              information, see Role templates for data pipelines.

          ServiceRole -> (string)
              The role (DataPipelineDefaultRole) assumed by AWS Data  Pipeline
              service to monitor the progress of the copy task from Amazon RDS
              to Amazon S3. For more information, see Role templates for  data
              pipelines.

          SubnetId -> (string)
              The  subnet ID to be used to access a VPC-based RDS DB instance.
              This attribute is used by Data Pipeline to carry  out  the  copy
              task from Amazon RDS to Amazon S3.

          SecurityGroupIds -> (list)
              The  security  group IDs to be used to access a VPC-based RDS DB
              instance. Ensure that there are appropriate ingress rules set up
              to  allow  access to the RDS DB instance. This attribute is used
              by Data Pipeline to carry out the copy operation from Amazon RDS
              to an Amazon S3 task.

              (string)

       Shorthand Syntax:

          DatabaseInformation={InstanceIdentifier=string,DatabaseName=string},SelectSqlQuery=string,DatabaseCredentials={Username=string,Password=string},S3StagingLocation=string,DataRearrangement=string,DataSchema=string,DataSchemaUri=string,ResourceRole=string,ServiceRole=string,SubnetId=string,SecurityGroupIds=string,string

       JSON Syntax:

          {
            "DatabaseInformation": {
              "InstanceIdentifier": "string",
              "DatabaseName": "string"
            },
            "SelectSqlQuery": "string",
            "DatabaseCredentials": {
              "Username": "string",
              "Password": "string"
            },
            "S3StagingLocation": "string",
            "DataRearrangement": "string",
            "DataSchema": "string",
            "DataSchemaUri": "string",
            "ResourceRole": "string",
            "ServiceRole": "string",
            "SubnetId": "string",
            "SecurityGroupIds": ["string", ...]
          }

       --role-arn (string)
          The  role that Amazon ML assumes on behalf of the user to create and
          activate a data pipeline in the user's account and copy  data  using
          the SelectSqlQuery query from Amazon RDS to Amazon S3.

       --compute-statistics | --no-compute-statistics (boolean)
          The  compute statistics for a DataSource . The statistics are gener-
          ated from the observation data referenced by a DataSource  .  Amazon
          ML  uses the statistics internally during MLModel training. This pa-
          rameter must be set to true if the DataSourceneeds to  be  used  for
          MLModel training.

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination. If automatic pagination is disabled,  the
       AWS CLI will only make one call, for the first page of results.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

OUTPUT
       DataSourceId -> (string)
          A  user-supplied  ID  that  uniquely identifies the datasource. This
          value should be identical to the value of the  DataSourceID  in  the
          request.



                                                 CREATE-DATA-SOURCE-FROM-RDS()
