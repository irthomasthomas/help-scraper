BATCH-GET-JOBS()                                              BATCH-GET-JOBS()



NAME
       batch-get-jobs -

DESCRIPTION
       Returns  a list of resource metadata for a given list of job names. Af-
       ter calling the ListJobs operation, you can call this operation to  ac-
       cess  the  data to which you have been granted permissions. This opera-
       tion supports all IAM permissions, including permission conditions that
       uses tags.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            batch-get-jobs
          --job-names <value>
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --job-names (list)
          A  list  of  job  names,  which might be the names returned from the
          ListJobs operation.

          (string)

       Syntax:

          "string" "string" ...

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       Jobs -> (list)
          A list of job definitions.

          (structure)
              Specifies a job definition.

              Name -> (string)
                 The name you assign to this job definition.

              Description -> (string)
                 A description of the job.

              LogUri -> (string)
                 This field is reserved for future use.

              Role -> (string)
                 The  name or Amazon Resource Name (ARN) of the IAM role asso-
                 ciated with this job.

              CreatedOn -> (timestamp)
                 The time and date that this job definition was created.

              LastModifiedOn -> (timestamp)
                 The last point in time when this job definition was modified.

              ExecutionProperty -> (structure)
                 An ExecutionProperty specifying the maximum number of concur-
                 rent runs allowed for this job.

                 MaxConcurrentRuns -> (integer)
                     The  maximum  number  of  concurrent runs allowed for the
                     job. The default is 1. An error  is  returned  when  this
                     threshold  is  reached. The maximum value you can specify
                     is controlled by a service limit.

              Command -> (structure)
                 The JobCommand that runs this job.

                 Name -> (string)
                     The name of the job command. For an Apache Spark ETL job,
                     this must be glueetl . For a Python shell job, it must be
                     pythonshell . For an Apache Spark streaming ETL job, this
                     must be gluestreaming .

                 ScriptLocation -> (string)
                     Specifies  the  Amazon Simple Storage Service (Amazon S3)
                     path to a script that runs a job.

                 PythonVersion -> (string)
                     The Python version being used to run a Python shell  job.
                     Allowed values are 2 or 3.

              DefaultArguments -> (map)
                 The  default  arguments for this job, specified as name-value
                 pairs.

                 You can specify arguments here that  your  own  job-execution
                 script  consumes,  as well as arguments that Glue itself con-
                 sumes.

                 For information about how to specify and consume your own Job
                 arguments,  see  the Calling Glue APIs in Python topic in the
                 developer guide.

                 For information about the key-value pairs that Glue  consumes
                 to  set  up your job, see the Special Parameters Used by Glue
                 topic in the developer guide.

                 key -> (string)

                 value -> (string)

              NonOverridableArguments -> (map)
                 Non-overridable  arguments  for  this   job,   specified   as
                 name-value pairs.

                 key -> (string)

                 value -> (string)

              Connections -> (structure)
                 The connections used for this job.

                 Connections -> (list)
                     A list of connections used by the job.

                     (string)

              MaxRetries -> (integer)
                 The  maximum number of times to retry this job after a JobRun
                 fails.

              AllocatedCapacity -> (integer)
                 This field is deprecated. Use MaxCapacity instead.

                 The number of Glue data processing units (DPUs) allocated  to
                 runs  of  this job. You can allocate a minimum of 2 DPUs; the
                 default is 10. A DPU is  a  relative  measure  of  processing
                 power  that consists of 4 vCPUs of compute capacity and 16 GB
                 of memory. For more information, see the Glue pricing page .

              Timeout -> (integer)
                 The job timeout in minutes. This is the maximum time  that  a
                 job run can consume resources before it is terminated and en-
                 ters TIMEOUT status. The default is 2,880 minutes (48 hours).

              MaxCapacity -> (double)
                 For Glue version 1.0 or  earlier  jobs,  using  the  standard
                 worker  type, the number of Glue data processing units (DPUs)
                 that can be allocated when this job runs. A DPU is a relative
                 measure  of processing power that consists of 4 vCPUs of com-
                 pute capacity and 16 GB of memory. For more information,  see
                 the Glue pricing page .

                 Do not set Max Capacity if using WorkerType and NumberOfWork-
                 ers .

                 The value that can be allocated for  MaxCapacity  depends  on
                 whether  you  are running a Python shell job, an Apache Spark
                 ETL job, or an Apache Spark streaming ETL job:

                 o When  you  specify  a  Python  shell  job  (JobCommand.Name
                   ="pythonshell"),  you  can allocate either 0.0625 or 1 DPU.
                   The default is 0.0625 DPU.

                 o When you specify an Apache Spark ETL  job  (JobCommand.Name
                   ="glueetl")  or  Apache  Spark  streaming  ETL job (JobCom-
                   mand.Name ="gluestreaming"), you can allocate a minimum  of
                   2 DPUs. The default is 10 DPUs. This job type cannot have a
                   fractional DPU allocation.

                 For Glue version 2.0 jobs, you cannot instead specify a Maxi-
                 mum  capacity . Instead, you should specify a Worker type and
                 the Number of workers .

              WorkerType -> (string)
                 The type of predefined worker that is allocated  when  a  job
                 runs. Accepts a value of Standard, G.1X, G.2X, or G.025X.

                 o For  the Standard worker type, each worker provides 4 vCPU,
                   16 GB of memory and  a  50GB  disk,  and  2  executors  per
                   worker.

                 o For  the  G.1X  worker  type,  each worker maps to 1 DPU (4
                   vCPU, 16 GB of memory, 64 GB disk), and provides 1 executor
                   per worker. We recommend this worker type for memory-inten-
                   sive jobs.

                 o For the G.2X worker type, each worker  maps  to  2  DPU  (8
                   vCPU,  32 GB of memory, 128 GB disk), and provides 1 execu-
                   tor per worker. We recommend  this  worker  type  for  mem-
                   ory-intensive jobs.

                 o For the G.025X worker type, each worker maps to 0.25 DPU (2
                   vCPU, 4 GB of memory, 64 GB disk), and provides 1  executor
                   per  worker.  We  recommend this worker type for low volume
                   streaming jobs. This worker type is only available for Glue
                   version 3.0 streaming jobs.

              NumberOfWorkers -> (integer)
                 The  number of workers of a defined workerType that are allo-
                 cated when a job runs.

              SecurityConfiguration -> (string)
                 The name of the SecurityConfiguration structure  to  be  used
                 with this job.

              NotificationProperty -> (structure)
                 Specifies configuration properties of a job notification.

                 NotifyDelayAfter -> (integer)
                     After a job run starts, the number of minutes to wait be-
                     fore sending a job run delay notification.

              GlueVersion -> (string)
                 Glue version determines the  versions  of  Apache  Spark  and
                 Python  that  Glue supports. The Python version indicates the
                 version supported for jobs of type Spark.

                 For more information about the available  Glue  versions  and
                 corresponding  Spark and Python versions, see Glue version in
                 the developer guide.

                 Jobs that are created without specifying a Glue  version  de-
                 fault to Glue 0.9.

              CodeGenConfigurationNodes -> (map)
                 The  representation of a directed acyclic graph on which both
                 the Glue Studio visual component and Glue Studio code genera-
                 tion is based.

                 key -> (string)

                 value -> (structure)
                        CodeGenConfigurationNode  enumerates  all  valid  Node
                        types. One and only one of its member variables can be
                        populated.

                     AthenaConnectorSource -> (structure)
                        Specifies a connector to an Amazon Athena data source.

                        Name -> (string)
                            The name of the data source.

                        ConnectionName -> (string)
                            The name of the connection that is associated with
                            the connector.

                        ConnectorName -> (string)
                            The name of a connector that assists with  access-
                            ing the data store in Glue Studio.

                        ConnectionType -> (string)
                            The type of connection, such as marketplace.athena
                            or custom.athena, designating a connection  to  an
                            Amazon Athena data store.

                        ConnectionTable -> (string)
                            The name of the table in the data source.

                        SchemaName -> (string)
                            The name of the Cloudwatch log group to read from.
                            For example, /aws-glue/jobs/output .

                        OutputSchemas -> (list)
                            Specifies the data schema for  the  custom  Athena
                            source.

                            (structure)
                               Specifies  a  user-defined schema when a schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies the column definitions that  make
                                   up a Glue schema.

                                   (structure)
                                      Specifies  a  single  column  in  a Glue
                                      schema definition.

                                      Name -> (string)
                                          The name of the column in  the  Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     JDBCConnectorSource -> (structure)
                        Specifies a connector to a JDBC data source.

                        Name -> (string)
                            The name of the data source.

                        ConnectionName -> (string)
                            The name of the connection that is associated with
                            the connector.

                        ConnectorName -> (string)
                            The  name of a connector that assists with access-
                            ing the data store in Glue Studio.

                        ConnectionType -> (string)
                            The type of connection, such  as  marketplace.jdbc
                            or custom.jdbc, designating a connection to a JDBC
                            data store.

                        AdditionalOptions -> (structure)
                            Additional connection options for the connector.

                            FilterPredicate -> (string)
                               Extra condition  clause  to  filter  data  from
                               source. For example:
                                   BillingCity='Mountain View'

                               When using a query instead of a table name, you
                               should validate that the query works  with  the
                               specified filterPredicate .

                            PartitionColumn -> (string)
                               The  name of an integer column that is used for
                               partitioning. This option works only when  it's
                               included  with  lowerBound  ,  upperBound , and
                               numPartitions . This option works the same  way
                               as in the Spark SQL JDBC reader.

                            LowerBound -> (long)
                               The  minimum  value  of partitionColumn that is
                               used to decide partition stride.

                            UpperBound -> (long)
                               The maximum value of  partitionColumn  that  is
                               used to decide partition stride.

                            NumPartitions -> (long)
                               The  number  of  partitions.  This value, along
                               with lowerBound (inclusive) and upperBound (ex-
                               clusive),  form partition strides for generated
                               WHERE clause expressions that are used to split
                               the partitionColumn .

                            JobBookmarkKeys -> (list)
                               The  name  of the job bookmark keys on which to
                               sort.

                               (string)

                            JobBookmarkKeysSortOrder -> (string)
                               Specifies an ascending or descending  sort  or-
                               der.

                            DataTypeMapping -> (map)
                               Custom  data type mapping that builds a mapping
                               from a JDBC data type to an Glue data type. For
                               example,      the      option     "dataTypeMap-
                               ping":{"FLOAT":"STRING"} maps  data  fields  of
                               JDBC  type  FLOAT  into the Java String type by
                               calling the ResultSet.getString() method of the
                               driver,  and  uses it to build the Glue record.
                               The ResultSet object  is  implemented  by  each
                               driver,  so  the  behavior  is  specific to the
                               driver you use. Refer to the documentation  for
                               your  JDBC  driver to understand how the driver
                               performs the conversions.

                               key -> (string)

                               value -> (string)

                        ConnectionTable -> (string)
                            The name of the table in the data source.

                        Query -> (string)
                            The table or SQL query to get the data  from.  You
                            can  specify either ConnectionTable or query , but
                            not both.

                        OutputSchemas -> (list)
                            Specifies the data  schema  for  the  custom  JDBC
                            source.

                            (structure)
                               Specifies  a  user-defined schema when a schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies the column definitions that  make
                                   up a Glue schema.

                                   (structure)
                                      Specifies  a  single  column  in  a Glue
                                      schema definition.

                                      Name -> (string)
                                          The name of the column in  the  Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     SparkConnectorSource -> (structure)
                        Specifies a connector to an Apache Spark data source.

                        Name -> (string)
                            The name of the data source.

                        ConnectionName -> (string)
                            The name of the connection that is associated with
                            the connector.

                        ConnectorName -> (string)
                            The  name of a connector that assists with access-
                            ing the data store in Glue Studio.

                        ConnectionType -> (string)
                            The type of connection, such as  marketplace.spark
                            or  custom.spark,  designating  a connection to an
                            Apache Spark data store.

                        AdditionalOptions -> (map)
                            Additional connection options for the connector.

                            key -> (string)

                            value -> (string)

                        OutputSchemas -> (list)
                            Specifies data schema for the custom spark source.

                            (structure)
                               Specifies a user-defined schema when  a  schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies  the column definitions that make
                                   up a Glue schema.

                                   (structure)
                                      Specifies a  single  column  in  a  Glue
                                      schema definition.

                                      Name -> (string)
                                          The  name  of the column in the Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     CatalogSource -> (structure)
                        Specifies a data store in the Glue Data Catalog.

                        Name -> (string)
                            The name of the data store.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     RedshiftSource -> (structure)
                        Specifies an Amazon Redshift data store.

                        Name -> (string)
                            The name of the Amazon Redshift data store.

                        Database -> (string)
                            The database to read from.

                        Table -> (string)
                            The database table to read from.

                        RedshiftTmpDir -> (string)
                            The Amazon S3 path where  temporary  data  can  be
                            staged when copying out of the database.

                        TmpDirIAMRole -> (string)
                            The IAM role with permissions.

                     S3CatalogSource -> (structure)
                        Specifies  an  Amazon  S3  data store in the Glue Data
                        Catalog.

                        Name -> (string)
                            The name of the data store.

                        Database -> (string)
                            The database to read from.

                        Table -> (string)
                            The database table to read from.

                        PartitionPredicate -> (string)
                            Partitions satisfying this predicate are  deleted.
                            Files  within the retention period in these parti-
                            tions are not deleted. Set to  ""   empty  by  de-
                            fault.

                        AdditionalOptions -> (structure)
                            Specifies additional connection options.

                            BoundedSize -> (long)
                               Sets the upper limit for the target size of the
                               dataset in bytes that will be processed.

                            BoundedFiles -> (long)
                               Sets the upper limit for the target  number  of
                               files that will be processed.

                     S3CsvSource -> (structure)
                        Specifies  a  command-separated value (CSV) data store
                        stored in Amazon S3.

                        Name -> (string)
                            The name of the data store.

                        Paths -> (list)
                            A list of the Amazon S3 paths to read from.

                            (string)

                        CompressionType -> (string)
                            Specifies how the data is compressed. This is gen-
                            erally  not  necessary  if the data has a standard
                            file extension. Possible  values  are  "gzip"  and
                            "bzip" ).

                        Exclusions -> (list)
                            A string containing a JSON list of Unix-style glob
                            patterns to exclude. For example, "["
                            **
                            .pdf"]" excludes all PDF files.

                            System Message: WARNING/2 (<string>:, line 1204)
                                   Inline    strong    start-string    without
                                   end-string.

                                   (string)

                        GroupSize -> (string)
                            The  target  group  size  in bytes. The default is
                            computed based on the input data size and the size
                            of  your cluster. When there are fewer than 50,000
                            input files, "groupFiles" must be set to "inParti-
                            tion" for this to take effect.

                        GroupFiles -> (string)
                            Grouping  files  is  turned on by default when the
                            input contains more than 50,000 files. To turn  on
                            grouping  with  fewer  than 50,000 files, set this
                            parameter to "inPartition".  To  disable  grouping
                            when  there  are  more than 50,000 files, set this
                            parameter to "none" .

                        Recurse -> (boolean)
                            If set to true, recursively  reads  files  in  all
                            subdirectories under the specified paths.

                        MaxBand -> (integer)
                            This  option controls the duration in milliseconds
                            after which the s3 listing is likely to be consis-
                            tent.  Files  with modification timestamps falling
                            within the last maxBand milliseconds  are  tracked
                            specially  when  using JobBookmarks to account for
                            Amazon S3 eventual consistency. Most  users  don't
                            need  to  set  this  option. The default is 900000
                            milliseconds, or 15 minutes.

                        MaxFilesInBand -> (integer)
                            This option specifies the maximum number of  files
                            to  save  from  the  last maxBand seconds. If this
                            number is exceeded, extra files  are  skipped  and
                            only processed in the next job run.

                        AdditionalOptions -> (structure)
                            Specifies additional connection options.

                            BoundedSize -> (long)
                               Sets the upper limit for the target size of the
                               dataset in bytes that will be processed.

                            BoundedFiles -> (long)
                               Sets the upper limit for the target  number  of
                               files that will be processed.

                            EnableSamplePath -> (boolean)
                               Sets option to enable a sample path.

                            SamplePath -> (string)
                               If enabled, specifies the sample path.

                        Separator -> (string)
                            Specifies  the delimiter character. The default is
                            a comma: ",", but any other character can be spec-
                            ified.

                        Escaper -> (string)
                            Specifies  a  character  to use for escaping. This
                            option is used only when reading  CSV  files.  The
                            default  value is none . If enabled, the character
                            which immediately follows is  used  as-is,  except
                            for  a  small set of well-known escapes (\n , \r ,
                            \t , and \0 ).

                        QuoteChar -> (string)
                            Specifies the character to use  for  quoting.  The
                            default is a double quote: '"' . Set this to -1 to
                            turn off quoting entirely.

                        Multiline -> (boolean)
                            A Boolean value that specifies  whether  a  single
                            record  can  span  multiple  lines. This can occur
                            when a field contains a quoted new-line character.
                            You  must  set  this  option to True if any record
                            spans multiple lines. The default value is False ,
                            which  allows  for  more aggressive file-splitting
                            during parsing.

                        WithHeader -> (boolean)
                            A Boolean value that specifies  whether  to  treat
                            the  first  line as a header. The default value is
                            False .

                        WriteHeader -> (boolean)
                            A Boolean value that specifies  whether  to  write
                            the header to output. The default value is True .

                        SkipFirst -> (boolean)
                            A Boolean value that specifies whether to skip the
                            first data line. The default value is False .

                        OptimizePerformance -> (boolean)
                            A Boolean value that specifies whether to use  the
                            advanced  SIMD  CSV reader along with Apache Arrow
                            based columnar memory formats. Only  available  in
                            Glue version 3.0.

                        OutputSchemas -> (list)
                            Specifies the data schema for the S3 CSV source.

                            (structure)
                               Specifies  a  user-defined schema when a schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies the column definitions that  make
                                   up a Glue schema.

                                   (structure)
                                      Specifies  a  single  column  in  a Glue
                                      schema definition.

                                      Name -> (string)
                                          The name of the column in  the  Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     S3JsonSource -> (structure)
                        Specifies a JSON data store stored in Amazon S3.

                        Name -> (string)
                            The name of the data store.

                        Paths -> (list)
                            A list of the Amazon S3 paths to read from.

                            (string)

                        CompressionType -> (string)
                            Specifies how the data is compressed. This is gen-
                            erally  not  necessary  if the data has a standard
                            file extension. Possible  values  are  "gzip"  and
                            "bzip" ).

                        Exclusions -> (list)
                            A string containing a JSON list of Unix-style glob
                            patterns to exclude. For example, "["
                            **
                            .pdf"]" excludes all PDF files.

                            System Message: WARNING/2 (<string>:, line 1506)
                                   Inline    strong    start-string    without
                                   end-string.

                                   (string)

                        GroupSize -> (string)
                            The  target  group  size  in bytes. The default is
                            computed based on the input data size and the size
                            of  your cluster. When there are fewer than 50,000
                            input files, "groupFiles" must be set to "inParti-
                            tion" for this to take effect.

                        GroupFiles -> (string)
                            Grouping  files  is  turned on by default when the
                            input contains more than 50,000 files. To turn  on
                            grouping  with  fewer  than 50,000 files, set this
                            parameter to "inPartition".  To  disable  grouping
                            when  there  are  more than 50,000 files, set this
                            parameter to "none" .

                        Recurse -> (boolean)
                            If set to true, recursively  reads  files  in  all
                            subdirectories under the specified paths.

                        MaxBand -> (integer)
                            This  option controls the duration in milliseconds
                            after which the s3 listing is likely to be consis-
                            tent.  Files  with modification timestamps falling
                            within the last maxBand milliseconds  are  tracked
                            specially  when  using JobBookmarks to account for
                            Amazon S3 eventual consistency. Most  users  don't
                            need  to  set  this  option. The default is 900000
                            milliseconds, or 15 minutes.

                        MaxFilesInBand -> (integer)
                            This option specifies the maximum number of  files
                            to  save  from  the  last maxBand seconds. If this
                            number is exceeded, extra files  are  skipped  and
                            only processed in the next job run.

                        AdditionalOptions -> (structure)
                            Specifies additional connection options.

                            BoundedSize -> (long)
                               Sets the upper limit for the target size of the
                               dataset in bytes that will be processed.

                            BoundedFiles -> (long)
                               Sets the upper limit for the target  number  of
                               files that will be processed.

                            EnableSamplePath -> (boolean)
                               Sets option to enable a sample path.

                            SamplePath -> (string)
                               If enabled, specifies the sample path.

                        JsonPath -> (string)
                            A JsonPath string defining the JSON data.

                        Multiline -> (boolean)
                            A  Boolean  value  that specifies whether a single
                            record can span multiple  lines.  This  can  occur
                            when a field contains a quoted new-line character.
                            You must set this option to  True  if  any  record
                            spans multiple lines. The default value is False ,
                            which allows for  more  aggressive  file-splitting
                            during parsing.

                        OutputSchemas -> (list)
                            Specifies the data schema for the S3 JSON source.

                            (structure)
                               Specifies  a  user-defined schema when a schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies the column definitions that  make
                                   up a Glue schema.

                                   (structure)
                                      Specifies  a  single  column  in  a Glue
                                      schema definition.

                                      Name -> (string)
                                          The name of the column in  the  Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     S3ParquetSource -> (structure)
                        Specifies an Apache Parquet data store stored in  Ama-
                        zon S3.

                        Name -> (string)
                            The name of the data store.

                        Paths -> (list)
                            A list of the Amazon S3 paths to read from.

                            (string)

                        CompressionType -> (string)
                            Specifies how the data is compressed. This is gen-
                            erally not necessary if the data  has  a  standard
                            file  extension.  Possible  values  are "gzip" and
                            "bzip" ).

                        Exclusions -> (list)
                            A string containing a JSON list of Unix-style glob
                            patterns to exclude. For example, "["
                            **
                            .pdf"]" excludes all PDF files.

                            System Message: WARNING/2 (<string>:, line 1748)
                                   Inline    strong    start-string    without
                                   end-string.

                                   (string)

                        GroupSize -> (string)
                            The target group size in  bytes.  The  default  is
                            computed based on the input data size and the size
                            of your cluster. When there are fewer than  50,000
                            input files, "groupFiles" must be set to "inParti-
                            tion" for this to take effect.

                        GroupFiles -> (string)
                            Grouping files is turned on by  default  when  the
                            input  contains more than 50,000 files. To turn on
                            grouping with fewer than 50,000  files,  set  this
                            parameter  to  "inPartition".  To disable grouping
                            when there are more than 50,000  files,  set  this
                            parameter to "none" .

                        Recurse -> (boolean)
                            If  set  to  true,  recursively reads files in all
                            subdirectories under the specified paths.

                        MaxBand -> (integer)
                            This option controls the duration in  milliseconds
                            after which the s3 listing is likely to be consis-
                            tent. Files with modification  timestamps  falling
                            within  the  last maxBand milliseconds are tracked
                            specially when using JobBookmarks to  account  for
                            Amazon  S3  eventual consistency. Most users don't
                            need to set this option.  The  default  is  900000
                            milliseconds, or 15 minutes.

                        MaxFilesInBand -> (integer)
                            This  option specifies the maximum number of files
                            to save from the last  maxBand  seconds.  If  this
                            number  is  exceeded,  extra files are skipped and
                            only processed in the next job run.

                        AdditionalOptions -> (structure)
                            Specifies additional connection options.

                            BoundedSize -> (long)
                               Sets the upper limit for the target size of the
                               dataset in bytes that will be processed.

                            BoundedFiles -> (long)
                               Sets  the  upper limit for the target number of
                               files that will be processed.

                            EnableSamplePath -> (boolean)
                               Sets option to enable a sample path.

                            SamplePath -> (string)
                               If enabled, specifies the sample path.

                        OutputSchemas -> (list)
                            Specifies the  data  schema  for  the  S3  Parquet
                            source.

                            (structure)
                               Specifies  a  user-defined schema when a schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies the column definitions that  make
                                   up a Glue schema.

                                   (structure)
                                      Specifies  a  single  column  in  a Glue
                                      schema definition.

                                      Name -> (string)
                                          The name of the column in  the  Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     RelationalCatalogSource -> (structure)
                        Specifies a Relational database  data  source  in  the
                        Glue Data Catalog.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     DynamoDBCatalogSource -> (structure)
                        Specifies a DynamoDB data source in the Glue Data Cat-
                        alog.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     JDBCConnectorTarget -> (structure)
                        Specifies a data target that writes to  Amazon  S3  in
                        Apache Parquet columnar storage.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        ConnectionName -> (string)
                            The name of the connection that is associated with
                            the connector.

                        ConnectionTable -> (string)
                            The name of the table in the data target.

                        ConnectorName -> (string)
                            The name of a connector that will be used.

                        ConnectionType -> (string)
                            The type of connection, such  as  marketplace.jdbc
                            or custom.jdbc, designating a connection to a JDBC
                            data target.

                        AdditionalOptions -> (map)
                            Additional connection options for the connector.

                            key -> (string)

                            value -> (string)

                        OutputSchemas -> (list)
                            Specifies the data schema for the JDBC target.

                            (structure)
                               Specifies a user-defined schema when  a  schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies  the column definitions that make
                                   up a Glue schema.

                                   (structure)
                                      Specifies a  single  column  in  a  Glue
                                      schema definition.

                                      Name -> (string)
                                          The  name  of the column in the Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     SparkConnectorTarget -> (structure)
                        Specifies  a  target that uses an Apache Spark connec-
                        tor.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        ConnectionName -> (string)
                            The name of a connection for an Apache Spark  con-
                            nector.

                        ConnectorName -> (string)
                            The name of an Apache Spark connector.

                        ConnectionType -> (string)
                            The  type of connection, such as marketplace.spark
                            or custom.spark, designating a  connection  to  an
                            Apache Spark data store.

                        AdditionalOptions -> (map)
                            Additional connection options for the connector.

                            key -> (string)

                            value -> (string)

                        OutputSchemas -> (list)
                            Specifies  the  data  schema  for the custom spark
                            target.

                            (structure)
                               Specifies a user-defined schema when  a  schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies  the column definitions that make
                                   up a Glue schema.

                                   (structure)
                                      Specifies a  single  column  in  a  Glue
                                      schema definition.

                                      Name -> (string)
                                          The  name  of the column in the Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     CatalogTarget -> (structure)
                        Specifies  a  target that uses a Glue Data Catalog ta-
                        ble.

                        Name -> (string)
                            The name of your data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The database that contains the table you  want  to
                            use  as the target. This database must already ex-
                            ist in the Data Catalog.

                        Table -> (string)
                            The table that defines the schema of  your  output
                            data.  This  table  must already exist in the Data
                            Catalog.

                     RedshiftTarget -> (structure)
                        Specifies a target that uses Amazon Redshift.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The name of the database to write to.

                        Table -> (string)
                            The name of the table in the database to write to.

                        RedshiftTmpDir -> (string)
                            The Amazon S3 path where  temporary  data  can  be
                            staged when copying out of the database.

                        TmpDirIAMRole -> (string)
                            The IAM role with permissions.

                        UpsertRedshiftOptions -> (structure)
                            The  set  of options to configure an upsert opera-
                            tion when writing to a Redshift target.

                            TableLocation -> (string)
                               The physical location of the Redshift table.

                            ConnectionName -> (string)
                               The name of the connection to use to  write  to
                               Redshift.

                            UpsertKeys -> (list)
                               The  keys  used to determine whether to perform
                               an update or insert.

                               (string)

                     S3CatalogTarget -> (structure)
                        Specifies a data target that writes to Amazon S3 using
                        the Glue Data Catalog.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        PartitionKeys -> (list)
                            Specifies  native partitioning using a sequence of
                            keys.

                            (list)
                               (string)

                        Table -> (string)
                            The name of the table in the database to write to.

                        Database -> (string)
                            The name of the database to write to.

                        SchemaChangePolicy -> (structure)
                            A policy that specifies update  behavior  for  the
                            crawler.

                            EnableUpdateCatalog -> (boolean)
                               Whether  to  use  the specified update behavior
                               when the crawler finds a changed schema.

                            UpdateBehavior -> (string)
                               The update behavior when the  crawler  finds  a
                               changed schema.

                     S3GlueParquetTarget -> (structure)
                        Specifies  a  data  target that writes to Amazon S3 in
                        Apache Parquet columnar storage.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        PartitionKeys -> (list)
                            Specifies native partitioning using a sequence  of
                            keys.

                            (list)
                               (string)

                        Path -> (string)
                            A single Amazon S3 path to write to.

                        Compression -> (string)
                            Specifies how the data is compressed. This is gen-
                            erally not necessary if the data  has  a  standard
                            file  extension.  Possible  values  are "gzip" and
                            "bzip" ).

                        SchemaChangePolicy -> (structure)
                            A policy that specifies update  behavior  for  the
                            crawler.

                            EnableUpdateCatalog -> (boolean)
                               Whether  to  use  the specified update behavior
                               when the crawler finds a changed schema.

                            UpdateBehavior -> (string)
                               The update behavior when the  crawler  finds  a
                               changed schema.

                            Table -> (string)
                               Specifies  the  table  in the database that the
                               schema change policy applies to.

                            Database -> (string)
                               Specifies the database that the  schema  change
                               policy applies to.

                     S3DirectTarget -> (structure)
                        Specifies a data target that writes to Amazon S3.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        PartitionKeys -> (list)
                            Specifies  native partitioning using a sequence of
                            keys.

                            (list)
                               (string)

                        Path -> (string)
                            A single Amazon S3 path to write to.

                        Compression -> (string)
                            Specifies how the data is compressed. This is gen-
                            erally  not  necessary  if the data has a standard
                            file extension. Possible  values  are  "gzip"  and
                            "bzip" ).

                        Format -> (string)
                            Specifies the data output format for the target.

                        SchemaChangePolicy -> (structure)
                            A  policy  that  specifies update behavior for the
                            crawler.

                            EnableUpdateCatalog -> (boolean)
                               Whether to use the  specified  update  behavior
                               when the crawler finds a changed schema.

                            UpdateBehavior -> (string)
                               The  update  behavior  when the crawler finds a
                               changed schema.

                            Table -> (string)
                               Specifies the table in the  database  that  the
                               schema change policy applies to.

                            Database -> (string)
                               Specifies  the  database that the schema change
                               policy applies to.

                     ApplyMapping -> (structure)
                        Specifies a transform that maps data property keys  in
                        the data source to data property keys in the data tar-
                        get. You can rename keys, modify the  data  types  for
                        keys, and choose which keys to drop from the dataset.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Mapping -> (list)
                            Specifies the mapping of data property keys in the
                            data source to data property keys in the data tar-
                            get.

                            (structure)
                               Specifies the mapping of data property keys.

                               ToKey -> (string)
                                   After  the  apply mapping, what the name of
                                   the column should be. Can be  the  same  as
                                   FromPath .

                               FromPath -> (list)
                                   The table or column to be modified.

                                   (string)

                               FromType -> (string)
                                   The type of the data to be modified.

                               ToType -> (string)
                                   The  data type that the data is to be modi-
                                   fied to.

                               Dropped -> (boolean)
                                   If true, then the column is removed.

                               Children -> (list)
                                   Only applicable to nested data  structures.
                                   If you want to change the parent structure,
                                   but also one of its children, you can  fill
                                   out this data strucutre. It is also Mapping
                                   , but its FromPath  will  be  the  parent's
                                   FromPath plus the FromPath from this struc-
                                   ture.

                                   For the children part, suppose you have the
                                   structure:
                                      { "FromPath": "OuterStructure", "ToKey":
                                      "OuterStructure",  "ToType":   "Struct",
                                      "Dropped":    false,    "Chidlren":   [{
                                      "FromPath": "inner",  "ToKey":  "inner",
                                      "ToType": "Double", "Dropped": false, }]
                                      }

                                   You can specify a Mapping that looks like:
                                      { "FromPath": "OuterStructure", "ToKey":
                                      "OuterStructure",   "ToType":  "Struct",
                                      "Dropped":   false,    "Chidlren":    [{
                                      "FromPath":  "inner",  "ToKey": "inner",
                                      "ToType": "Double", "Dropped": false, }]
                                      }

                                   (structure)
                                      Specifies  the  mapping of data property
                                      keys.

                                      ToKey -> (string)
                                          After the apply  mapping,  what  the
                                          name of the column should be. Can be
                                          the same as FromPath .

                                      FromPath -> (list)
                                          The table or column to be modified.

                                          (string)

                                      FromType -> (string)
                                          The type of the data to be modified.

                                      ToType -> (string)
                                          The data type that the data is to be
                                          modified to.

                                      Dropped -> (boolean)
                                          If true, then the column is removed.

                     SelectFields -> (structure)
                        Specifies  a  transform that chooses the data property
                        keys that you want to keep.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Paths -> (list)
                            A JSON path to a variable in the data structure.

                            (list)
                               (string)

                     DropFields -> (structure)
                        Specifies a transform that chooses the  data  property
                        keys that you want to drop.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Paths -> (list)
                            A JSON path to a variable in the data structure.

                            (list)
                               (string)

                     RenameField -> (structure)
                        Specifies a transform that renames a single data prop-
                        erty key.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        SourcePath -> (list)
                            A JSON path to a variable in  the  data  structure
                            for the source data.

                            (string)

                        TargetPath -> (list)
                            A  JSON  path  to a variable in the data structure
                            for the target data.

                            (string)

                     Spigot -> (structure)
                        Specifies a transform that writes samples of the  data
                        to an Amazon S3 bucket.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Path -> (string)
                            A path in Amazon S3 where the transform will write
                            a subset of records from the  dataset  to  a  JSON
                            file in an Amazon S3 bucket.

                        Topk -> (integer)
                            Specifies  a  number  of records to write starting
                            from the beginning of the dataset.

                        Prob -> (double)
                            The probability (a decimal value  with  a  maximum
                            value  of  1) of picking any given record. A value
                            of 1 indicates that each row read from the dataset
                            should be included in the sample output.

                     Join -> (structure)
                        Specifies a transform that joins two datasets into one
                        dataset using a comparison  phrase  on  the  specified
                        data  property  keys.  You can use inner, outer, left,
                        right, left semi, and left anti joins.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        JoinType -> (string)
                            Specifies the type of join to be performed on  the
                            datasets.

                        Columns -> (list)
                            A list of the two columns to be joined.

                            (structure)
                               Specifies a column to be joined.

                               From -> (string)
                                   The column to be joined.

                               Keys -> (list)
                                   The key of the column to be joined.

                                   (list)
                                      (string)

                     SplitFields -> (structure)
                        Specifies  a  transform that splits data property keys
                        into two DynamicFrames . The output is a collection of
                        DynamicFrames  : one with selected data property keys,
                        and one with the remaining data property keys.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Paths -> (list)
                            A JSON path to a variable in the data structure.

                            (list)
                               (string)

                     SelectFromCollection -> (structure)
                        Specifies a transform that  chooses  one  DynamicFrame
                        from a collection of DynamicFrames . The output is the
                        selected DynamicFrame

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Index -> (integer)
                            The index for the DynamicFrame to be selected.

                     FillMissingValues -> (structure)
                        Specifies a transform  that  locates  records  in  the
                        dataset  that have missing values and adds a new field
                        with a value determined by imputation. The input  data
                        set  is  used to train the machine learning model that
                        determines what the missing value should be.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        ImputedPath -> (string)
                            A JSON path to a variable in  the  data  structure
                            for the dataset that is imputed.

                        FilledPath -> (string)
                            A  JSON  path  to a variable in the data structure
                            for the dataset that is filled.

                     Filter -> (structure)
                        Specifies a transform that splits a dataset into  two,
                        based on a filter condition.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        LogicalOperator -> (string)
                            The  operator used to filter rows by comparing the
                            key value to a specified value.

                        Filters -> (list)
                            Specifies a filter expression.

                            (structure)
                               Specifies a filter expression.

                               Operation -> (string)
                                   The type of operation to perform in the ex-
                                   pression.

                               Negated -> (boolean)
                                   Whether the expression is to be negated.

                               Values -> (list)
                                   A list of filter values.

                                   (structure)
                                      Represents a single entry in the list of
                                      values for a FilterExpression .

                                      Type -> (string)
                                          The type of filter value.

                                      Value -> (list)
                                          The value to be associated.

                                          (string)

                     CustomCode -> (structure)
                        Specifies a transform that uses custom code  you  pro-
                        vide to perform the data transformation. The output is
                        a collection of DynamicFrames.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Code -> (string)
                            The custom code that is used to perform  the  data
                            transformation.

                        ClassName -> (string)
                            The name defined for the custom code node class.

                        OutputSchemas -> (list)
                            Specifies  the  data  schema  for  the custom code
                            transform.

                            (structure)
                               Specifies a user-defined schema when  a  schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies  the column definitions that make
                                   up a Glue schema.

                                   (structure)
                                      Specifies a  single  column  in  a  Glue
                                      schema definition.

                                      Name -> (string)
                                          The  name  of the column in the Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     SparkSQL -> (structure)
                        Specifies  a transform where you enter a SQL query us-
                        ing Spark SQL syntax to transform the data. The output
                        is a single DynamicFrame .

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The  data  inputs  identified by their node names.
                            You can associate a table  name  with  each  input
                            node  to use in the SQL query. The name you choose
                            must meet the Spark SQL naming restrictions.

                            (string)

                        SqlQuery -> (string)
                            A SQL query that must use Spark SQL syntax and re-
                            turn a single data set.

                        SqlAliases -> (list)
                            A  list of aliases. An alias allows you to specify
                            what name to use in the SQL for a given input. For
                            example,  you  have  a  datasource  named "MyData-
                            Source". If you specify From as MyDataSource,  and
                            Alias as SqlName, then in your SQL you can do:
                               select * from SqlName

                            and that gets data from MyDataSource.

                            (structure)
                               Represents a single entry in the list of values
                               for SqlAliases .

                               From -> (string)
                                   A table, or a column in a table.

                               Alias -> (string)
                                   A temporary name given to  a  table,  or  a
                                   column in a table.

                        OutputSchemas -> (list)
                            Specifies  the data schema for the SparkSQL trans-
                            form.

                            (structure)
                               Specifies a user-defined schema when  a  schema
                               cannot be determined by AWS Glue.

                               Columns -> (list)
                                   Specifies  the column definitions that make
                                   up a Glue schema.

                                   (structure)
                                      Specifies a  single  column  in  a  Glue
                                      schema definition.

                                      Name -> (string)
                                          The  name  of the column in the Glue
                                          Studio schema.

                                      Type -> (string)
                                          The hive type for this column in the
                                          Glue Studio schema.

                     DirectKinesisSource -> (structure)
                        Specifies a direct Amazon Kinesis data source.

                        Name -> (string)
                            The name of the data source.

                        WindowSize -> (integer)
                            The  amount of time to spend processing each micro
                            batch.

                        DetectSchema -> (boolean)
                            Whether to automatically determine the schema from
                            the incoming data.

                        StreamingOptions -> (structure)
                            Additional  options for the Kinesis streaming data
                            source.

                            EndpointUrl -> (string)
                               The URL of the Kinesis endpoint.

                            StreamName -> (string)
                               The name of the Kinesis data stream.

                            Classification -> (string)
                               An optional classification.

                            Delimiter -> (string)
                               Specifies the delimiter character.

                            StartingPosition -> (string)
                               The  starting  position  in  the  Kinesis  data
                               stream  to  read data from. The possible values
                               are "latest" , "trim_horizon" , or "earliest" .
                               The default value is "latest" .

                            MaxFetchTimeInMs -> (long)
                               The  maximum  time spent in the job executor to
                               fetch a record from the Kinesis data stream per
                               shard,  specified in milliseconds (ms). The de-
                               fault value is 1000 .

                            MaxFetchRecordsPerShard -> (long)
                               The maximum number  of  records  to  fetch  per
                               shard  in  the Kinesis data stream. The default
                               value is 100000 .

                            MaxRecordPerRead -> (long)
                               The maximum number of records to fetch from the
                               Kinesis  data  stream in each getRecords opera-
                               tion. The default value is 10000 .

                            AddIdleTimeBetweenReads -> (boolean)
                               Adds a time delay between two  consecutive  ge-
                               tRecords   operations.  The  default  value  is
                               "False" . This option is only configurable  for
                               Glue version 2.0 and above.

                            IdleTimeBetweenReadsInMs -> (long)
                               The  minimum time delay between two consecutive
                               getRecords operations, specified in ms. The de-
                               fault  value is 1000 . This option is only con-
                               figurable for Glue version 2.0 and above.

                            DescribeShardInterval -> (long)
                               The minimum time  interval  between  two  List-
                               Shards  API  calls  for your script to consider
                               resharding. The default value is 1s .

                            NumRetries -> (integer)
                               The maximum number of retries for Kinesis  Data
                               Streams API requests. The default value is 3 .

                            RetryIntervalMs -> (long)
                               The  cool-off time period (specified in ms) be-
                               fore retrying  the  Kinesis  Data  Streams  API
                               call. The default value is 1000 .

                            MaxRetryIntervalMs -> (long)
                               The  maximum cool-off time period (specified in
                               ms) between  two  retries  of  a  Kinesis  Data
                               Streams API call. The default value is 10000 .

                            AvoidEmptyBatches -> (boolean)
                               Avoids  creating  an  empty  microbatch  job by
                               checking for unread data in  the  Kinesis  data
                               stream before the batch is started. The default
                               value is "False" .

                            StreamArn -> (string)
                               The Amazon Resource Name (ARN) of  the  Kinesis
                               data stream.

                            RoleArn -> (string)
                               The  Amazon  Resource Name (ARN) of the role to
                               assume using AWS Security  Token  Service  (AWS
                               STS).  This  role must have permissions for de-
                               scribe or read record operations for the  Kine-
                               sis  data  stream.  You must use this parameter
                               when accessing a data stream in a different ac-
                               count. Used in conjunction with "awsSTSSession-
                               Name" .

                            RoleSessionName -> (string)
                               An identifier for the session assuming the role
                               using AWS STS. You must use this parameter when
                               accessing a data stream in a different account.
                               Used in conjunction with "awsSTSRoleARN" .

                        DataPreviewOptions -> (structure)
                            Additional options for data preview.

                            PollingTime -> (long)
                               The polling time in milliseconds.

                            RecordPollingLimit -> (long)
                               The limit to the number of records polled.

                     DirectKafkaSource -> (structure)
                        Specifies an Apache Kafka data store.

                        Name -> (string)
                            The name of the data store.

                        StreamingOptions -> (structure)
                            Specifies the streaming options.

                            BootstrapServers -> (string)
                               A  list  of bootstrap server URLs, for example,
                               as
                               b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.ama-
                               zonaws.com:9094 . This option must be specified
                               in  the  API call or defined in the table meta-
                               data in the Data Catalog.

                            SecurityProtocol -> (string)
                               The protocol used to communicate with  brokers.
                               The possible values are "SSL" or "PLAINTEXT" .

                            ConnectionName -> (string)
                               The name of the connection.

                            TopicName -> (string)
                               The  topic  name  as specified in Apache Kafka.
                               You must specify at least one of "topicName"  ,
                               "assign" or "subscribePattern" .

                            Assign -> (string)
                               The  specific  TopicPartitions  to consume. You
                               must specify at least one of "topicName" , "as-
                               sign" or "subscribePattern" .

                            SubscribePattern -> (string)
                               A  Java  regex string that identifies the topic
                               list to subscribe to. You must specify at least
                               one of "topicName" , "assign" or "subscribePat-
                               tern" .

                            Classification -> (string)
                               An optional classification.

                            Delimiter -> (string)
                               Specifies the delimiter character.

                            StartingOffsets -> (string)
                               The starting position in  the  Kafka  topic  to
                               read data from. The possible values are "earli-
                               est" or "latest" . The default value  is  "lat-
                               est" .

                            EndingOffsets -> (string)
                               The end point when a batch query is ended. Pos-
                               sible values are  either  "latest"  or  a  JSON
                               string that specifies an ending offset for each
                               TopicPartition .

                            PollTimeoutMs -> (long)
                               The timeout in milliseconds to poll  data  from
                               Kafka in Spark job executors. The default value
                               is 512 .

                            NumRetries -> (integer)
                               The number of times to retry before failing  to
                               fetch Kafka offsets. The default value is 3 .

                            RetryIntervalMs -> (long)
                               The  time in milliseconds to wait before retry-
                               ing to fetch Kafka offsets. The  default  value
                               is 10 .

                            MaxOffsetsPerTrigger -> (long)
                               The rate limit on the maximum number of offsets
                               that are processed per  trigger  interval.  The
                               specified  total  number  of offsets is propor-
                               tionally split across topicPartitions  of  dif-
                               ferent  volumes.  The  default  value  is null,
                               which means that the consumer reads all offsets
                               until the known latest offset.

                            MinPartitions -> (integer)
                               The  desired  minimum  number  of partitions to
                               read from Kafka. The  default  value  is  null,
                               which means that the number of spark partitions
                               is equal to the number of Kafka partitions.

                        WindowSize -> (integer)
                            The amount of time to spend processing each  micro
                            batch.

                        DetectSchema -> (boolean)
                            Whether to automatically determine the schema from
                            the incoming data.

                        DataPreviewOptions -> (structure)
                            Specifies options  related  to  data  preview  for
                            viewing a sample of your data.

                            PollingTime -> (long)
                               The polling time in milliseconds.

                            RecordPollingLimit -> (long)
                               The limit to the number of records polled.

                     CatalogKinesisSource -> (structure)
                        Specifies a Kinesis data source in the Glue Data Cata-
                        log.

                        Name -> (string)
                            The name of the data source.

                        WindowSize -> (integer)
                            The amount of time to spend processing each  micro
                            batch.

                        DetectSchema -> (boolean)
                            Whether to automatically determine the schema from
                            the incoming data.

                        Table -> (string)
                            The name of the table  in  the  database  to  read
                            from.

                        Database -> (string)
                            The name of the database to read from.

                        StreamingOptions -> (structure)
                            Additional  options for the Kinesis streaming data
                            source.

                            EndpointUrl -> (string)
                               The URL of the Kinesis endpoint.

                            StreamName -> (string)
                               The name of the Kinesis data stream.

                            Classification -> (string)
                               An optional classification.

                            Delimiter -> (string)
                               Specifies the delimiter character.

                            StartingPosition -> (string)
                               The  starting  position  in  the  Kinesis  data
                               stream  to  read data from. The possible values
                               are "latest" , "trim_horizon" , or "earliest" .
                               The default value is "latest" .

                            MaxFetchTimeInMs -> (long)
                               The  maximum  time spent in the job executor to
                               fetch a record from the Kinesis data stream per
                               shard,  specified in milliseconds (ms). The de-
                               fault value is 1000 .

                            MaxFetchRecordsPerShard -> (long)
                               The maximum number  of  records  to  fetch  per
                               shard  in  the Kinesis data stream. The default
                               value is 100000 .

                            MaxRecordPerRead -> (long)
                               The maximum number of records to fetch from the
                               Kinesis  data  stream in each getRecords opera-
                               tion. The default value is 10000 .

                            AddIdleTimeBetweenReads -> (boolean)
                               Adds a time delay between two  consecutive  ge-
                               tRecords   operations.  The  default  value  is
                               "False" . This option is only configurable  for
                               Glue version 2.0 and above.

                            IdleTimeBetweenReadsInMs -> (long)
                               The  minimum time delay between two consecutive
                               getRecords operations, specified in ms. The de-
                               fault  value is 1000 . This option is only con-
                               figurable for Glue version 2.0 and above.

                            DescribeShardInterval -> (long)
                               The minimum time  interval  between  two  List-
                               Shards  API  calls  for your script to consider
                               resharding. The default value is 1s .

                            NumRetries -> (integer)
                               The maximum number of retries for Kinesis  Data
                               Streams API requests. The default value is 3 .

                            RetryIntervalMs -> (long)
                               The  cool-off time period (specified in ms) be-
                               fore retrying  the  Kinesis  Data  Streams  API
                               call. The default value is 1000 .

                            MaxRetryIntervalMs -> (long)
                               The  maximum cool-off time period (specified in
                               ms) between  two  retries  of  a  Kinesis  Data
                               Streams API call. The default value is 10000 .

                            AvoidEmptyBatches -> (boolean)
                               Avoids  creating  an  empty  microbatch  job by
                               checking for unread data in  the  Kinesis  data
                               stream before the batch is started. The default
                               value is "False" .

                            StreamArn -> (string)
                               The Amazon Resource Name (ARN) of  the  Kinesis
                               data stream.

                            RoleArn -> (string)
                               The  Amazon  Resource Name (ARN) of the role to
                               assume using AWS Security  Token  Service  (AWS
                               STS).  This  role must have permissions for de-
                               scribe or read record operations for the  Kine-
                               sis  data  stream.  You must use this parameter
                               when accessing a data stream in a different ac-
                               count. Used in conjunction with "awsSTSSession-
                               Name" .

                            RoleSessionName -> (string)
                               An identifier for the session assuming the role
                               using AWS STS. You must use this parameter when
                               accessing a data stream in a different account.
                               Used in conjunction with "awsSTSRoleARN" .

                        DataPreviewOptions -> (structure)
                            Additional options for data preview.

                            PollingTime -> (long)
                               The polling time in milliseconds.

                            RecordPollingLimit -> (long)
                               The limit to the number of records polled.

                     CatalogKafkaSource -> (structure)
                        Specifies an Apache Kafka data store in the Data Cata-
                        log.

                        Name -> (string)
                            The name of the data store.

                        WindowSize -> (integer)
                            The amount of time to spend processing each  micro
                            batch.

                        DetectSchema -> (boolean)
                            Whether to automatically determine the schema from
                            the incoming data.

                        Table -> (string)
                            The name of the table  in  the  database  to  read
                            from.

                        Database -> (string)
                            The name of the database to read from.

                        StreamingOptions -> (structure)
                            Specifies the streaming options.

                            BootstrapServers -> (string)
                               A  list  of bootstrap server URLs, for example,
                               as
                               b-1.vpc-test-2.o4q88o.c6.kafka.us-east-1.ama-
                               zonaws.com:9094 . This option must be specified
                               in  the  API call or defined in the table meta-
                               data in the Data Catalog.

                            SecurityProtocol -> (string)
                               The protocol used to communicate with  brokers.
                               The possible values are "SSL" or "PLAINTEXT" .

                            ConnectionName -> (string)
                               The name of the connection.

                            TopicName -> (string)
                               The  topic  name  as specified in Apache Kafka.
                               You must specify at least one of "topicName"  ,
                               "assign" or "subscribePattern" .

                            Assign -> (string)
                               The  specific  TopicPartitions  to consume. You
                               must specify at least one of "topicName" , "as-
                               sign" or "subscribePattern" .

                            SubscribePattern -> (string)
                               A  Java  regex string that identifies the topic
                               list to subscribe to. You must specify at least
                               one of "topicName" , "assign" or "subscribePat-
                               tern" .

                            Classification -> (string)
                               An optional classification.

                            Delimiter -> (string)
                               Specifies the delimiter character.

                            StartingOffsets -> (string)
                               The starting position in  the  Kafka  topic  to
                               read data from. The possible values are "earli-
                               est" or "latest" . The default value  is  "lat-
                               est" .

                            EndingOffsets -> (string)
                               The end point when a batch query is ended. Pos-
                               sible values are  either  "latest"  or  a  JSON
                               string that specifies an ending offset for each
                               TopicPartition .

                            PollTimeoutMs -> (long)
                               The timeout in milliseconds to poll  data  from
                               Kafka in Spark job executors. The default value
                               is 512 .

                            NumRetries -> (integer)
                               The number of times to retry before failing  to
                               fetch Kafka offsets. The default value is 3 .

                            RetryIntervalMs -> (long)
                               The  time in milliseconds to wait before retry-
                               ing to fetch Kafka offsets. The  default  value
                               is 10 .

                            MaxOffsetsPerTrigger -> (long)
                               The rate limit on the maximum number of offsets
                               that are processed per  trigger  interval.  The
                               specified  total  number  of offsets is propor-
                               tionally split across topicPartitions  of  dif-
                               ferent  volumes.  The  default  value  is null,
                               which means that the consumer reads all offsets
                               until the known latest offset.

                            MinPartitions -> (integer)
                               The  desired  minimum  number  of partitions to
                               read from Kafka. The  default  value  is  null,
                               which means that the number of spark partitions
                               is equal to the number of Kafka partitions.

                        DataPreviewOptions -> (structure)
                            Specifies options  related  to  data  preview  for
                            viewing a sample of your data.

                            PollingTime -> (long)
                               The polling time in milliseconds.

                            RecordPollingLimit -> (long)
                               The limit to the number of records polled.

                     DropNullFields -> (structure)
                        Specifies  a  transform  that removes columns from the
                        dataset if all values in the column are 'null'. By de-
                        fault,  Glue  Studio  will recognize null objects, but
                        some values such as empty strings,  strings  that  are
                        "null",  -1 integers or other placeholders such as ze-
                        ros, are not automatically recognized as nulls.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        NullCheckBoxList -> (structure)
                            A structure that represents whether certain values
                            are recognized as null values for removal.

                            IsEmpty -> (boolean)
                               Specifies that an empty string is considered as
                               a null value.

                            IsNullString -> (boolean)
                               Specifies that a value spelling  out  the  word
                               'null' is considered as a null value.

                            IsNegOne -> (boolean)
                               Specifies  that  an integer value of -1 is con-
                               sidered as a null value.

                        NullTextList -> (list)
                            A structure that specifies a  list  of  NullValue-
                            Field  structures  that  represent  a  custom null
                            value such as zero or other value being used as  a
                            null placeholder unique to the dataset.

                            The  DropNullFields  transform removes custom null
                            values only if both the value of the  null  place-
                            holder and the datatype match the data.

                            (structure)
                               Represents  a custom null value such as a zeros
                               or other value being used as a null placeholder
                               unique to the dataset.

                               Value -> (string)
                                   The value of the null placeholder.

                               Datatype -> (structure)
                                   The datatype of the value.

                                   Id -> (string)
                                      The datatype of the value.

                                   Label -> (string)
                                      A label assigned to the datatype.

                     Merge -> (structure)
                        Specifies  a transform that merges a DynamicFrame with
                        a staging DynamicFrame based on the specified  primary
                        keys  to  identify records. Duplicate records (records
                        with the same primary keys) are not de-duplicated.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Source -> (string)
                            The source DynamicFrame that will be merged with a
                            staging DynamicFrame .

                        PrimaryKeys -> (list)
                            The  list  of  primary key fields to match records
                            from the source and staging dynamic frames.

                            (list)
                               (string)

                     Union -> (structure)
                        Specifies a transform that combines the rows from  two
                        or more datasets into a single result.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The node ID inputs to the transform.

                            (string)

                        UnionType -> (string)
                            Indicates the type of Union transform.

                            Specify  ALL to join all rows from data sources to
                            the resulting DynamicFrame.  The  resulting  union
                            does not remove duplicate rows.

                            Specify  DISTINCT  to remove duplicate rows in the
                            resulting DynamicFrame.

                     PIIDetection -> (structure)
                        Specifies a  transform  that  identifies,  removes  or
                        masks PII data.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The node ID inputs to the transform.

                            (string)

                        PiiType -> (string)
                            Indicates the type of PIIDetection transform.

                        EntityTypesToDetect -> (list)
                            Indicates  the  types of entities the PIIDetection
                            transform will identify as PII data.

                            PII  type  entities  include:  PERSON_NAME,  DATE,
                            USA_SNN,   EMAIL,  USA_ITIN,  USA_PASSPORT_NUMBER,
                            PHONE_NUMBER,  BANK_ACCOUNT,  IP_ADDRESS,  MAC_AD-
                            DRESS,   USA_CPT_CODE,   USA_HCPCS_CODE,   USA_NA-
                            TIONAL_DRUG_CODE, USA_MEDICARE_BENEFICIARY_IDENTI-
                            FIER,              USA_HEALTH_INSURANCE_CLAIM_NUM-
                            BER,CREDIT_CARD,USA_NATIONAL_PROVIDER_IDENTI-
                            FIER,USA_DEA_NUMBER,USA_DRIVING_LICENSE

                            (string)

                        OutputColumnName -> (string)
                            Indicates the output column name that will contain
                            any entity type detected in that row.

                        SampleFraction -> (double)
                            Indicates the fraction of the data to sample  when
                            scanning for PII entities.

                        ThresholdFraction -> (double)
                            Indicates  the  fraction  of the data that must be
                            met in order for a column to be identified as  PII
                            data.

                        MaskValue -> (string)
                            Indicates the value that will replace the detected
                            entity.

                     Aggregate -> (structure)
                        Specifies a  transform  that  groups  rows  by  chosen
                        fields  and computes the aggregated value by specified
                        function.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            Specifies the fields and rows to use as inputs for
                            the aggregate transform.

                            (string)

                        Groups -> (list)
                            Specifies the fields to group by.

                            (list)
                               (string)

                        Aggs -> (list)
                            Specifies  the aggregate functions to be performed
                            on specified fields.

                            (structure)
                               Specifies the set of parameters needed to  per-
                               form aggregation in the aggregate transform.

                               Column -> (list)
                                   Specifies  the  column  on  the data set on
                                   which the aggregation function will be  ap-
                                   plied.

                                   (string)

                               AggFunc -> (string)
                                   Specifies  the  aggregation function to ap-
                                   ply.

                                   Possible aggregation functions include: avg
                                   countDistinct,  count,  first, last, kurto-
                                   sis, max, min, skewness, stddev_samp,  std-
                                   dev_pop,    sum,   sumDistinct,   var_samp,
                                   var_pop

                     DropDuplicates -> (structure)
                        Specifies a transform that removes rows  of  repeating
                        data from a data set.

                        Name -> (string)
                            The name of the transform node.

                        Inputs -> (list)
                            The data inputs identified by their node names.

                            (string)

                        Columns -> (list)
                            The name of the columns to be merged or removed if
                            repeating.

                            (list)
                               (string)

                     GovernedCatalogTarget -> (structure)
                        Specifies a data target that  writes  to  a  goverened
                        catalog.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        PartitionKeys -> (list)
                            Specifies  native partitioning using a sequence of
                            keys.

                            (list)
                               (string)

                        Table -> (string)
                            The name of the table in the database to write to.

                        Database -> (string)
                            The name of the database to write to.

                        SchemaChangePolicy -> (structure)
                            A policy that specifies update  behavior  for  the
                            governed catalog.

                            EnableUpdateCatalog -> (boolean)
                               Whether  to  use  the specified update behavior
                               when the crawler finds a changed schema.

                            UpdateBehavior -> (string)
                               The update behavior when the  crawler  finds  a
                               changed schema.

                     GovernedCatalogSource -> (structure)
                        Specifies a data source in a goverened Data Catalog.

                        Name -> (string)
                            The name of the data store.

                        Database -> (string)
                            The database to read from.

                        Table -> (string)
                            The database table to read from.

                        PartitionPredicate -> (string)
                            Partitions  satisfying this predicate are deleted.
                            Files within the retention period in these  parti-
                            tions  are  not  deleted.  Set to ""  empty by de-
                            fault.

                        AdditionalOptions -> (structure)
                            Specifies additional connection options.

                            BoundedSize -> (long)
                               Sets the upper limit for the target size of the
                               dataset in bytes that will be processed.

                            BoundedFiles -> (long)
                               Sets  the  upper limit for the target number of
                               files that will be processed.

                     MicrosoftSQLServerCatalogSource -> (structure)
                        Specifies a Microsoft SQL server data  source  in  the
                        Glue Data Catalog.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     MySQLCatalogSource -> (structure)
                        Specifies a MySQL data source in the Glue  Data  Cata-
                        log.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     OracleSQLCatalogSource -> (structure)
                        Specifies an Oracle data source in the Glue Data Cata-
                        log.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     PostgreSQLCatalogSource -> (structure)
                        Specifies a PostgresSQL data source in the  Glue  Data
                        Catalog.

                        Name -> (string)
                            The name of the data source.

                        Database -> (string)
                            The name of the database to read from.

                        Table -> (string)
                            The  name  of  the  table  in the database to read
                            from.

                     MicrosoftSQLServerCatalogTarget -> (structure)
                        Specifies a target that uses Microsoft SQL.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The name of the database to write to.

                        Table -> (string)
                            The name of the table in the database to write to.

                     MySQLCatalogTarget -> (structure)
                        Specifies a target that uses MySQL.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The name of the database to write to.

                        Table -> (string)
                            The name of the table in the database to write to.

                     OracleSQLCatalogTarget -> (structure)
                        Specifies a target that uses Oracle SQL.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The name of the database to write to.

                        Table -> (string)
                            The name of the table in the database to write to.

                     PostgreSQLCatalogTarget -> (structure)
                        Specifies a target that uses Postgres SQL.

                        Name -> (string)
                            The name of the data target.

                        Inputs -> (list)
                            The nodes that are inputs to the data target.

                            (string)

                        Database -> (string)
                            The name of the database to write to.

                        Table -> (string)
                            The name of the table in the database to write to.

              ExecutionClass -> (string)
                 Indicates whether the job is run with a standard or  flexible
                 execution  class.  The  standard execution class is ideal for
                 time-sensitive workloads that require fast  job  startup  and
                 dedicated resources.

                 The flexible execution class is appropriate for time-insensi-
                 tive jobs whose start and completion times may vary.

                 Only jobs with Glue version 3.0 and above  and  command  type
                 glueetl  will  be allowed to set ExecutionClass to FLEX . The
                 flexible execution class is available for Spark jobs.

       JobsNotFound -> (list)
          A list of names of jobs not found.

          (string)



                                                              BATCH-GET-JOBS()
