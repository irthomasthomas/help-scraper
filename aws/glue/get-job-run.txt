GET-JOB-RUN()                                                    GET-JOB-RUN()



NAME
       get-job-run -

DESCRIPTION
       Retrieves the metadata for a given job run.

       See also: AWS API Documentation

SYNOPSIS
            get-job-run
          --job-name <value>
          --run-id <value>
          [--predecessors-included | --no-predecessors-included]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --job-name (string)
          Name of the job definition being run.

       --run-id (string)
          The ID of the job run.

       --predecessors-included | --no-predecessors-included (boolean)
          True if a list of predecessor runs should be returned.

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do not sign requests. Credentials will not be loaded if  this  argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The maximum socket read time in seconds. If the value is set to 0,  the
       socket  read  will be blocking and not timeout. The default value is 60
       seconds.

       --cli-connect-timeout (int)

       The maximum socket connect time in seconds. If the value is set  to  0,
       the  socket connect will be blocking and not timeout. The default value
       is 60 seconds.

EXAMPLES
       NOTE:
          To use the following examples, you must have the AWS  CLI  installed
          and  configured.  See  the Getting started guide in the AWS CLI User
          Guide for more information.

          Unless otherwise  stated,  all  examples  have  unix-like  quotation
          rules.  These  examples  will  need to be adapted to your terminal's
          quoting rules. See Using quotation marks with strings in the AWS CLI
          User Guide .

       To get information about a job run

       The  following  get-job-run  example  retrieves information about a job
       run.

          aws glue get-job-run \
              --job-name "Combine legistators data" \
              --run-id jr_012e176506505074d94d761755e5c62538ee1aad6f17d39f527e9140cf0c9a5e

       Output:

          {
              "JobRun": {
                  "Id": "jr_012e176506505074d94d761755e5c62538ee1aad6f17d39f527e9140cf0c9a5e",
                  "Attempt": 0,
                  "JobName": "Combine legistators data",
                  "StartedOn": 1602873931.255,
                  "LastModifiedOn": 1602874075.985,
                  "CompletedOn": 1602874075.985,
                  "JobRunState": "SUCCEEDED",
                  "Arguments": {
                      "--enable-continuous-cloudwatch-log": "true",
                      "--enable-metrics": "",
                      "--enable-spark-ui": "true",
                      "--job-bookmark-option": "job-bookmark-enable",
                      "--spark-event-logs-path": "s3://aws-glue-assets-111122223333-us-east-1/sparkHistoryLogs/"
                  },
                  "PredecessorRuns": [],
                  "AllocatedCapacity": 10,
                  "ExecutionTime": 117,
                  "Timeout": 2880,
                  "MaxCapacity": 10.0,
                  "WorkerType": "G.1X",
                  "NumberOfWorkers": 10,
                  "LogGroupName": "/aws-glue/jobs",
                  "GlueVersion": "2.0"
              }
          }

       For more information, see Job Runs in the AWS Glue Developer Guide.

OUTPUT
       JobRun -> (structure)
          The requested job-run metadata.

          Id -> (string)
              The ID of this job run.

          Attempt -> (integer)
              The number of the attempt to run this job.

          PreviousRunId -> (string)
              The ID of the previous run of this job.  For  example,  the  Jo-
              bRunId specified in the StartJobRun action.

          TriggerName -> (string)
              The name of the trigger that started this job run.

          JobName -> (string)
              The name of the job definition being used in this run.

          StartedOn -> (timestamp)
              The date and time at which this job run was started.

          LastModifiedOn -> (timestamp)
              The last time that this job run was modified.

          CompletedOn -> (timestamp)
              The date and time that this job run completed.

          JobRunState -> (string)
              The current state of the job run. For more information about the
              statuses of jobs that have terminated abnormally, see  Glue  Job
              Run Statuses .

          Arguments -> (map)
              The  job  arguments  associated with this run. For this job run,
              they replace the default arguments set in the job definition it-
              self.

              You  can  specify  arguments  here  that  your own job-execution
              script consumes, as well as arguments that Glue itself consumes.

              Job arguments may be logged. Do not pass  plaintext  secrets  as
              arguments. Retrieve secrets from a Glue Connection, Secrets Man-
              ager or other secret management mechanism if you intend to  keep
              them within the Job.

              For  information  about  how to specify and consume your own Job
              arguments, see the Calling Glue APIs in Python topic in the  de-
              veloper guide.

              For  information  about  the  arguments  you can provide to this
              field when configuring Spark jobs, see  the  Special  Parameters
              Used by Glue topic in the developer guide.

              For  information  about  the  arguments  you can provide to this
              field when configuring Ray jobs, see Using job parameters in Ray
              jobs in the developer guide.

              key -> (string)

              value -> (string)

          ErrorMessage -> (string)
              An error message associated with this job run.

          PredecessorRuns -> (list)
              A list of predecessors to this job run.

              (structure)
                 A  job  run  that  was used in the predicate of a conditional
                 trigger that triggered this job run.

                 JobName -> (string)
                     The name of the job definition used  by  the  predecessor
                     job run.

                 RunId -> (string)
                     The job-run ID of the predecessor job run.

          AllocatedCapacity -> (integer)
              This field is deprecated. Use MaxCapacity instead.

              The  number  of  Glue  data processing units (DPUs) allocated to
              this JobRun. From 2 to 100 DPUs can be allocated; the default is
              10.  A  DPU  is a relative measure of processing power that con-
              sists of 4 vCPUs of compute capacity and 16 GB  of  memory.  For
              more information, see the Glue pricing page .

          ExecutionTime -> (integer)
              The  amount  of  time (in seconds) that the job run consumed re-
              sources.

          Timeout -> (integer)
              The JobRun timeout in minutes. This is the maximum time  that  a
              job run can consume resources before it is terminated and enters
              TIMEOUT status. This value overrides the timeout  value  set  in
              the parent job.

              The  maximum value for timeout for batch jobs is 7 days or 10080
              minutes. The default is 2880 minutes (48 hours) for batch jobs.

              Any existing Glue jobs that have a greater timeout value are de-
              faulted  to 7 days. For instance you have specified a timeout of
              20 days for a batch job, it will be stopped on the 7th day.

              Streaming jobs must have timeout values  less  than  7  days  or
              10080  minutes.  When  the  value is left blank, the job will be
              restarted after 7 days based if you have not setup a maintenance
              window.  If  you  have  setup  maintenance  window,  it  will be
              restarted during the maintenance window after 7 days.

          MaxCapacity -> (double)
              For Glue version 1.0 or earlier jobs, using the standard  worker
              type,  the  number of Glue data processing units (DPUs) that can
              be allocated when this job runs. A DPU is a relative measure  of
              processing  power  that  consists of 4 vCPUs of compute capacity
              and 16 GB of memory. For more information, see the Glue  pricing
              page .

              For  Glue version 2.0+ jobs, you cannot specify a Maximum capac-
              ity . Instead, you should specify a Worker type and  the  Number
              of workers .

              Do not set MaxCapacity if using WorkerType and NumberOfWorkers .

              The  value  that  can  be  allocated  for MaxCapacity depends on
              whether you are running a Python shell job, an Apache Spark  ETL
              job, or an Apache Spark streaming ETL job:

              o When you specify a Python shell job (JobCommand.Name ="python-
                shell"), you can allocate either 0.0625 or 1 DPU. The  default
                is 0.0625 DPU.

              o When  you  specify  an  Apache  Spark ETL job (JobCommand.Name
                ="glueetl") or Apache Spark streaming ETL job (JobCommand.Name
                ="gluestreaming"),  you  can  allocate from 2 to 100 DPUs. The
                default is 10 DPUs. This job type cannot have a fractional DPU
                allocation.

          WorkerType -> (string)
              The type of predefined worker that is allocated when a job runs.
              Accepts a value of G.1X, G.2X, G.4X, G.8X or  G.025X  for  Spark
              jobs. Accepts the value Z.2X for Ray jobs.

              o For  the G.1X worker type, each worker maps to 1 DPU (4 vCPUs,
                16 GB of memory) with 84GB disk (approximately 34GB free), and
                provides  1 executor per worker. We recommend this worker type
                for workloads such as data transforms, joins, and queries,  to
                offers a scalable and cost effective way to run most jobs.

              o For  the G.2X worker type, each worker maps to 2 DPU (8 vCPUs,
                32 GB of memory) with 128GB disk  (approximately  77GB  free),
                and  provides  1 executor per worker. We recommend this worker
                type  for  workloads  such  as  data  transforms,  joins,  and
                queries,  to  offers  a scalable and cost effective way to run
                most jobs.

              o For the G.4X worker type, each worker maps to 4 DPU (16 vCPUs,
                64  GB  of memory) with 256GB disk (approximately 235GB free),
                and provides 1 executor per worker. We recommend  this  worker
                type  for  jobs  whose  workloads  contain your most demanding
                transforms, aggregations, joins, and queries. This worker type
                is available only for Glue version 3.0 or later Spark ETL jobs
                in the following Amazon Web Services Regions: US East  (Ohio),
                US  East (N. Virginia), US West (Oregon), Asia Pacific (Singa-
                pore), Asia Pacific (Sydney),  Asia  Pacific  (Tokyo),  Canada
                (Central),  Europe  (Frankfurt),  Europe (Ireland), and Europe
                (Stockholm).

              o For the G.8X worker type, each worker maps to 8 DPU (32 vCPUs,
                128  GB of memory) with 512GB disk (approximately 487GB free),
                and provides 1 executor per worker. We recommend  this  worker
                type  for  jobs  whose  workloads  contain your most demanding
                transforms, aggregations, joins, and queries. This worker type
                is  available  only  for  Glue  version 3.0 or later Spark ETL
                jobs, in the same Amazon Web Services Regions as supported for
                the G.4X worker type.

              o For  the  G.025X  worker type, each worker maps to 0.25 DPU (2
                vCPUs, 4 GB of memory)  with  84GB  disk  (approximately  34GB
                free),  and  provides 1 executor per worker. We recommend this
                worker type for low volume streaming jobs. This worker type is
                only available for Glue version 3.0 streaming jobs.

              o For the Z.2X worker type, each worker maps to 2 M-DPU (8vCPUs,
                64 GB of memory) with 128 GB disk (approximately 120GB  free),
                and provides up to 8 Ray workers based on the autoscaler.

          NumberOfWorkers -> (integer)
              The number of workers of a defined workerType that are allocated
              when a job runs.

          SecurityConfiguration -> (string)
              The name of the SecurityConfiguration structure to be used  with
              this job run.

          LogGroupName -> (string)
              The  name  of  the  log  group  for  secure  logging that can be
              server-side encrypted in Amazon CloudWatch using KMS. This  name
              can be /aws-glue/jobs/ , in which case the default encryption is
              NONE . If you add a role name and SecurityConfiguration name (in
              other  words, /aws-glue/jobs-yourRoleName-yourSecurityConfigura-
              tionName/ ), then that security configuration is used to encrypt
              the log group.

          NotificationProperty -> (structure)
              Specifies configuration properties of a job run notification.

              NotifyDelayAfter -> (integer)
                 After  a job run starts, the number of minutes to wait before
                 sending a job run delay notification.

          GlueVersion -> (string)
              In Spark jobs, GlueVersion determines  the  versions  of  Apache
              Spark  and  Python that Glue available in a job. The Python ver-
              sion indicates the version supported for jobs of type Spark.

              Ray jobs should set GlueVersion to 4.0 or greater. However,  the
              versions  of  Ray,  Python and additional libraries available in
              your Ray job are determined by the Runtime parameter of the  Job
              command.

              For  more information about the available Glue versions and cor-
              responding Spark and Python versions, see Glue  version  in  the
              developer guide.

              Jobs  that are created without specifying a Glue version default
              to Glue 0.9.

          DPUSeconds -> (double)
              This field can be set for either job runs with  execution  class
              FLEX  or  when Auto Scaling is enabled, and represents the total
              time each executor ran during the lifecycle of a job run in sec-
              onds,  multiplied  by a DPU factor (1 for G.1X , 2 for G.2X , or
              0.25 for G.025X workers). This value may be different  than  the
              executionEngineRuntime  *  MaxCapacity  as  in  the case of Auto
              Scaling jobs, as the number of executors running at a given time
              may  be  less  than  the MaxCapacity . Therefore, it is possible
              that the value of DPUSeconds is less than executionEngineRuntime
              * MaxCapacity .

          ExecutionClass -> (string)
              Indicates whether the job is run with a standard or flexible ex-
              ecution  class.  The  standard  execution-class  is  ideal   for
              time-sensitive workloads that require fast job startup and dedi-
              cated resources.

              The flexible execution class is appropriate for time-insensitive
              jobs whose start and completion times may vary.

              Only  jobs  with  Glue  version  3.0  and above and command type
              glueetl will be allowed to set  ExecutionClass  to  FLEX  .  The
              flexible execution class is available for Spark jobs.

          MaintenanceWindow -> (string)
              This  field  specifies  a day of the week and hour for a mainte-
              nance window for  streaming  jobs.  Glue  periodically  performs
              maintenance  activities.  During these maintenance windows, Glue
              will need to restart your streaming jobs.

              Glue will restart the job within 3 hours of the specified  main-
              tenance window. For instance, if you set up the maintenance win-
              dow for Monday at 10:00AM GMT, your jobs will be  restarted  be-
              tween 10:00AM GMT to 1:00PM GMT.



                                                                 GET-JOB-RUN()
