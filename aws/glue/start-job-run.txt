START-JOB-RUN()                                                START-JOB-RUN()



NAME
       start-job-run -

DESCRIPTION
       Starts a job run using a job definition.

       See also: AWS API Documentation

SYNOPSIS
            start-job-run
          --job-name <value>
          [--job-run-id <value>]
          [--arguments <value>]
          [--allocated-capacity <value>]
          [--timeout <value>]
          [--max-capacity <value>]
          [--security-configuration <value>]
          [--notification-property <value>]
          [--worker-type <value>]
          [--number-of-workers <value>]
          [--execution-class <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --job-name (string)
          The name of the job definition to use.

       --job-run-id (string)
          The ID of a previous JobRun to retry.

       --arguments (map)
          The  job  arguments associated with this run. For this job run, they
          replace the default arguments set in the job definition itself.

          You can specify arguments here that your  own  job-execution  script
          consumes, as well as arguments that Glue itself consumes.

          Job  arguments may be logged. Do not pass plaintext secrets as argu-
          ments. Retrieve secrets from a Glue Connection, Secrets  Manager  or
          other  secret management mechanism if you intend to keep them within
          the Job.

          For information about how to specify and consume your own Job  argu-
          ments,  see  the  Calling Glue APIs in Python topic in the developer
          guide.

          For information about the arguments you can provide  to  this  field
          when configuring Spark jobs, see the Special Parameters Used by Glue
          topic in the developer guide.

          For information about the arguments you can provide  to  this  field
          when  configuring  Ray jobs, see Using job parameters in Ray jobs in
          the developer guide.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --allocated-capacity (integer)
          This field is deprecated. Use MaxCapacity instead.

          The number of Glue data processing units (DPUs) to allocate to  this
          JobRun.  You  can allocate a minimum of 2 DPUs; the default is 10. A
          DPU is a relative measure of processing power that consists of 4 vC-
          PUs  of  compute capacity and 16 GB of memory. For more information,
          see the Glue pricing page .

       --timeout (integer)
          The JobRun timeout in minutes. This is the maximum time that  a  job
          run can consume resources before it is terminated and enters TIMEOUT
          status. This value overrides the timeout value  set  in  the  parent
          job.

          Streaming  jobs  must  have timeout values less than 7 days or 10080
          minutes. When the value is left blank, the job will be restarted af-
          ter  7 days based if you have not setup a maintenance window. If you
          have setup maintenance window, it will be restarted during the main-
          tenance window after 7 days.

       --max-capacity (double)
          For  Glue  version  1.0  or  earlier jobs, using the standard worker
          type, the number of Glue data processing units (DPUs)  that  can  be
          allocated  when  this  job runs. A DPU is a relative measure of pro-
          cessing power that consists of 4 vCPUs of compute capacity and 16 GB
          of memory. For more information, see the Glue pricing page .

          For  Glue version 2.0+ jobs, you cannot specify a Maximum capacity .
          Instead, you should specify a Worker type and the Number of  workers
          .

          Do not set MaxCapacity if using WorkerType and NumberOfWorkers .

          The  value  that can be allocated for MaxCapacity depends on whether
          you are running a Python shell job, an Apache Spark ETL job,  or  an
          Apache Spark streaming ETL job:

          o When  you  specify  a  Python shell job (JobCommand.Name ="python-
            shell"), you can allocate either 0.0625 or 1 DPU. The  default  is
            0.0625 DPU.

          o When   you  specify  an  Apache  Spark  ETL  job  (JobCommand.Name
            ="glueetl") or Apache Spark  streaming  ETL  job  (JobCommand.Name
            ="gluestreaming"),  you  can  allocate from 2 to 100 DPUs. The de-
            fault is 10 DPUs. This job type cannot have a fractional DPU allo-
            cation.

       --security-configuration (string)
          The name of the SecurityConfiguration structure to be used with this
          job run.

       --notification-property (structure)
          Specifies configuration properties of a job run notification.

          NotifyDelayAfter -> (integer)
              After a job run starts, the number of  minutes  to  wait  before
              sending a job run delay notification.

       Shorthand Syntax:

          NotifyDelayAfter=integer

       JSON Syntax:

          {
            "NotifyDelayAfter": integer
          }

       --worker-type (string)
          The type of predefined worker that is allocated when a job runs. Ac-
          cepts a value of G.1X, G.2X, G.4X, G.8X or G.025X  for  Spark  jobs.
          Accepts the value Z.2X for Ray jobs.

          o For  the  G.1X worker type, each worker maps to 1 DPU (4 vCPUs, 16
            GB of memory) with 84GB disk (approximately 34GB free),  and  pro-
            vides  1  executor  per  worker. We recommend this worker type for
            workloads such as data transforms, joins, and queries, to offers a
            scalable and cost effective way to run most jobs.

          o For  the  G.2X worker type, each worker maps to 2 DPU (8 vCPUs, 32
            GB of memory) with 128GB disk (approximately 77GB free), and  pro-
            vides  1  executor  per  worker. We recommend this worker type for
            workloads such as data transforms, joins, and queries, to offers a
            scalable and cost effective way to run most jobs.

          o For  the G.4X worker type, each worker maps to 4 DPU (16 vCPUs, 64
            GB of memory) with 256GB disk (approximately 235GB free), and pro-
            vides  1  executor  per  worker. We recommend this worker type for
            jobs whose workloads contain your most demanding  transforms,  ag-
            gregations, joins, and queries. This worker type is available only
            for Glue version 3.0 or later Spark ETL jobs in the following Ama-
            zon  Web  Services Regions: US East (Ohio), US East (N. Virginia),
            US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney),
            Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe
            (Ireland), and Europe (Stockholm).

          o For the G.8X worker type, each worker maps to 8 DPU (32 vCPUs, 128
            GB of memory) with 512GB disk (approximately 487GB free), and pro-
            vides 1 executor per worker. We recommend  this  worker  type  for
            jobs  whose  workloads contain your most demanding transforms, ag-
            gregations, joins, and queries. This worker type is available only
            for  Glue  version 3.0 or later Spark ETL jobs, in the same Amazon
            Web Services Regions as supported for the G.4X worker type.

          o For the G.025X worker type, each worker maps to 0.25 DPU (2 vCPUs,
            4 GB of memory) with 84GB disk (approximately 34GB free), and pro-
            vides 1 executor per worker. We recommend this worker type for low
            volume streaming jobs. This worker type is only available for Glue
            version 3.0 streaming jobs.

          o For the Z.2X worker type, each worker maps to 2 M-DPU (8vCPUs,  64
            GB  of  memory)  with  128 GB disk (approximately 120GB free), and
            provides up to 8 Ray workers based on the autoscaler.

          Possible values:

          o Standard

          o G.1X

          o G.2X

          o G.025X

          o G.4X

          o G.8X

          o Z.2X

       --number-of-workers (integer)
          The number of workers of a defined  workerType  that  are  allocated
          when a job runs.

       --execution-class (string)
          Indicates  whether the job is run with a standard or flexible execu-
          tion class. The standard execution-class is ideal for time-sensitive
          workloads that require fast job startup and dedicated resources.

          The  flexible  execution  class  is appropriate for time-insensitive
          jobs whose start and completion times may vary.

          Only jobs with Glue version 3.0 and above and command  type  glueetl
          will  be allowed to set ExecutionClass to FLEX . The flexible execu-
          tion class is available for Spark jobs.

          Possible values:

          o FLEX

          o STANDARD

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By  default, the AWS CLI uses SSL when communicating with AWS services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

EXAMPLES
       NOTE:
          To  use  the following examples, you must have the AWS CLI installed
          and configured. See the Getting started guide in the  AWS  CLI  User
          Guide for more information.

          Unless  otherwise  stated,  all  examples  have  unix-like quotation
          rules. These examples will need to be  adapted  to  your  terminal's
          quoting rules. See Using quotation marks with strings in the AWS CLI
          User Guide .

       To start running a job

       The following start-job-run example starts a job.

          aws glue start-job-run \
              --job-name my-job

       Output:

          {
              "JobRunId": "jr_22208b1f44eb5376a60569d4b21dd20fcb8621e1a366b4e7b2494af764b82ded"
          }

       For more information, see Authoring Jobs  in  the  AWS  Glue  Developer
       Guide.

OUTPUT
       JobRunId -> (string)
          The ID assigned to this job run.



                                                               START-JOB-RUN()
