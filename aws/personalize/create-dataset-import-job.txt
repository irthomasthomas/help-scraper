CREATE-DATASET-IMPORT-JOB()                        CREATE-DATASET-IMPORT-JOB()



NAME
       create-dataset-import-job -

DESCRIPTION
       Creates a job that imports training data from your data source (an Ama-
       zon S3 bucket) to an Amazon Personalize dataset. To allow  Amazon  Per-
       sonalize  to  import the training data, you must specify an IAM service
       role that has permission to read from the data source, as  Amazon  Per-
       sonalize makes a copy of your data and processes it internally. For in-
       formation on granting access to your Amazon S3 bucket, see Giving  Ama-
       zon Personalize Access to Amazon S3 Resources .

       WARNING:
              By  default,  a dataset import job replaces any existing data in
              the dataset that you imported in bulk. To add new records  with-
              out  replacing existing data, specify INCREMENTAL for the import
              mode in the CreateDatasetImportJob operation.

          Status

       A dataset import job can be in one of the following states:

       o CREATE PENDING > CREATE IN_PROGRESS > ACTIVE -or- CREATE FAILED

       To get the status of the import job,  call  DescribeDatasetImportJob  ,
       providing the Amazon Resource Name (ARN) of the dataset import job. The
       dataset import is complete when the status shows as ACTIVE. If the sta-
       tus  shows as CREATE FAILED, the response includes a failureReason key,
       which describes why the job failed.

       NOTE:
              Importing takes time. You must wait until the  status  shows  as
              ACTIVE before training a model using the dataset.

          Related APIs

       o ListDatasetImportJobs

       o DescribeDatasetImportJob

       See also: AWS API Documentation

SYNOPSIS
            create-dataset-import-job
          --job-name <value>
          --dataset-arn <value>
          --data-source <value>
          --role-arn <value>
          [--tags <value>]
          [--import-mode <value>]
          [--publish-attribution-metrics-to-s3 | --no-publish-attribution-metrics-to-s3]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --job-name (string)
          The name for the dataset import job.

       --dataset-arn (string)
          The ARN of the dataset that receives the imported data.

       --data-source (structure)
          The Amazon S3 bucket that contains the training data to import.

          dataLocation -> (string)
              The path to the Amazon S3 bucket where the data that you want to
              upload to your dataset is stored. For example:
                 s3://bucket-name/folder-name/

       Shorthand Syntax:

          dataLocation=string

       JSON Syntax:

          {
            "dataLocation": "string"
          }

       --role-arn (string)
          The ARN of the IAM role that has permissions to read from the Amazon
          S3 data source.

       --tags (list)
          A list of tags to apply to the dataset import job.

          (structure)
              The  optional  metadata  that you apply to resources to help you
              categorize and organize them. Each tag consists of a key and  an
              optional  value,  both of which you define. For more information
              see Tagging Personalize resources .

              tagKey -> (string)
                 One part of a key-value pair that makes up a tag. A key is  a
                 general label that acts like a category for more specific tag
                 values.

              tagValue -> (string)
                 The optional part of a key-value pair that makes up a tag.  A
                 value acts as a descriptor within a tag category (key).

       Shorthand Syntax:

          tagKey=string,tagValue=string ...

       JSON Syntax:

          [
            {
              "tagKey": "string",
              "tagValue": "string"
            }
            ...
          ]

       --import-mode (string)
          Specify  how  to add the new records to an existing dataset. The de-
          fault import mode is FULL . If you  haven't  imported  bulk  records
          into the dataset previously, you can only specify FULL .

          o Specify  FULL to overwrite all existing bulk data in your dataset.
            Data you imported individually is not replaced.

          o Specify INCREMENTAL to append the new records to the existing data
            in  your  dataset. Amazon Personalize replaces any record with the
            same ID with the new one.

          Possible values:

          o FULL

          o INCREMENTAL

       --publish-attribution-metrics-to-s3   |   --no-publish-attribution-met-
       rics-to-s3 (boolean)
          If you created a metric attribution, specify whether to publish met-
          rics for this import job to Amazon S3

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By  default, the AWS CLI uses SSL when communicating with AWS services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

OUTPUT
       datasetImportJobArn -> (string)
          The ARN of the dataset import job.



                                                   CREATE-DATASET-IMPORT-JOB()
