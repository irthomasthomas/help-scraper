LIST-INFERENCE-EXECUTIONS()                        LIST-INFERENCE-EXECUTIONS()



NAME
       list-inference-executions -

DESCRIPTION
       Lists  all  inference executions that have been performed by the speci-
       fied inference scheduler.

       See also: AWS API Documentation

SYNOPSIS
            list-inference-executions
          [--next-token <value>]
          [--max-results <value>]
          --inference-scheduler-name <value>
          [--data-start-time-after <value>]
          [--data-end-time-before <value>]
          [--status <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --next-token (string)
          An opaque pagination token indicating where to continue the  listing
          of inference executions.

       --max-results (integer)
          Specifies the maximum number of inference executions to list.

       --inference-scheduler-name (string)
          The  name  of  the  inference  scheduler for the inference execution
          listed.

       --data-start-time-after (timestamp)
          The time reference in the  inferenced  dataset  after  which  Amazon
          Lookout for Equipment started the inference execution.

       --data-end-time-before (timestamp)
          The  time  reference  in  the inferenced dataset before which Amazon
          Lookout for Equipment stopped the inference execution.

       --status (string)
          The status of the inference execution.

          Possible values:

          o IN_PROGRESS

          o SUCCESS

          o FAILED

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By  default, the AWS CLI uses SSL when communicating with AWS services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

OUTPUT
       NextToken -> (string)
          An  opaque pagination token indicating where to continue the listing
          of inference executions.

       InferenceExecutionSummaries -> (list)
          Provides an array of information about the individual inference exe-
          cutions returned from the ListInferenceExecutions operation, includ-
          ing model used, inference scheduler, data configuration, and so on.

          NOTE:
              If you don't supply the InferenceSchedulerName  request  parame-
              ter,  or  if  you supply the name of an inference scheduler that
              doesn't exist, ListInferenceExecutions returns an empty array in
              InferenceExecutionSummaries .

          (structure)
              Contains information about the specific inference execution, in-
              cluding input and output data configuration, inference  schedul-
              ing information, status, and so on.

              ModelName -> (string)
                 The name of the machine learning model being used for the in-
                 ference execution.

              ModelArn -> (string)
                 The Amazon Resource Name (ARN) of the machine learning  model
                 used for the inference execution.

              InferenceSchedulerName -> (string)
                 The name of the inference scheduler being used for the infer-
                 ence execution.

              InferenceSchedulerArn -> (string)
                 The Amazon Resource Name (ARN) of the inference scheduler be-
                 ing used for the inference execution.

              ScheduledStartTime -> (timestamp)
                 Indicates the start time at which the inference scheduler be-
                 gan the specific inference execution.

              DataStartTime -> (timestamp)
                 Indicates the time reference in the dataset at which the  in-
                 ference execution began.

              DataEndTime -> (timestamp)
                 Indicates  the time reference in the dataset at which the in-
                 ference execution stopped.

              DataInputConfiguration -> (structure)
                 Specifies configuration information for the  input  data  for
                 the  inference  scheduler,  including  delimiter, format, and
                 dataset location.

                 S3InputConfiguration -> (structure)
                     Specifies configuration information for  the  input  data
                     for  the inference, including Amazon S3 location of input
                     data.

                     Bucket -> (string)
                        The bucket containing the input dataset for the infer-
                        ence.

                     Prefix -> (string)
                        The  prefix  for the S3 bucket used for the input data
                        for the inference.

                 InputTimeZoneOffset -> (string)
                     Indicates the difference between your time zone and Coor-
                     dinated Universal Time (UTC).

                 InferenceInputNameConfiguration -> (structure)
                     Specifies  configuration  information  for the input data
                     for the inference, including timestamp format and  delim-
                     iter.

                     TimestampFormat -> (string)
                        The  format  of  the timestamp, whether Epoch time, or
                        standard, with or without hyphens (-).

                     ComponentTimestampDelimiter -> (string)
                        Indicates the delimiter character used  between  items
                        in the data.

              DataOutputConfiguration -> (structure)
                 Specifies  configuration  information  for the output results
                 from for the inference execution, including the output Amazon
                 S3 location.

                 S3OutputConfiguration -> (structure)
                     Specifies  configuration  information  for the output re-
                     sults from for the inference, output S3 location.

                     Bucket -> (string)
                        The bucket containing the output results from the  in-
                        ference

                     Prefix -> (string)
                        The  prefix  for the S3 bucket used for the output re-
                        sults from the inference.

                 KmsKeyId -> (string)
                     The ID number for the KMS key key used to encrypt the in-
                     ference output.

              CustomerResultObject -> (structure)
                 The  S3  object that the inference execution results were up-
                 loaded to.

                 Bucket -> (string)
                     The name of the specific S3 bucket.

                 Key -> (string)
                     The Amazon Web Services Key Management Service (KMS  key)
                     key  being  used  to  encrypt the S3 object. Without this
                     key, data in the bucket is not accessible.

              Status -> (string)
                 Indicates the status of the inference execution.

              FailedReason -> (string)
                 Specifies the reason for failure when an inference  execution
                 has failed.

              ModelVersion -> (long)
                 The model version used for the inference execution.

              ModelVersionArn -> (string)
                 The  Amazon  Resource  Number (ARN) of the model version used
                 for the inference execution.



                                                   LIST-INFERENCE-EXECUTIONS()
