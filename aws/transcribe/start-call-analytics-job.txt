START-CALL-ANALYTICS-JOB()                          START-CALL-ANALYTICS-JOB()



NAME
       start-call-analytics-job -

DESCRIPTION
       Transcribes  the audio from a customer service call and applies any ad-
       ditional Request Parameters you choose to include in your request.

       In addition to many of the standard transcription features,  Call  Ana-
       lytics  provides  you  with  call  characteristics, call summarization,
       speaker sentiment, and optional redaction of your text  transcript  and
       your audio file. You can also apply custom categories to flag specified
       conditions. To learn more about these features and insights,  refer  to
       Analyzing call center audio with Call Analytics .

       If  you  want  to apply categories to your Call Analytics job, you must
       create them before submitting your job request.  Categories  cannot  be
       retroactively applied to a job. To create a new category, use the oper-
       ation. To learn more about Call Analytics categories, see Creating cat-
       egories .

       To make a StartCallAnalyticsJob request, you must first upload your me-
       dia file into an Amazon S3 bucket; you can then specify the  Amazon  S3
       location of the file using the Media parameter.

       You must include the following parameters in your StartCallAnalyticsJob
       request:

       o region : The Amazon Web Services Region where you are making your re-
         quest.  For a list of Amazon Web Services Regions supported with Ama-
         zon Transcribe, refer to Amazon Transcribe endpoints and quotas .

       o CallAnalyticsJobName : A custom name you create for  your  transcrip-
         tion job that is unique within your Amazon Web Services account.

       o DataAccessRoleArn  :  The  Amazon  Resource Name (ARN) of an IAM role
         that has permissions to access the Amazon  S3  bucket  that  contains
         your input files.

       o Media (MediaFileUri or RedactedMediaFileUri ): The Amazon S3 location
         of your media file.

       NOTE:
          With Call Analytics, you can redact the audio contained in your  me-
          dia file by including RedactedMediaFileUri , instead of MediaFileUri
          , to specify the location of your input  audio.  If  you  choose  to
          redact  your audio, you can find your redacted media at the location
          specified in the RedactedMediaFileUri field of your response.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            start-call-analytics-job
          --call-analytics-job-name <value>
          --media <value>
          [--output-location <value>]
          [--output-encryption-kms-key-id <value>]
          [--data-access-role-arn <value>]
          [--settings <value>]
          [--channel-definitions <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --call-analytics-job-name (string)
          A unique name, chosen by you, for your Call Analytics job.

          This name is case sensitive, cannot  contain  spaces,  and  must  be
          unique within an Amazon Web Services account. If you try to create a
          new job with the same name as an existing job, you get a ConflictEx-
          ception error.

       --media (structure)
          Describes  the  Amazon S3 location of the media file you want to use
          in your request.

          MediaFileUri -> (string)
              The Amazon S3 location of the media file you want to transcribe.
              For example:

              o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

              o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

              Note  that  the  Amazon S3 bucket that contains your input media
              must be located in the same Amazon  Web  Services  Region  where
              you're making your transcription request.

          RedactedMediaFileUri -> (string)
              The Amazon S3 location of the media file you want to redact. For
              example:

              o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

              o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

              Note that the Amazon S3 bucket that contains  your  input  media
              must  be  located  in  the same Amazon Web Services Region where
              you're making your transcription request.

              WARNING:
                 RedactedMediaFileUri is only  supported  for  Call  Analytics
                 (StartCallAnalyticsJob ) transcription requests.

       Shorthand Syntax:

          MediaFileUri=string,RedactedMediaFileUri=string

       JSON Syntax:

          {
            "MediaFileUri": "string",
            "RedactedMediaFileUri": "string"
          }

       --output-location (string)
          The Amazon S3 location where you want your Call Analytics transcrip-
          tion output stored. You can use any  of  the  following  formats  to
          specify the output location:

          o s3://DOC-EXAMPLE-BUCKET

          o s3://DOC-EXAMPLE-BUCKET/my-output-folder/

          o s3://DOC-EXAMPLE-BUCKET/my-output-folder/my-call-analyt-
            ics-job.json

          Unless you specify a file name (option 3), the name of  your  output
          file  has  a  default  value that matches the name you specified for
          your transcription job using the CallAnalyticsJobName parameter.

          You can specify a KMS key to encrypt your output using the OutputEn-
          cryptionKMSKeyId  parameter.  If you don't specify a KMS key, Amazon
          Transcribe uses the default Amazon S3 key  for  server-side  encryp-
          tion.

          If you don't specify OutputLocation , your transcript is placed in a
          service-managed Amazon S3 bucket and you are provided with a URI  to
          access your transcript.

       --output-encryption-kms-key-id (string)
          The KMS key you want to use to encrypt your Call Analytics output.

          If  using  a key located in the current Amazon Web Services account,
          you can specify your KMS key in one of four ways:

          o Use    the     KMS     key     ID     itself.     For     example,
            1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use an alias for the KMS key ID. For example, alias/ExampleAlias .

          o Use  the  Amazon Resource Name (ARN) for the KMS key ID. For exam-
            ple,                                        arn:aws:kms:region:ac-
            count-ID:key/1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use  the  ARN  for the KMS key alias. For example, arn:aws:kms:re-
            gion:account-ID:alias/ExampleAlias .

          If using a key located in a different Amazon  Web  Services  account
          than  the  current Amazon Web Services account, you can specify your
          KMS key in one of two ways:

          o Use the ARN for the  KMS  key  ID.  For  example,  arn:aws:kms:re-
            gion:account-ID:key/1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use  the  ARN  for the KMS key alias. For example, arn:aws:kms:re-
            gion:account-ID:alias/ExampleAlias .

          If you don't specify an encryption key,  your  output  is  encrypted
          with the default Amazon S3 key (SSE-S3).

          If you specify a KMS key to encrypt your output, you must also spec-
          ify an output location using the OutputLocation parameter.

          Note that the user making the request must have  permission  to  use
          the specified KMS key.

       --data-access-role-arn (string)
          The  Amazon  Resource Name (ARN) of an IAM role that has permissions
          to access the Amazon S3 bucket that contains your  input  files.  If
          the  role you specify doesnt have the appropriate permissions to ac-
          cess the specified Amazon S3 location, your request fails.

          IAM   role   ARNs    have    the    format    arn:partition:iam::ac-
          count:role/role-name-with-path         .         For        example:
          arn:aws:iam::111122223333:role/Admin .

          For more information, see IAM ARNs .

       --settings (structure)
          Specify additional optional settings in your request, including con-
          tent  redaction; allows you to apply custom language models, vocabu-
          lary filters, and custom vocabularies to your Call Analytics job.

          VocabularyName -> (string)
              The name of the custom vocabulary you want to  include  in  your
              Call  Analytics transcription request. Vocabulary names are case
              sensitive.

          VocabularyFilterName -> (string)
              The name of the custom vocabulary filter you want to include  in
              your  Call  Analytics  transcription  request. Vocabulary filter
              names are case sensitive.

              Note that if you include VocabularyFilterName in  your  request,
              you must also include VocabularyFilterMethod .

          VocabularyFilterMethod -> (string)
              Specify  how  you  want  your  vocabulary filter applied to your
              transcript.

              To replace words with *** , choose mask .

              To delete words, choose remove .

              To flag words without changing them, choose tag .

          LanguageModelName -> (string)
              The name of the custom language model you want to use when  pro-
              cessing  your Call Analytics job. Note that language model names
              are case sensitive.

              The language of the specified language model must match the lan-
              guage  code  you  specify  in your transcription request. If the
              languages don't match, the language model isn't  applied.  There
              are no errors or warnings associated with a language mismatch.

          ContentRedaction -> (structure)
              Allows  you  to redact or flag specified personally identifiable
              information (PII) in your transcript. If you  use  ContentRedac-
              tion  , you must also include the sub-parameters: PiiEntityTypes
              , RedactionOutput , and RedactionType .

              RedactionType -> (string)
                 Specify the category of information you want to  redact;  PII
                 (personally  identifiable  information)  is  the  only  valid
                 value. You can use PiiEntityTypes to choose  which  types  of
                 PII you want to redact.

              RedactionOutput -> (string)
                 Specify  if  you  want  only a redacted transcript, or if you
                 want a redacted and an unredacted transcript.

                 When you choose redacted Amazon  Transcribe  creates  only  a
                 redacted transcript.

                 When  you  choose  redacted_and_unredacted  Amazon Transcribe
                 creates a redacted and an unredacted transcript (as two sepa-
                 rate files).

              PiiEntityTypes -> (list)
                 Specify  which  types  of personally identifiable information
                 (PII) you want to redact in your transcript. You can  include
                 as many types as you'd like, or you can select ALL .

                 (string)

          LanguageOptions -> (list)
              You  can  specify  two or more language codes that represent the
              languages you think may be present in your media; including more
              than  five  is  not recommended. If you're unsure what languages
              are present, do not include this parameter.

              Including language options can improve the accuracy of  language
              identification.

              For  a list of languages supported with Call Analytics, refer to
              the Supported languages table.

              (string)

          LanguageIdSettings -> (map)
              If using automatic language identification  (IdentifyLanguage  )
              in your request and you want to apply a custom language model, a
              custom vocabulary, or a custom vocabulary filter,  include  Lan-
              guageIdSettings with the relevant sub-parameters (VocabularyName
              , LanguageModelName , and VocabularyFilterName ).

              You can specify two or more language codes  that  represent  the
              languages you think may be present in your media; including more
              than five is not recommended. Each language code you include can
              have an associated custom language model, custom vocabulary, and
              custom vocabulary filter. The languages you specify  must  match
              the  languages  of  the specified custom language models, custom
              vocabularies, and custom vocabulary filters.

              To include language options using IdentifyLanguage  without  in-
              cluding  a custom language model, a custom vocabulary, or a cus-
              tom vocabulary filter, use LanguageOptions instead of LanguageI-
              dSettings  . Including language options can improve the accuracy
              of automatic language identification.

              If you want to include a custom language model with your request
              but  do  not  want to use automatic language identification, use
              instead the parameter with the LanguageModelName sub-parameter.

              If you want to include a custom vocabulary or a  custom  vocabu-
              lary  filter  (or both) with your request but do not want to use
              automatic language identification,  use  instead  the  parameter
              with   the  VocabularyName  or  VocabularyFilterName  (or  both)
              sub-parameter.

              key -> (string)

              value -> (structure)
                 If using automatic language identification  (IdentifyLanguage
                 )  in  your  request  and you want to apply a custom language
                 model, a custom vocabulary, or a  custom  vocabulary  filter,
                 include  LanguageIdSettings  with the relevant sub-parameters
                 (VocabularyName , LanguageModelName ,  and  VocabularyFilter-
                 Name ).

                 You can specify two or more language codes that represent the
                 languages you think may be present in your  media;  including
                 more than five is not recommended. Each language code you in-
                 clude can have an associated custom  language  model,  custom
                 vocabulary,  and  custom vocabulary filter. The languages you
                 specify must match the languages of the specified custom lan-
                 guage models, custom vocabularies, and custom vocabulary fil-
                 ters.

                 To include language options using  IdentifyLanguage   without
                 including  a custom language model, a custom vocabulary, or a
                 custom vocabulary filter, use LanguageOptions instead of Lan-
                 guageIdSettings  . Including language options can improve the
                 accuracy of automatic language identification.

                 If you want to include a custom language model with your  re-
                 quest  but  do not want to use automatic language identifica-
                 tion, use instead the parameter  with  the  LanguageModelName
                 sub-parameter.

                 If you want to include a custom vocabulary or a custom vocab-
                 ulary filter (or both) with your request but do not  want  to
                 use automatic language identification, use instead the param-
                 eter with  the  VocabularyName  or  VocabularyFilterName  (or
                 both) sub-parameter.

                 VocabularyName -> (string)
                     The  name  of  the custom vocabulary you want to use when
                     processing your transcription job. Vocabulary  names  are
                     case sensitive.

                     The  language  of the specified vocabulary must match the
                     language code you specify in your transcription  request.
                     If  the  languages  don't match, the vocabulary isn't ap-
                     plied. There are no errors or warnings associated with  a
                     language mismatch.

                 VocabularyFilterName -> (string)
                     The  name of the custom vocabulary filter you want to use
                     when processing your transcription job. Vocabulary filter
                     names are case sensitive.

                     The  language  of  the  specified  vocabulary filter must
                     match the language code you specify in your transcription
                     request.  If  the  languages  don't match, the vocabulary
                     filter isn't applied. There are no errors or warnings as-
                     sociated with a language mismatch.

                     Note that if you include VocabularyFilterName in your re-
                     quest, you must also include VocabularyFilterMethod .

                 LanguageModelName -> (string)
                     The name of the custom language model  you  want  to  use
                     when  processing  your  transcription job. Note that lan-
                     guage model names are case sensitive.

                     The language of the specified language model  must  match
                     the  language  code you specify in your transcription re-
                     quest. If the languages don't match, the  language  model
                     isn't applied. There are no errors or warnings associated
                     with a language mismatch.

       Shorthand Syntax:

          VocabularyName=string,VocabularyFilterName=string,VocabularyFilterMethod=string,LanguageModelName=string,ContentRedaction={RedactionType=string,RedactionOutput=string,PiiEntityTypes=[string,string]},LanguageOptions=string,string,LanguageIdSettings={KeyName1={VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string},KeyName2={VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string}}

       JSON Syntax:

          {
            "VocabularyName": "string",
            "VocabularyFilterName": "string",
            "VocabularyFilterMethod": "remove"|"mask"|"tag",
            "LanguageModelName": "string",
            "ContentRedaction": {
              "RedactionType": "PII",
              "RedactionOutput": "redacted"|"redacted_and_unredacted",
              "PiiEntityTypes": ["BANK_ACCOUNT_NUMBER"|"BANK_ROUTING"|"CREDIT_DEBIT_NUMBER"|"CREDIT_DEBIT_CVV"|"CREDIT_DEBIT_EXPIRY"|"PIN"|"EMAIL"|"ADDRESS"|"NAME"|"PHONE"|"SSN"|"ALL", ...]
            },
            "LanguageOptions": ["af-ZA"|"ar-AE"|"ar-SA"|"cy-GB"|"da-DK"|"de-CH"|"de-DE"|"en-AB"|"en-AU"|"en-GB"|"en-IE"|"en-IN"|"en-US"|"en-WL"|"es-ES"|"es-US"|"fa-IR"|"fr-CA"|"fr-FR"|"ga-IE"|"gd-GB"|"he-IL"|"hi-IN"|"id-ID"|"it-IT"|"ja-JP"|"ko-KR"|"ms-MY"|"nl-NL"|"pt-BR"|"pt-PT"|"ru-RU"|"ta-IN"|"te-IN"|"tr-TR"|"zh-CN"|"zh-TW"|"th-TH"|"en-ZA"|"en-NZ", ...],
            "LanguageIdSettings": {"af-ZA"|"ar-AE"|"ar-SA"|"cy-GB"|"da-DK"|"de-CH"|"de-DE"|"en-AB"|"en-AU"|"en-GB"|"en-IE"|"en-IN"|"en-US"|"en-WL"|"es-ES"|"es-US"|"fa-IR"|"fr-CA"|"fr-FR"|"ga-IE"|"gd-GB"|"he-IL"|"hi-IN"|"id-ID"|"it-IT"|"ja-JP"|"ko-KR"|"ms-MY"|"nl-NL"|"pt-BR"|"pt-PT"|"ru-RU"|"ta-IN"|"te-IN"|"tr-TR"|"zh-CN"|"zh-TW"|"th-TH"|"en-ZA"|"en-NZ": {
                  "VocabularyName": "string",
                  "VocabularyFilterName": "string",
                  "LanguageModelName": "string"
                }
              ...}
          }

       --channel-definitions (list)
          Allows you to specify which speaker is on which channel.  For  exam-
          ple,  if your agent is the first participant to speak, you would set
          ChannelId to 0 (to indicate the first channel)  and  ParticipantRole
          to AGENT (to indicate that it's the agent speaking).

          (structure)
              Allows you to specify which speaker is on which channel. For ex-
              ample, if your agent is the  first  participant  to  speak,  you
              would  set  ChannelId  to  0 (to indicate the first channel) and
              ParticipantRole to AGENT (to indicate that it's the agent speak-
              ing).

              ChannelId -> (integer)
                 Specify the audio channel you want to define.

              ParticipantRole -> (string)
                 Specify the speaker you want to define. Omitting this parame-
                 ter is equivalent to specifying both participants.

       Shorthand Syntax:

          ChannelId=integer,ParticipantRole=string ...

       JSON Syntax:

          [
            {
              "ChannelId": integer,
              "ParticipantRole": "AGENT"|"CUSTOMER"
            }
            ...
          ]

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       CallAnalyticsJob -> (structure)
          Provides  detailed information about the current Call Analytics job,
          including job status and, if applicable, failure reason.

          CallAnalyticsJobName -> (string)
              The name of the Call Analytics job. Job names are case sensitive
              and must be unique within an Amazon Web Services account.

          CallAnalyticsJobStatus -> (string)
              Provides the status of the specified Call Analytics job.

              If  the  status  is  COMPLETED , the job is finished and you can
              find the results at the location specified in  TranscriptFileUri
              (or  RedactedTranscriptFileUri  ,  if  you  requested transcript
              redaction). If the status is FAILED , FailureReason provides de-
              tails on why your transcription job failed.

          LanguageCode -> (string)
              The  language code used to create your Call Analytics job. For a
              list of supported languages and their associated language codes,
              refer to the Supported languages table.

              If  you  don't  know the language spoken in your media file, you
              can omit this field  and  let  Amazon  Transcribe  automatically
              identify  the language of your media. To improve the accuracy of
              language identification, you can include several language  codes
              and  Amazon  Transcribe chooses the closest match for your tran-
              scription.

          MediaSampleRateHertz -> (integer)
              The sample rate, in Hertz, of the audio track in your input  me-
              dia file.

          MediaFormat -> (string)
              The format of the input media file.

          Media -> (structure)
              Describes  the  Amazon S3 location of the media file you want to
              use in your request.

              MediaFileUri -> (string)
                 The Amazon S3 location of the media file you  want  to  tran-
                 scribe. For example:

                 o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

                 o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

                 Note that the Amazon S3 bucket that contains your input media
                 must be located in the same Amazon Web Services Region  where
                 you're making your transcription request.

              RedactedMediaFileUri -> (string)
                 The  Amazon S3 location of the media file you want to redact.
                 For example:

                 o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

                 o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

                 Note that the Amazon S3 bucket that contains your input media
                 must  be located in the same Amazon Web Services Region where
                 you're making your transcription request.

                 WARNING:
                     RedactedMediaFileUri is only supported for Call Analytics
                     (StartCallAnalyticsJob ) transcription requests.

          Transcript -> (structure)
              Provides  you  with the Amazon S3 URI you can use to access your
              transcript.

              TranscriptFileUri -> (string)
                 The Amazon S3 location of your transcript. You can  use  this
                 URI to access or download your transcript.

                 If  you  included  OutputBucketName in your transcription job
                 request, this is the URI of that bucket. If you also included
                 OutputKey in your request, your output is located in the path
                 you specified in your request.

                 If you didn't include OutputBucketName in your  transcription
                 job  request,  your transcript is stored in a service-managed
                 bucket, and TranscriptFileUri provides you with  a  temporary
                 URI you can use for secure access to your transcript.

                 NOTE:
                     Temporary  URIs for service-managed Amazon S3 buckets are
                     only valid for 15 minutes. If you get an AccesDenied  er-
                     ror,  you  can  get a new temporary URI by running a Get-
                     TranscriptionJob or ListTranscriptionJob request.

              RedactedTranscriptFileUri -> (string)
                 The Amazon S3 location of your redacted transcript.  You  can
                 use this URI to access or download your transcript.

                 If  you  included  OutputBucketName in your transcription job
                 request, this is the URI of that bucket. If you also included
                 OutputKey in your request, your output is located in the path
                 you specified in your request.

                 If you didn't include OutputBucketName in your  transcription
                 job  request,  your transcript is stored in a service-managed
                 bucket, and RedactedTranscriptFileUri  provides  you  with  a
                 temporary  URI  you  can  use for secure access to your tran-
                 script.

                 NOTE:
                     Temporary URIs for service-managed Amazon S3 buckets  are
                     only  valid for 15 minutes. If you get an AccesDenied er-
                     ror, you can get a new temporary URI by  running  a  Get-
                     TranscriptionJob or ListTranscriptionJob request.

          StartTime -> (timestamp)
              The  date  and  time the specified Call Analytics job began pro-
              cessing.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:32:58.789000-07:00 represents a tran-
              scription job that started processing at 12:32 PM UTC-7  on  May
              4, 2022.

          CreationTime -> (timestamp)
              The  date  and time the specified Call Analytics job request was
              made.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:32:58.761000-07:00 represents a tran-
              scription job that started processing at 12:32 PM UTC-7  on  May
              4, 2022.

          CompletionTime -> (timestamp)
              The date and time the specified Call Analytics job finished pro-
              cessing.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:33:13.922000-07:00 represents a tran-
              scription job that started processing at 12:33 PM UTC-7  on  May
              4, 2022.

          FailureReason -> (string)
              If CallAnalyticsJobStatus is FAILED , FailureReason contains in-
              formation about why the Call Analytics job request failed.

              The FailureReason field contains one of the following values:

              o Unsupported media format . The media format specified in Medi-
                aFormat  isn't  valid. Refer to MediaFormat for a list of sup-
                ported formats.

              o The media format provided does not match  the  detected  media
                format  .  The  media  format specified in MediaFormat doesn't
                match the format of the input file. Check the media format  of
                your media file and correct the specified value.

              o Invalid sample rate for audio file . The sample rate specified
                in MediaSampleRateHertz isn't valid. The sample rate  must  be
                between 8,000 and 48,000 Hertz.

              o The  sample  rate  provided does not match the detected sample
                rate .  The  sample  rate  specified  in  MediaSampleRateHertz
                doesn't  match  the  sample  rate detected in your input media
                file. Check the sample rate of your media file and correct the
                specified value.

              o Invalid  file size: file size too large . The size of your me-
                dia file is larger than what Amazon  Transcribe  can  process.
                For more information, refer to Guidelines and quotas .

              o Invalid  number  of  channels:  number of channels too large .
                Your audio contains more channels than  Amazon  Transcribe  is
                able to process. For more information, refer to Guidelines and
                quotas .

          DataAccessRoleArn -> (string)
              The Amazon Resource Name (ARN) of an IAM role that  has  permis-
              sions  to  access  the Amazon S3 bucket that contains your input
              files. If the role you specify doesnt have the appropriate  per-
              missions  to  access  the specified Amazon S3 location, your re-
              quest fails.

              IAM   role   ARNs   have   the   format   arn:partition:iam::ac-
              count:role/role-name-with-path        .       For       example:
              arn:aws:iam::111122223333:role/Admin .

              For more information, see IAM ARNs .

          IdentifiedLanguageScore -> (float)
              The confidence score associated with the language identified  in
              your media file.

              Confidence scores are values between 0 and 1; a larger value in-
              dicates a higher probability that the identified  language  cor-
              rectly matches the language spoken in your media.

          Settings -> (structure)
              Allows  additional  optional settings in your request, including
              content redaction; allows you to apply custom  language  models,
              vocabulary filters, and custom vocabularies to your Call Analyt-
              ics job.

              VocabularyName -> (string)
                 The name of the custom vocabulary you want to include in your
                 Call  Analytics  transcription  request. Vocabulary names are
                 case sensitive.

              VocabularyFilterName -> (string)
                 The name of the custom vocabulary filter you want to  include
                 in your Call Analytics transcription request. Vocabulary fil-
                 ter names are case sensitive.

                 Note that if you include  VocabularyFilterName  in  your  re-
                 quest, you must also include VocabularyFilterMethod .

              VocabularyFilterMethod -> (string)
                 Specify  how  you want your vocabulary filter applied to your
                 transcript.

                 To replace words with *** , choose mask .

                 To delete words, choose remove .

                 To flag words without changing them, choose tag .

              LanguageModelName -> (string)
                 The name of the custom language model you want  to  use  when
                 processing  your Call Analytics job. Note that language model
                 names are case sensitive.

                 The language of the specified language model must  match  the
                 language  code  you specify in your transcription request. If
                 the languages don't match, the language model isn't  applied.
                 There  are  no  errors or warnings associated with a language
                 mismatch.

              ContentRedaction -> (structure)
                 Allows you to redact or flag specified  personally  identifi-
                 able  information  (PII)  in your transcript. If you use Con-
                 tentRedaction , you must also include the sub-parameters: Pi-
                 iEntityTypes , RedactionOutput , and RedactionType .

                 RedactionType -> (string)
                     Specify  the  category of information you want to redact;
                     PII (personally identifiable  information)  is  the  only
                     valid  value.  You can use PiiEntityTypes to choose which
                     types of PII you want to redact.

                 RedactionOutput -> (string)
                     Specify if you want only a redacted transcript, or if you
                     want a redacted and an unredacted transcript.

                     When you choose redacted Amazon Transcribe creates only a
                     redacted transcript.

                     When you choose redacted_and_unredacted Amazon Transcribe
                     creates  a  redacted and an unredacted transcript (as two
                     separate files).

                 PiiEntityTypes -> (list)
                     Specify which types of personally  identifiable  informa-
                     tion (PII) you want to redact in your transcript. You can
                     include as many types as you'd like, or  you  can  select
                     ALL .

                     (string)

              LanguageOptions -> (list)
                 You can specify two or more language codes that represent the
                 languages you think may be present in your  media;  including
                 more than five is not recommended. If you're unsure what lan-
                 guages are present, do not include this parameter.

                 Including language options can improve the accuracy  of  lan-
                 guage identification.

                 For  a list of languages supported with Call Analytics, refer
                 to the Supported languages table.

                 (string)

              LanguageIdSettings -> (map)
                 If using automatic language identification  (IdentifyLanguage
                 )  in  your  request  and you want to apply a custom language
                 model, a custom vocabulary, or a  custom  vocabulary  filter,
                 include  LanguageIdSettings  with the relevant sub-parameters
                 (VocabularyName , LanguageModelName ,  and  VocabularyFilter-
                 Name ).

                 You can specify two or more language codes that represent the
                 languages you think may be present in your  media;  including
                 more than five is not recommended. Each language code you in-
                 clude can have an associated custom  language  model,  custom
                 vocabulary,  and  custom vocabulary filter. The languages you
                 specify must match the languages of the specified custom lan-
                 guage models, custom vocabularies, and custom vocabulary fil-
                 ters.

                 To include language options using  IdentifyLanguage   without
                 including  a custom language model, a custom vocabulary, or a
                 custom vocabulary filter, use LanguageOptions instead of Lan-
                 guageIdSettings  . Including language options can improve the
                 accuracy of automatic language identification.

                 If you want to include a custom language model with your  re-
                 quest  but  do not want to use automatic language identifica-
                 tion, use instead the parameter  with  the  LanguageModelName
                 sub-parameter.

                 If you want to include a custom vocabulary or a custom vocab-
                 ulary filter (or both) with your request but do not  want  to
                 use automatic language identification, use instead the param-
                 eter with  the  VocabularyName  or  VocabularyFilterName  (or
                 both) sub-parameter.

                 key -> (string)

                 value -> (structure)
                     If  using automatic language identification (IdentifyLan-
                     guage ) in your request and you want to  apply  a  custom
                     language  model, a custom vocabulary, or a custom vocabu-
                     lary filter, include LanguageIdSettings with the relevant
                     sub-parameters  (VocabularyName , LanguageModelName , and
                     VocabularyFilterName ).

                     You can specify two or more language codes that represent
                     the languages you think may be present in your media; in-
                     cluding more than five is not recommended. Each  language
                     code  you  include can have an associated custom language
                     model, custom vocabulary, and custom  vocabulary  filter.
                     The languages you specify must match the languages of the
                     specified custom language  models,  custom  vocabularies,
                     and custom vocabulary filters.

                     To include language options using IdentifyLanguage  with-
                     out including a custom language model, a  custom  vocabu-
                     lary,  or a custom vocabulary filter, use LanguageOptions
                     instead of LanguageIdSettings .  Including  language  op-
                     tions  can  improve  the  accuracy  of automatic language
                     identification.

                     If you want to include a custom language model with  your
                     request but do not want to use automatic language identi-
                     fication, use instead the parameter with the LanguageMod-
                     elName sub-parameter.

                     If  you  want  to include a custom vocabulary or a custom
                     vocabulary filter (or both) with your request but do  not
                     want  to  use  automatic language identification, use in-
                     stead the parameter with the  VocabularyName  or  Vocabu-
                     laryFilterName (or both) sub-parameter.

                     VocabularyName -> (string)
                        The name of the custom vocabulary you want to use when
                        processing your transcription  job.  Vocabulary  names
                        are case sensitive.

                        The  language  of  the specified vocabulary must match
                        the language code you specify  in  your  transcription
                        request.  If the languages don't match, the vocabulary
                        isn't applied. There are no errors or warnings associ-
                        ated with a language mismatch.

                     VocabularyFilterName -> (string)
                        The  name  of the custom vocabulary filter you want to
                        use when processing your transcription job. Vocabulary
                        filter names are case sensitive.

                        The  language  of the specified vocabulary filter must
                        match the language code you specify in your transcrip-
                        tion request. If the languages don't match, the vocab-
                        ulary filter isn't applied. There  are  no  errors  or
                        warnings associated with a language mismatch.

                        Note  that if you include VocabularyFilterName in your
                        request, you must also include  VocabularyFilterMethod
                        .

                     LanguageModelName -> (string)
                        The  name of the custom language model you want to use
                        when processing your transcription job. Note that lan-
                        guage model names are case sensitive.

                        The  language  of  the  specified  language model must
                        match the language code you specify in your transcrip-
                        tion  request.  If the languages don't match, the lan-
                        guage model isn't applied.  There  are  no  errors  or
                        warnings associated with a language mismatch.

          ChannelDefinitions -> (list)
              Allows  you to specify which speaker is on which channel in your
              Call Analytics job request. For example, if your  agent  is  the
              first participant to speak, you would set ChannelId to 0 (to in-
              dicate the first channel) and ParticipantRole to AGENT (to indi-
              cate that it's the agent speaking).

              (structure)
                 Allows  you to specify which speaker is on which channel. For
                 example, if your agent is the first participant to speak, you
                 would  set ChannelId to 0 (to indicate the first channel) and
                 ParticipantRole to AGENT (to indicate  that  it's  the  agent
                 speaking).

                 ChannelId -> (integer)
                     Specify the audio channel you want to define.

                 ParticipantRole -> (string)
                     Specify the speaker you want to define. Omitting this pa-
                     rameter is equivalent to specifying both participants.



                                                    START-CALL-ANALYTICS-JOB()
