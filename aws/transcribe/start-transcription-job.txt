START-TRANSCRIPTION-JOB()                            START-TRANSCRIPTION-JOB()



NAME
       start-transcription-job -

DESCRIPTION
       Transcribes  the audio from a media file and applies any additional Re-
       quest Parameters you choose to include in your request.

       To make a StartTranscriptionJob request, you must first upload your me-
       dia  file  into an Amazon S3 bucket; you can then specify the Amazon S3
       location of the file using the Media parameter.

       You must include the following parameters in your StartTranscriptionJob
       request:

       o region : The Amazon Web Services Region where you are making your re-
         quest. For a list of Amazon Web Services Regions supported with  Ama-
         zon Transcribe, refer to Amazon Transcribe endpoints and quotas .

       o TranscriptionJobName  :  A custom name you create for your transcrip-
         tion job that is unique within your Amazon Web Services account.

       o Media (MediaFileUri ): The Amazon S3 location of your media file.

       o One of LanguageCode , IdentifyLanguage , or IdentifyMultipleLanguages
         :  If  you know the language of your media file, specify it using the
         LanguageCode parameter; you can find all valid language codes in  the
         Supported  languages table. If you don't know the languages spoken in
         your media, use either IdentifyLanguage or  IdentifyMultipleLanguages
         and let Amazon Transcribe identify the languages for you.

       See also: AWS API Documentation

SYNOPSIS
            start-transcription-job
          --transcription-job-name <value>
          [--language-code <value>]
          [--media-sample-rate-hertz <value>]
          [--media-format <value>]
          --media <value>
          [--output-bucket-name <value>]
          [--output-key <value>]
          [--output-encryption-kms-key-id <value>]
          [--kms-encryption-context <value>]
          [--settings <value>]
          [--model-settings <value>]
          [--job-execution-settings <value>]
          [--content-redaction <value>]
          [--identify-language | --no-identify-language]
          [--identify-multiple-languages | --no-identify-multiple-languages]
          [--language-options <value>]
          [--subtitles <value>]
          [--tags <value>]
          [--language-id-settings <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --transcription-job-name (string)
          A  unique  name, chosen by you, for your transcription job. The name
          that you specify is also used as the default name of your transcrip-
          tion  output  file. If you want to specify a different name for your
          transcription output, use the OutputKey parameter.

          This name is case sensitive, cannot  contain  spaces,  and  must  be
          unique within an Amazon Web Services account. If you try to create a
          new job with the same name as an existing job, you get a ConflictEx-
          ception error.

       --language-code (string)
          The  language  code that represents the language spoken in the input
          media file.

          If you're unsure of the language spoken in your media file, consider
          using  IdentifyLanguage or IdentifyMultipleLanguages to enable auto-
          matic language identification.

          Note that you must include one of LanguageCode , IdentifyLanguage  ,
          or  IdentifyMultipleLanguages  in  your request. If you include more
          than one of these parameters, your transcription job fails.

          For a list of supported  languages  and  their  associated  language
          codes, refer to the Supported languages table.

          NOTE:
              To  transcribe  speech  in Modern Standard Arabic (ar-SA ), your
              media file must be encoded at a sample  rate  of  16,000  Hz  or
              higher.

          Possible values:

          o af-ZA

          o ar-AE

          o ar-SA

          o da-DK

          o de-CH

          o de-DE

          o en-AB

          o en-AU

          o en-GB

          o en-IE

          o en-IN

          o en-US

          o en-WL

          o es-ES

          o es-US

          o fa-IR

          o fr-CA

          o fr-FR

          o he-IL

          o hi-IN

          o id-ID

          o it-IT

          o ja-JP

          o ko-KR

          o ms-MY

          o nl-NL

          o pt-BR

          o pt-PT

          o ru-RU

          o ta-IN

          o te-IN

          o tr-TR

          o zh-CN

          o zh-TW

          o th-TH

          o en-ZA

          o en-NZ

          o vi-VN

          o sv-SE

       --media-sample-rate-hertz (integer)
          The  sample  rate,  in hertz, of the audio track in your input media
          file.

          If you don't specify the media sample rate, Amazon Transcribe deter-
          mines  it for you. If you specify the sample rate, it must match the
          rate detected by Amazon Transcribe. If there's  a  mismatch  between
          the  value  that you specify and the value detected, your job fails.
          In most cases, you can  omit  MediaSampleRateHertz  and  let  Amazon
          Transcribe determine the sample rate.

       --media-format (string)
          Specify the format of your input media file.

          Possible values:

          o mp3

          o mp4

          o wav

          o flac

          o ogg

          o amr

          o webm

       --media (structure)
          Describes  the  Amazon S3 location of the media file you want to use
          in your request.

          MediaFileUri -> (string)
              The Amazon S3 location of the media file you want to transcribe.
              For example:

              o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

              o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

              Note  that  the  Amazon S3 bucket that contains your input media
              must be located in the same Amazon  Web  Services  Region  where
              you're making your transcription request.

          RedactedMediaFileUri -> (string)
              The Amazon S3 location of the media file you want to redact. For
              example:

              o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

              o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

              Note that the Amazon S3 bucket that contains  your  input  media
              must  be  located  in  the same Amazon Web Services Region where
              you're making your transcription request.

              WARNING:
                 RedactedMediaFileUri produces a redacted audio file in  addi-
                 tion  to a redacted transcript. It is only supported for Call
                 Analytics (StartCallAnalyticsJob ) transcription requests.

       Shorthand Syntax:

          MediaFileUri=string,RedactedMediaFileUri=string

       JSON Syntax:

          {
            "MediaFileUri": "string",
            "RedactedMediaFileUri": "string"
          }

       --output-bucket-name (string)
          The name of the Amazon S3 bucket where you want  your  transcription
          output  stored.  Do  not  include  the S3:// prefix of the specified
          bucket.

          If you want your output to go to a sub-folder of this bucket,  spec-
          ify  it using the OutputKey parameter; OutputBucketName only accepts
          the name of a bucket.

          For example, if  you  want  your  output  stored  in  S3://DOC-EXAM-
          PLE-BUCKET  ,  set OutputBucketName to DOC-EXAMPLE-BUCKET . However,
          if   you    want    your    output    stored    in    S3://DOC-EXAM-
          PLE-BUCKET/test-files/  , set OutputBucketName to DOC-EXAMPLE-BUCKET
          and OutputKey to test-files/ .

          Note that Amazon Transcribe must have permission to use  the  speci-
          fied location. You can change Amazon S3 permissions using the Amazon
          Web Services Management Console . See also Permissions Required  for
          IAM User Roles .

          If you don't specify OutputBucketName , your transcript is placed in
          a service-managed Amazon S3 bucket and you are provided with  a  URI
          to access your transcript.

       --output-key (string)
          Use in combination with OutputBucketName to specify the output loca-
          tion of your transcript and, optionally, a unique name for your out-
          put file. The default name for your transcription output is the same
          as the name you specified for your transcription job (Transcription-
          JobName ).

          Here are some examples of how you can use OutputKey :

          o If  you  specify  'DOC-EXAMPLE-BUCKET' as the OutputBucketName and
            'my-transcript.json' as the OutputKey , your transcription  output
            path is s3://DOC-EXAMPLE-BUCKET/my-transcript.json .

          o If  you  specify 'my-first-transcription' as the TranscriptionJob-
            Name  ,  'DOC-EXAMPLE-BUCKET'  as  the  OutputBucketName   ,   and
            'my-transcript'  as the OutputKey , your transcription output path
            is       s3://DOC-EXAMPLE-BUCKET/my-transcript/my-first-transcrip-
            tion.json .

          o If  you  specify  'DOC-EXAMPLE-BUCKET' as the OutputBucketName and
            'test-files/my-transcript.json' as the OutputKey , your transcrip-
            tion  output  path  is s3://DOC-EXAMPLE-BUCKET/test-files/my-tran-
            script.json .

          o If you specify 'my-first-transcription' as  the  TranscriptionJob-
            Name   ,   'DOC-EXAMPLE-BUCKET'  as  the  OutputBucketName  ,  and
            'test-files/my-transcript' as the OutputKey ,  your  transcription
            output    path    is   s3://DOC-EXAMPLE-BUCKET/test-files/my-tran-
            script/my-first-transcription.json .

          If you specify the name of  an  Amazon  S3  bucket  sub-folder  that
          doesn't exist, one is created for you.

       --output-encryption-kms-key-id (string)
          The KMS key you want to use to encrypt your transcription output.

          If  using  a key located in the current Amazon Web Services account,
          you can specify your KMS key in one of four ways:

          o Use    the     KMS     key     ID     itself.     For     example,
            1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use an alias for the KMS key ID. For example, alias/ExampleAlias .

          o Use  the  Amazon Resource Name (ARN) for the KMS key ID. For exam-
            ple,                                        arn:aws:kms:region:ac-
            count-ID:key/1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use  the  ARN  for the KMS key alias. For example, arn:aws:kms:re-
            gion:account-ID:alias/ExampleAlias .

          If using a key located in a different Amazon  Web  Services  account
          than  the  current Amazon Web Services account, you can specify your
          KMS key in one of two ways:

          o Use the ARN for the  KMS  key  ID.  For  example,  arn:aws:kms:re-
            gion:account-ID:key/1234abcd-12ab-34cd-56ef-1234567890ab .

          o Use  the  ARN  for the KMS key alias. For example, arn:aws:kms:re-
            gion:account-ID:alias/ExampleAlias .

          If you don't specify an encryption key,  your  output  is  encrypted
          with the default Amazon S3 key (SSE-S3).

          If you specify a KMS key to encrypt your output, you must also spec-
          ify an output location using the OutputLocation parameter.

          Note that the role making the request must have  permission  to  use
          the specified KMS key.

       --kms-encryption-context (map)
          A map of plain text, non-secret key:value pairs, known as encryption
          context pairs, that provide an added  layer  of  security  for  your
          data.   For   more  information,  see  KMS  encryption  context  and
          Asymmetric keys in KMS .

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --settings (structure)
          Specify additional optional  settings  in  your  request,  including
          channel  identification,  alternative transcriptions, speaker parti-
          tioning. You can use that to apply custom vocabularies  and  vocabu-
          lary filters.

          If  you  want  to include a custom vocabulary or a custom vocabulary
          filter (or both) with your request but do not want to use  automatic
          language identification, use Settings with the VocabularyName or Vo-
          cabularyFilterName (or both) sub-parameter.

          If you're using automatic language identification with your  request
          and want to include a custom language model, a custom vocabulary, or
          a custom vocabulary filter, use instead the parameter with the  Lan-
          guageModelName  , VocabularyName or VocabularyFilterName sub-parame-
          ters.

          VocabularyName -> (string)
              The name of the custom vocabulary you want to use in your  tran-
              scription  job request. This name is case sensitive, cannot con-
              tain spaces, and must be unique within an  Amazon  Web  Services
              account.

          ShowSpeakerLabels -> (boolean)
              Enables speaker partitioning (diarization) in your transcription
              output. Speaker partitioning labels the speech  from  individual
              speakers in your media file.

              If  you  enable ShowSpeakerLabels in your request, you must also
              include MaxSpeakerLabels .

              You can't include both ShowSpeakerLabels and  ChannelIdentifica-
              tion  in  the  same request. Including both parameters returns a
              BadRequestException .

              For more information, see Partitioning speakers (diarization) .

          MaxSpeakerLabels -> (integer)
              Specify the maximum number of speakers you want to partition  in
              your media.

              Note  that  if your media contains more speakers than the speci-
              fied number, multiple speakers are treated as a single speaker.

              If you specify the MaxSpeakerLabels  field,  you  must  set  the
              ShowSpeakerLabels field to true.

          ChannelIdentification -> (boolean)
              Enables channel identification in multi-channel audio.

              Channel identification transcribes the audio on each channel in-
              dependently, then appends the output for each channel  into  one
              transcript.

              You  can't include both ShowSpeakerLabels and ChannelIdentifica-
              tion in the same request. Including both  parameters  returns  a
              BadRequestException .

              For more information, see Transcribing multi-channel audio .

          ShowAlternatives -> (boolean)
              To  include alternative transcriptions within your transcription
              output, include ShowAlternatives in your transcription request.

              If you have multi-channel audio and do not enable channel  iden-
              tification, your audio is transcribed in a continuous manner and
              your transcript does not separate the speech by channel.

              If you include ShowAlternatives , you must also  include  MaxAl-
              ternatives  ,  which  is the maximum number of alternative tran-
              scriptions you want Amazon Transcribe to generate.

              For more information, see Alternative transcriptions .

          MaxAlternatives -> (integer)
              Indicate the maximum number of  alternative  transcriptions  you
              want Amazon Transcribe to include in your transcript.

              If  you  select  a number greater than the number of alternative
              transcriptions generated by Amazon Transcribe, only  the  actual
              number of alternative transcriptions are included.

              If  you  include  MaxAlternatives in your request, you must also
              include ShowAlternatives with a value of true .

              For more information, see Alternative transcriptions .

          VocabularyFilterName -> (string)
              The name of the custom vocabulary filter you want to use in your
              transcription  job  request. This name is case sensitive, cannot
              contain spaces, and must be unique within an Amazon Web Services
              account.

              Note  that  if you include VocabularyFilterName in your request,
              you must also include VocabularyFilterMethod .

          VocabularyFilterMethod -> (string)
              Specify how you want your custom vocabulary  filter  applied  to
              your transcript.

              To replace words with *** , choose mask .

              To delete words, choose remove .

              To flag words without changing them, choose tag .

       Shorthand Syntax:

          VocabularyName=string,ShowSpeakerLabels=boolean,MaxSpeakerLabels=integer,ChannelIdentification=boolean,ShowAlternatives=boolean,MaxAlternatives=integer,VocabularyFilterName=string,VocabularyFilterMethod=string

       JSON Syntax:

          {
            "VocabularyName": "string",
            "ShowSpeakerLabels": true|false,
            "MaxSpeakerLabels": integer,
            "ChannelIdentification": true|false,
            "ShowAlternatives": true|false,
            "MaxAlternatives": integer,
            "VocabularyFilterName": "string",
            "VocabularyFilterMethod": "remove"|"mask"|"tag"
          }

       --model-settings (structure)
          Specify  the  custom  language  model  you want to include with your
          transcription job. If you include ModelSettings in your request, you
          must include the LanguageModelName sub-parameter.

          For more information, see Custom language models .

          LanguageModelName -> (string)
              The  name of the custom language model you want to use when pro-
              cessing your transcription job. Note that custom language  model
              names are case sensitive.

              The  language  of the specified custom language model must match
              the language code that you specify  in  your  transcription  re-
              quest.  If  the languages don't match, the custom language model
              isn't applied. There are no errors or warnings associated with a
              language mismatch.

       Shorthand Syntax:

          LanguageModelName=string

       JSON Syntax:

          {
            "LanguageModelName": "string"
          }

       --job-execution-settings (structure)
          Makes  it  possible  to  control  how your transcription job is pro-
          cessed. Currently, the only  JobExecutionSettings  modification  you
          can choose is enabling job queueing using the AllowDeferredExecution
          sub-parameter.

          If you include JobExecutionSettings in your request, you  must  also
          include  the  sub-parameters: AllowDeferredExecution and DataAccess-
          RoleArn .

          AllowDeferredExecution -> (boolean)
              Makes it possible to enable job queuing when your concurrent re-
              quest  limit  is exceeded. When AllowDeferredExecution is set to
              true , transcription job requests are placed in  a  queue  until
              the  number of jobs falls below the concurrent request limit. If
              AllowDeferredExecution is set to false and the number  of  tran-
              scription  job requests exceed the concurrent request limit, you
              get a LimitExceededException error.

              If you include AllowDeferredExecution in your request, you  must
              also include DataAccessRoleArn .

          DataAccessRoleArn -> (string)
              The  Amazon  Resource Name (ARN) of an IAM role that has permis-
              sions to access the Amazon S3 bucket that  contains  your  input
              files.  If the role that you specify doesnt have the appropriate
              permissions to access the specified Amazon S3 location, your re-
              quest fails.

              IAM   role   ARNs   have   the   format   arn:partition:iam::ac-
              count:role/role-name-with-path       .       For        example:
              arn:aws:iam::111122223333:role/Admin . For more information, see
              IAM ARNs .

              Note that if you include DataAccessRoleArn in your request,  you
              must also include AllowDeferredExecution .

       Shorthand Syntax:

          AllowDeferredExecution=boolean,DataAccessRoleArn=string

       JSON Syntax:

          {
            "AllowDeferredExecution": true|false,
            "DataAccessRoleArn": "string"
          }

       --content-redaction (structure)
          Makes  it  possible to redact or flag specified personally identifi-
          able information (PII) in your transcript. If you use  ContentRedac-
          tion  ,  you  must also include the sub-parameters: PiiEntityTypes ,
          RedactionOutput , and RedactionType .

          RedactionType -> (string)
              Specify the category of information  you  want  to  redact;  PII
              (personally  identifiable  information) is the only valid value.
              You can use PiiEntityTypes to choose which types of PII you want
              to redact.

          RedactionOutput -> (string)
              Specify if you want only a redacted transcript, or if you want a
              redacted and an unredacted transcript.

              When you  choose  redacted  Amazon  Transcribe  creates  only  a
              redacted transcript.

              When  you  choose redacted_and_unredacted Amazon Transcribe cre-
              ates a redacted and an unredacted transcript  (as  two  separate
              files).

          PiiEntityTypes -> (list)
              Specify which types of personally identifiable information (PII)
              you want to redact in your transcript. You can include  as  many
              types as you'd like, or you can select ALL .

              (string)

       Shorthand Syntax:

          RedactionType=string,RedactionOutput=string,PiiEntityTypes=string,string

       JSON Syntax:

          {
            "RedactionType": "PII",
            "RedactionOutput": "redacted"|"redacted_and_unredacted",
            "PiiEntityTypes": ["BANK_ACCOUNT_NUMBER"|"BANK_ROUTING"|"CREDIT_DEBIT_NUMBER"|"CREDIT_DEBIT_CVV"|"CREDIT_DEBIT_EXPIRY"|"PIN"|"EMAIL"|"ADDRESS"|"NAME"|"PHONE"|"SSN"|"ALL", ...]
          }

       --identify-language | --no-identify-language (boolean)
          Enables  automatic language identification in your transcription job
          request. Use this parameter if your media  file  contains  only  one
          language.  If  your media contains multiple languages, use Identify-
          MultipleLanguages instead.

          If you include IdentifyLanguage , you can optionally include a  list
          of  language  codes,  using  LanguageOptions , that you think may be
          present in your  media  file.  Including  LanguageOptions  restricts
          IdentifyLanguage  to  only  the  language  options that you specify,
          which can improve transcription accuracy.

          If you want to apply a custom language model, a  custom  vocabulary,
          or a custom vocabulary filter to your automatic language identifica-
          tion request, include LanguageIdSettings with the  relevant  sub-pa-
          rameters (VocabularyName , LanguageModelName , and VocabularyFilter-
          Name ). If you include LanguageIdSettings , also include LanguageOp-
          tions .

          Note  that you must include one of LanguageCode , IdentifyLanguage ,
          or IdentifyMultipleLanguages in your request. If  you  include  more
          than one of these parameters, your transcription job fails.

       --identify-multiple-languages | --no-identify-multiple-languages (bool-
       ean)
          Enables automatic multi-language identification in  your  transcrip-
          tion  job  request.  Use  this parameter if your media file contains
          more than one language. If your media contains  only  one  language,
          use IdentifyLanguage instead.

          If  you  include  IdentifyMultipleLanguages , you can optionally in-
          clude a list of language codes, using  LanguageOptions  ,  that  you
          think  may  be present in your media file. Including LanguageOptions
          restricts IdentifyLanguage to only the  language  options  that  you
          specify, which can improve transcription accuracy.

          If you want to apply a custom vocabulary or a custom vocabulary fil-
          ter to your automatic language identification request, include  Lan-
          guageIdSettings with the relevant sub-parameters (VocabularyName and
          VocabularyFilterName ). If you include LanguageIdSettings , also in-
          clude LanguageOptions .

          Note  that you must include one of LanguageCode , IdentifyLanguage ,
          or IdentifyMultipleLanguages in your request. If  you  include  more
          than one of these parameters, your transcription job fails.

       --language-options (list)
          You  can  specify two or more language codes that represent the lan-
          guages you think may be present in your media. Including  more  than
          five  is  not  recommended.  If  you're  unsure  what  languages are
          present, do not include this parameter.

          If you include LanguageOptions in your request, you  must  also  in-
          clude IdentifyLanguage .

          For more information, refer to Supported languages .

          To  transcribe speech in Modern Standard Arabic (ar-SA ), your media
          file must be encoded at a sample rate of 16,000 Hz or higher.

          (string)

       Syntax:

          "string" "string" ...

          Where valid values are:
            af-ZA
            ar-AE
            ar-SA
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ
            vi-VN
            sv-SE

       --subtitles (structure)
          Produces subtitle files for your input media. You can specify WebVTT
          (.vtt) and SubRip (.srt) formats.

          Formats -> (list)
              Specify  the output format for your subtitle file; if you select
              both WebVTT (vtt ) and SubRip (srt ) formats, two  output  files
              are generated.

              (string)

          OutputStartIndex -> (integer)
              Specify  the starting value that is assigned to the first subti-
              tle segment.

              The default start index for Amazon Transcribe is 0 , which  dif-
              fers  from the more widely used standard of 1 . If you're uncer-
              tain which value to use, we recommend choosing 1 , as  this  may
              improve compatibility with other services.

       Shorthand Syntax:

          Formats=string,string,OutputStartIndex=integer

       JSON Syntax:

          {
            "Formats": ["vtt"|"srt", ...],
            "OutputStartIndex": integer
          }

       --tags (list)
          Adds  one or more custom tags, each in the form of a key:value pair,
          to a new transcription job at the time you start this new job.

          To learn more about using tags  with  Amazon  Transcribe,  refer  to
          Tagging resources .

          (structure)
              Adds metadata, in the form of a key:value pair, to the specified
              resource.

              For example, you could add the tag  Department:Sales  to  a  re-
              source to indicate that it pertains to your organization's sales
              department. You can also use tags for tag-based access control.

              To learn more about tagging, see Tagging resources .

              Key -> (string)
                 The first part of a key:value pair that forms a  tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales , the key is 'Department'.

              Value -> (string)
                 The second part of a key:value pair that forms a tag  associ-
                 ated  with  a given resource. For example, in the tag Depart-
                 ment:Sales , the value is 'Sales'.

                 Note that you can set the value of a tag to an empty  string,
                 but  you  can't  set the value of a tag to null. Omitting the
                 tag value is the same as using an empty string.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --language-id-settings (map)
          If using automatic language identification in your request  and  you
          want  to  apply  a  custom language model, a custom vocabulary, or a
          custom vocabulary filter, include LanguageIdSettings with the  rele-
          vant sub-parameters (VocabularyName , LanguageModelName , and Vocab-
          ularyFilterName ). Note that multi-language identification  (Identi-
          fyMultipleLanguages ) doesn't support custom language models.
              LanguageIdSettings  supports  two  to  five language codes. Each
              language code you include can have an associated custom language
              model, custom vocabulary, and custom vocabulary filter. The lan-
              guage codes that you specify must match the languages of the as-
              sociated custom language models, custom vocabularies, and custom
              vocabulary filters.

          It's recommended that you include LanguageOptions  when  using  Lan-
          guageIdSettings to ensure that the correct language dialect is iden-
          tified. For example, if you specify a custom vocabulary that  is  in
          en-US  but  Amazon Transcribe determines that the language spoken in
          your media is en-AU , your custom vocabulary is not applied to  your
          transcription.  If  you include LanguageOptions and include en-US as
          the only English language dialect, your custom vocabulary is applied
          to your transcription.

          If you want to include a custom language model with your request but
          do not want to use automatic language  identification,  use  instead
          the  parameter with the LanguageModelName sub-parameter. If you want
          to include a custom vocabulary or a  custom  vocabulary  filter  (or
          both)  with  your  request but do not want to use automatic language
          identification, use instead the parameter with the VocabularyName or
          VocabularyFilterName (or both) sub-parameter.

          key -> (string)

          value -> (structure)
              If  using  automatic language identification in your request and
              you want to apply a custom language model, a custom  vocabulary,
              or  a  custom vocabulary filter, include LanguageIdSettings with
              the relevant sub-parameters (VocabularyName ,  LanguageModelName
              , and VocabularyFilterName ). Note that multi-language identifi-
              cation (IdentifyMultipleLanguages ) doesn't support custom  lan-
              guage models.
                 LanguageIdSettings  supports two to five language codes. Each
                 language code you include can have an associated custom  lan-
                 guage model, custom vocabulary, and custom vocabulary filter.
                 The language codes that you specify must match the  languages
                 of  the  associated custom language models, custom vocabular-
                 ies, and custom vocabulary filters.

              It's recommended that you  include  LanguageOptions  when  using
              LanguageIdSettings  to  ensure that the correct language dialect
              is identified. For example, if you specify a  custom  vocabulary
              that  is in en-US but Amazon Transcribe determines that the lan-
              guage spoken in your media is en-AU , your custom vocabulary  is
              not  applied  to  your transcription. If you include LanguageOp-
              tions and include en-US as the only  English  language  dialect,
              your custom vocabulary is applied to your transcription.

              If you want to include a custom language model with your request
              but do not want to use automatic  language  identification,  use
              instead  the parameter with the LanguageModelName sub-parameter.
              If you want to include a custom vocabulary or a  custom  vocabu-
              lary  filter  (or both) with your request but do not want to use
              automatic language identification,  use  instead  the  parameter
              with   the  VocabularyName  or  VocabularyFilterName  (or  both)
              sub-parameter.

              VocabularyName -> (string)
                 The name of the custom vocabulary you want to use  when  pro-
                 cessing  your  transcription job. Custom vocabulary names are
                 case sensitive.

                 The language of the specified custom  vocabulary  must  match
                 the  language code that you specify in your transcription re-
                 quest. If the languages don't match,  the  custom  vocabulary
                 isn't  applied.  There  are  no errors or warnings associated
                 with a language mismatch.

              VocabularyFilterName -> (string)
                 The name of the custom vocabulary filter you want to use when
                 processing  your  transcription job. Custom vocabulary filter
                 names are case sensitive.

                 The language of the specified custom vocabulary  filter  must
                 match  the  language code that you specify in your transcrip-
                 tion request. If the languages don't match, the custom vocab-
                 ulary  filter  isn't applied. There are no errors or warnings
                 associated with a language mismatch.

                 Note that if you include  VocabularyFilterName  in  your  re-
                 quest, you must also include VocabularyFilterMethod .

              LanguageModelName -> (string)
                 The  name  of  the custom language model you want to use when
                 processing your transcription job. Note that custom  language
                 model names are case sensitive.

                 The  language  of  the  specified  custom language model must
                 match the language code that you specify in  your  transcrip-
                 tion  request.  If the languages don't match, the custom lan-
                 guage model isn't applied. There are no  errors  or  warnings
                 associated with a language mismatch.

       Shorthand Syntax:

            KeyName1=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string,KeyName2=VocabularyName=string,VocabularyFilterName=string,LanguageModelName=string

          Where valid key names are:
            af-ZA
            ar-AE
            ar-SA
            da-DK
            de-CH
            de-DE
            en-AB
            en-AU
            en-GB
            en-IE
            en-IN
            en-US
            en-WL
            es-ES
            es-US
            fa-IR
            fr-CA
            fr-FR
            he-IL
            hi-IN
            id-ID
            it-IT
            ja-JP
            ko-KR
            ms-MY
            nl-NL
            pt-BR
            pt-PT
            ru-RU
            ta-IN
            te-IN
            tr-TR
            zh-CN
            zh-TW
            th-TH
            en-ZA
            en-NZ
            vi-VN
            sv-SE

       JSON Syntax:

          {"af-ZA"|"ar-AE"|"ar-SA"|"da-DK"|"de-CH"|"de-DE"|"en-AB"|"en-AU"|"en-GB"|"en-IE"|"en-IN"|"en-US"|"en-WL"|"es-ES"|"es-US"|"fa-IR"|"fr-CA"|"fr-FR"|"he-IL"|"hi-IN"|"id-ID"|"it-IT"|"ja-JP"|"ko-KR"|"ms-MY"|"nl-NL"|"pt-BR"|"pt-PT"|"ru-RU"|"ta-IN"|"te-IN"|"tr-TR"|"zh-CN"|"zh-TW"|"th-TH"|"en-ZA"|"en-NZ"|"vi-VN"|"sv-SE": {
                "VocabularyName": "string",
                "VocabularyFilterName": "string",
                "LanguageModelName": "string"
              }
            ...}

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By default, the AWS CLI uses SSL when communicating with AWS  services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do not sign requests. Credentials will not be loaded if  this  argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The maximum socket read time in seconds. If the value is set to 0,  the
       socket  read  will be blocking and not timeout. The default value is 60
       seconds.

       --cli-connect-timeout (int)

       The maximum socket connect time in seconds. If the value is set  to  0,
       the  socket connect will be blocking and not timeout. The default value
       is 60 seconds.

EXAMPLES
       NOTE:
          To use the following examples, you must have the AWS  CLI  installed
          and  configured.  See  the Getting started guide in the AWS CLI User
          Guide for more information.

          Unless otherwise  stated,  all  examples  have  unix-like  quotation
          rules.  These  examples  will  need to be adapted to your terminal's
          quoting rules. See Using quotation marks with strings in the AWS CLI
          User Guide .

       Example 1: To transcribe an audio file

       The  following  start-transcription-job  example transcribes your audio
       file.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfile.json

       Contents of myfile.json:

          {
              "TranscriptionJobName": "cli-simple-transcription-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       For more information, see Getting Started (AWS Command Line  Interface)
       in the Amazon Transcribe Developer Guide.

       Example 2: To transcribe a multi-channel audio file

       The   following   start-transcription-job   example   transcribes  your
       multi-channel audio file.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysecondfile.json

       Contents of mysecondfile.json:

          {
              "TranscriptionJobName": "cli-channelid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "ChannelIdentification":true
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-channelid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:07:56.817000+00:00",
                  "CreationTime": "2020-09-17T16:07:56.784000+00:00",
                  "Settings": {
                      "ChannelIdentification": true
                  }
              }
          }

       For more information, see Transcribing Multi-Channel Audio in the  Ama-
       zon Transcribe Developer Guide.

       Example  3:  To  transcribe  an  audio  file and identify the different
       speakers

       The following start-transcription-job example  transcribes  your  audio
       file and identifies the speakers in the transcription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://mythirdfile.json

       Contents of mythirdfile.json:

          {
              "TranscriptionJobName": "cli-speakerid-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
              "ShowSpeakerLabels": true,
              "MaxSpeakerLabels": 2
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-speakerid-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-17T16:22:59.696000+00:00",
                  "CreationTime": "2020-09-17T16:22:59.676000+00:00",
                  "Settings": {
                      "ShowSpeakerLabels": true,
                      "MaxSpeakerLabels": 2
                  }
              }
          }

       For more information, see Identifying Speakers in the Amazon Transcribe
       Developer Guide.

       Example 4: To transcribe an audio file and mask any unwanted  words  in
       the transcription output

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfourthfile.json

       Contents of myfourthfile.json:

          {
              "TranscriptionJobName": "cli-filter-mask-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                    "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "mask"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-mask-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "mask"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 5: To transcribe an audio file and remove any unwanted words in
       the transcription output

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myfifthfile.json

       Contents of myfifthfile.json:

          {
              "TranscriptionJobName": "cli-filter-remove-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyFilterName": "your-vocabulary-filter",
                  "VocabularyFilterMethod": "remove"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-filter-remove-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyFilterName": "your-vocabulary-filter",
                      "VocabularyFilterMethod": "remove"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 6: To transcribe an audio file with increased accuracy using  a
       custom vocabulary

       The  following  start-transcription-job  example transcribes your audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://mysixthfile.json

       Contents of mysixthfile.json:

          {
              "TranscriptionJobName": "cli-vocab-job",
              "LanguageCode": "the-language-of-your-transcription-job",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              },
              "Settings":{
                  "VocabularyName": "your-vocabulary"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-vocab-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "the-language-of-your-transcription-job",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T16:36:18.568000+00:00",
                  "CreationTime": "2020-09-18T16:36:18.547000+00:00",
                  "Settings": {
                      "VocabularyName": "your-vocabulary"
                  }
              }
          }

       For  more information, see Filtering Transcriptions in the Amazon Tran-
       scribe Developer Guide.

       Example 7: To identify the language of an audio file and transcribe it

       The following start-transcription-job example  transcribes  your  audio
       file and uses a vocabulary filter you've previously created to mask any
       unwanted words.

          aws transcribe start-transcription-job \
              --cli-input-json file://myseventhfile.json

       Contents of myseventhfile.json:

          {
              "TranscriptionJobName": "cli-identify-language-transcription-job",
              "IdentifyLanguage": true,
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-identify-language-transcription-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/Amazon-S3-prefix/your-media-file-name.file-extension"
                  },
                  "StartTime": "2020-09-18T22:27:23.970000+00:00",
                  "CreationTime": "2020-09-18T22:27:23.948000+00:00",
                  "IdentifyLanguage": true
              }
          }

       For more information, see Identifying the Language in the Amazon  Tran-
       scribe Developer Guide.

       Example 8: To transcribe an audio file with personally identifiable in-
       formation redacted

       The following start-transcription-job example  transcribes  your  audio
       file  and  redacts any personally identifiable information in the tran-
       scription output.

          aws transcribe start-transcription-job \
              --cli-input-json file://myeighthfile.json

       Contents of myeigthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
              },
              "ContentRedaction": {
                  "RedactionOutput":"redacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:49:13.195000+00:00",
                  "CreationTime": "2020-09-25T23:49:13.176000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted"
                  }
              }
          }

       For more information, see Automatic Content  Redaction  in  the  Amazon
       Transcribe Developer Guide.

       Example 9: To generate a transcript with personally identifiable infor-
       mation (PII) redacted and an unredacted transcript

       The following start-transcription-job example generates  two  transcrp-
       tions of your audio file, one with the personally identifiable informa-
       tion redacted, and the other without any redactions.

          aws transcribe start-transcription-job \
              --cli-input-json file://myninthfile.json

       Contents of myninthfile.json:

          {
              "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
              "LanguageCode": "language-code",
              "Media": {
                    "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
              "ContentRedaction": {
                  "RedactionOutput":"redacted_and_unredacted",
                  "RedactionType":"PII"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-redaction-job-with-unredacted-transcript",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://Amazon-S3-Prefix/your-media-file.file-extension"
                  },
                  "StartTime": "2020-09-25T23:59:47.677000+00:00",
                  "CreationTime": "2020-09-25T23:59:47.653000+00:00",
                  "ContentRedaction": {
                      "RedactionType": "PII",
                      "RedactionOutput": "redacted_and_unredacted"
                  }
              }
          }

       For more information, see Automatic Content  Redaction  in  the  Amazon
       Transcribe Developer Guide.

       Example 10: To use a custom language model you've previously created to
       transcribe an audio file.

       The following start-transcription-job example  transcribes  your  audio
       file with a custom language model you've previously created.

          aws transcribe start-transcription-job \
              --cli-input-json file://mytenthfile.json

       Contents of mytenthfile.json:

          {
              "TranscriptionJobName": "cli-clm-2-job-1",
              "LanguageCode": "language-code",
              "Media": {
                  "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
              },
              "ModelSettings": {
                  "LanguageModelName":"cli-clm-2"
              }
          }

       Output:

          {
              "TranscriptionJob": {
                  "TranscriptionJobName": "cli-clm-2-job-1",
                  "TranscriptionJobStatus": "IN_PROGRESS",
                  "LanguageCode": "language-code",
                  "Media": {
                      "MediaFileUri": "s3://DOC-EXAMPLE-BUCKET/your-audio-file.file-extension"
                  },
                  "StartTime": "2020-09-28T17:56:01.835000+00:00",
                  "CreationTime": "2020-09-28T17:56:01.801000+00:00",
                  "ModelSettings": {
                      "LanguageModelName": "cli-clm-2"
                  }
              }
          }

       For more information, see Improving Domain-Specific Transcription Accu-
       racy with Custom Language Models in  the  Amazon  Transcribe  Developer
       Guide.

OUTPUT
       TranscriptionJob -> (structure)
          Provides  detailed  information about the current transcription job,
          including job status and, if applicable, failure reason.

          TranscriptionJobName -> (string)
              The name of the transcription job. Job names are case  sensitive
              and must be unique within an Amazon Web Services account.

          TranscriptionJobStatus -> (string)
              Provides the status of the specified transcription job.

              If  the  status  is  COMPLETED , the job is finished and you can
              find the results at the location specified in  TranscriptFileUri
              (or  RedactedTranscriptFileUri  ,  if  you  requested transcript
              redaction). If the status is FAILED , FailureReason provides de-
              tails on why your transcription job failed.

          LanguageCode -> (string)
              The  language  code  used to create your transcription job. This
              parameter  is  used  with  single-language  identification.  For
              multi-language identification requests, refer to the plural ver-
              sion of this parameter, LanguageCodes .

          MediaSampleRateHertz -> (integer)
              The sample rate, in hertz, of the audio track in your input  me-
              dia file.

          MediaFormat -> (string)
              The format of the input media file.

          Media -> (structure)
              Provides  the  Amazon  S3 location of the media file you used in
              your request.

              MediaFileUri -> (string)
                 The Amazon S3 location of the media file you  want  to  tran-
                 scribe. For example:

                 o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

                 o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

                 Note that the Amazon S3 bucket that contains your input media
                 must be located in the same Amazon Web Services Region  where
                 you're making your transcription request.

              RedactedMediaFileUri -> (string)
                 The  Amazon S3 location of the media file you want to redact.
                 For example:

                 o s3://DOC-EXAMPLE-BUCKET/my-media-file.flac

                 o s3://DOC-EXAMPLE-BUCKET/media-files/my-media-file.flac

                 Note that the Amazon S3 bucket that contains your input media
                 must  be located in the same Amazon Web Services Region where
                 you're making your transcription request.

                 WARNING:
                     RedactedMediaFileUri produces a redacted  audio  file  in
                     addition  to  a redacted transcript. It is only supported
                     for Call Analytics (StartCallAnalyticsJob ) transcription
                     requests.

          Transcript -> (structure)
              Provides  you  with the Amazon S3 URI you can use to access your
              transcript.

              TranscriptFileUri -> (string)
                 The Amazon S3 location of your transcript. You can  use  this
                 URI to access or download your transcript.

                 If  you  included  OutputBucketName in your transcription job
                 request, this is the URI of that bucket. If you also included
                 OutputKey in your request, your output is located in the path
                 you specified in your request.

                 If you didn't include OutputBucketName in your  transcription
                 job  request,  your transcript is stored in a service-managed
                 bucket, and TranscriptFileUri provides you with  a  temporary
                 URI you can use for secure access to your transcript.

                 NOTE:
                     Temporary  URIs for service-managed Amazon S3 buckets are
                     only valid for 15 minutes. If you get an AccesDenied  er-
                     ror,  you  can  get a new temporary URI by running a Get-
                     TranscriptionJob or ListTranscriptionJob request.

              RedactedTranscriptFileUri -> (string)
                 The Amazon S3 location of your redacted transcript.  You  can
                 use this URI to access or download your transcript.

                 If  you  included  OutputBucketName in your transcription job
                 request, this is the URI of that bucket. If you also included
                 OutputKey in your request, your output is located in the path
                 you specified in your request.

                 If you didn't include OutputBucketName in your  transcription
                 job  request,  your transcript is stored in a service-managed
                 bucket, and RedactedTranscriptFileUri  provides  you  with  a
                 temporary  URI  you  can  use for secure access to your tran-
                 script.

                 NOTE:
                     Temporary URIs for service-managed Amazon S3 buckets  are
                     only  valid for 15 minutes. If you get an AccesDenied er-
                     ror, you can get a new temporary URI by  running  a  Get-
                     TranscriptionJob or ListTranscriptionJob request.

          StartTime -> (timestamp)
              The date and time the specified transcription job began process-
              ing.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:32:58.789000-07:00 represents a tran-
              scription job that started processing at 12:32 PM UTC-7  on  May
              4, 2022.

          CreationTime -> (timestamp)
              The  date  and  time the specified transcription job request was
              made.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:32:58.761000-07:00 represents a tran-
              scription job that started processing at 12:32 PM UTC-7  on  May
              4, 2022.

          CompletionTime -> (timestamp)
              The  date and time the specified transcription job finished pro-
              cessing.

              Timestamps are in the format YYYY-MM-DD'T'HH:MM:SS.SSSSSS-UTC  .
              For example, 2022-05-04T12:33:13.922000-07:00 represents a tran-
              scription job that started processing at 12:33 PM UTC-7  on  May
              4, 2022.

          FailureReason -> (string)
              If TranscriptionJobStatus is FAILED , FailureReason contains in-
              formation about why the transcription job request failed.

              The FailureReason field contains one of the following values:

              o Unsupported media format . The media format specified in Medi-
                aFormat  isn't  valid. Refer to MediaFormat for a list of sup-
                ported formats.

              o The media format provided does not match  the  detected  media
                format  .  The  media  format specified in MediaFormat doesn't
                match the format of the input file. Check the media format  of
                your media file and correct the specified value.

              o Invalid sample rate for audio file . The sample rate specified
                in MediaSampleRateHertz isn't valid. The sample rate  must  be
                between 8,000 and 48,000 hertz.

              o The  sample  rate  provided does not match the detected sample
                rate .  The  sample  rate  specified  in  MediaSampleRateHertz
                doesn't  match  the  sample  rate detected in your input media
                file. Check the sample rate of your media file and correct the
                specified value.

              o Invalid  file size: file size too large . The size of your me-
                dia file is larger than what Amazon  Transcribe  can  process.
                For more information, refer to Guidelines and quotas .

              o Invalid  number  of  channels:  number of channels too large .
                Your audio contains more channels than  Amazon  Transcribe  is
                able to process. For more information, refer to Guidelines and
                quotas .

          Settings -> (structure)
              Provides information on any additional settings  that  were  in-
              cluded  in  your  request.  Additional  settings include channel
              identification, alternative transcriptions,  speaker  partition-
              ing, custom vocabularies, and custom vocabulary filters.

              VocabularyName -> (string)
                 The  name  of  the  custom vocabulary you want to use in your
                 transcription job request. This name is case sensitive,  can-
                 not  contain  spaces, and must be unique within an Amazon Web
                 Services account.

              ShowSpeakerLabels -> (boolean)
                 Enables speaker partitioning (diarization) in your transcrip-
                 tion  output. Speaker partitioning labels the speech from in-
                 dividual speakers in your media file.

                 If you enable ShowSpeakerLabels in  your  request,  you  must
                 also include MaxSpeakerLabels .

                 You can't include both ShowSpeakerLabels and ChannelIdentifi-
                 cation in the same request. Including both parameters returns
                 a BadRequestException .

                 For more information, see Partitioning speakers (diarization)
                 .

              MaxSpeakerLabels -> (integer)
                 Specify the maximum number of speakers you want to  partition
                 in your media.

                 Note that if your media contains more speakers than the spec-
                 ified number, multiple  speakers  are  treated  as  a  single
                 speaker.

                 If  you  specify the MaxSpeakerLabels field, you must set the
                 ShowSpeakerLabels field to true.

              ChannelIdentification -> (boolean)
                 Enables channel identification in multi-channel audio.

                 Channel identification transcribes the audio on each  channel
                 independently,  then appends the output for each channel into
                 one transcript.

                 You can't include both ShowSpeakerLabels and ChannelIdentifi-
                 cation in the same request. Including both parameters returns
                 a BadRequestException .

                 For more information, see Transcribing multi-channel audio .

              ShowAlternatives -> (boolean)
                 To include alternative transcriptions within your  transcrip-
                 tion  output,  include ShowAlternatives in your transcription
                 request.

                 If you have multi-channel audio and  do  not  enable  channel
                 identification,  your  audio  is  transcribed in a continuous
                 manner and your transcript does not separate  the  speech  by
                 channel.

                 If  you include ShowAlternatives , you must also include Max-
                 Alternatives , which is the  maximum  number  of  alternative
                 transcriptions you want Amazon Transcribe to generate.

                 For more information, see Alternative transcriptions .

              MaxAlternatives -> (integer)
                 Indicate the maximum number of alternative transcriptions you
                 want Amazon Transcribe to include in your transcript.

                 If you select a number greater than the number of alternative
                 transcriptions  generated  by Amazon Transcribe, only the ac-
                 tual number of alternative transcriptions are included.

                 If you include MaxAlternatives in your request, you must also
                 include ShowAlternatives with a value of true .

                 For more information, see Alternative transcriptions .

              VocabularyFilterName -> (string)
                 The  name  of the custom vocabulary filter you want to use in
                 your transcription job request. This name is case  sensitive,
                 cannot  contain  spaces,  and must be unique within an Amazon
                 Web Services account.

                 Note that if you include  VocabularyFilterName  in  your  re-
                 quest, you must also include VocabularyFilterMethod .

              VocabularyFilterMethod -> (string)
                 Specify how you want your custom vocabulary filter applied to
                 your transcript.

                 To replace words with *** , choose mask .

                 To delete words, choose remove .

                 To flag words without changing them, choose tag .

          ModelSettings -> (structure)
              Provides information on the custom language model  you  included
              in your request.

              LanguageModelName -> (string)
                 The  name  of  the custom language model you want to use when
                 processing your transcription job. Note that custom  language
                 model names are case sensitive.

                 The  language  of  the  specified  custom language model must
                 match the language code that you specify in  your  transcrip-
                 tion  request.  If the languages don't match, the custom lan-
                 guage model isn't applied. There are no  errors  or  warnings
                 associated with a language mismatch.

          JobExecutionSettings -> (structure)
              Provides  information  about how your transcription job was pro-
              cessed. This parameter shows if your request was queued and what
              data access role was used.

              AllowDeferredExecution -> (boolean)
                 Makes  it possible to enable job queuing when your concurrent
                 request limit is exceeded. When AllowDeferredExecution is set
                 to  true  ,  transcription job requests are placed in a queue
                 until the number of jobs falls below the  concurrent  request
                 limit. If AllowDeferredExecution is set to false and the num-
                 ber of transcription job requests exceed the  concurrent  re-
                 quest limit, you get a LimitExceededException error.

                 If  you  include  AllowDeferredExecution in your request, you
                 must also include DataAccessRoleArn .

              DataAccessRoleArn -> (string)
                 The Amazon Resource Name (ARN) of an IAM role that  has  per-
                 missions  to  access  the Amazon S3 bucket that contains your
                 input files. If the role that you specify doesnt have the ap-
                 propriate permissions to access the specified Amazon S3 loca-
                 tion, your request fails.

                 IAM  role  ARNs  have   the   format   arn:partition:iam::ac-
                 count:role/role-name-with-path       .      For      example:
                 arn:aws:iam::111122223333:role/Admin . For more  information,
                 see IAM ARNs .

                 Note  that  if you include DataAccessRoleArn in your request,
                 you must also include AllowDeferredExecution .

          ContentRedaction -> (structure)
              Indicates whether redaction was enabled in your transcript.

              RedactionType -> (string)
                 Specify the category of information you want to  redact;  PII
                 (personally  identifiable  information)  is  the  only  valid
                 value. You can use PiiEntityTypes to choose  which  types  of
                 PII you want to redact.

              RedactionOutput -> (string)
                 Specify  if  you  want  only a redacted transcript, or if you
                 want a redacted and an unredacted transcript.

                 When you choose redacted Amazon  Transcribe  creates  only  a
                 redacted transcript.

                 When  you  choose  redacted_and_unredacted  Amazon Transcribe
                 creates a redacted and an unredacted transcript (as two sepa-
                 rate files).

              PiiEntityTypes -> (list)
                 Specify  which  types  of personally identifiable information
                 (PII) you want to redact in your transcript. You can  include
                 as many types as you'd like, or you can select ALL .

                 (string)

          IdentifyLanguage -> (boolean)
              Indicates  whether automatic language identification was enabled
              (TRUE ) for the specified transcription job.

          IdentifyMultipleLanguages -> (boolean)
              Indicates whether automatic  multi-language  identification  was
              enabled (TRUE ) for the specified transcription job.

          LanguageOptions -> (list)
              Provides the language codes you specified in your request.

              (string)

          IdentifiedLanguageScore -> (float)
              The  confidence score associated with the language identified in
              your media file.

              Confidence scores are values between 0 and 1; a larger value in-
              dicates  a  higher probability that the identified language cor-
              rectly matches the language spoken in your media.

          LanguageCodes -> (list)
              The language codes used to create your transcription  job.  This
              parameter  is  used with multi-language identification. For sin-
              gle-language identification requests, refer to the singular ver-
              sion of this parameter, LanguageCode .

              (structure)
                 Provides  information  on  the speech contained in a discreet
                 utterance when multi-language identification  is  enabled  in
                 your  request.  This  utterance  represents a block of speech
                 consisting of one language, preceded or followed by  a  block
                 of speech in a different language.

                 LanguageCode -> (string)
                     Provides  the  language code for each language identified
                     in your media.

                 DurationInSeconds -> (float)
                     Provides the total time, in seconds, each identified lan-
                     guage is spoken in your media.

          Tags -> (list)
              The  tags, each in the form of a key:value pair, assigned to the
              specified transcription job.

              (structure)
                 Adds metadata, in the form of a key:value pair, to the speci-
                 fied resource.

                 For  example, you could add the tag Department:Sales to a re-
                 source to indicate that it pertains  to  your  organization's
                 sales  department. You can also use tags for tag-based access
                 control.

                 To learn more about tagging, see Tagging resources .

                 Key -> (string)
                     The first part of a key:value pair that forms a tag asso-
                     ciated with a given resource. For example, in the tag De-
                     partment:Sales , the key is 'Department'.

                 Value -> (string)
                     The second part of a key:value pair that forms a tag  as-
                     sociated  with  a given resource. For example, in the tag
                     Department:Sales , the value is 'Sales'.

                     Note that you can set the value of  a  tag  to  an  empty
                     string,  but  you  can't  set the value of a tag to null.
                     Omitting the tag value is the  same  as  using  an  empty
                     string.

          Subtitles -> (structure)
              Indicates  whether subtitles were generated with your transcrip-
              tion.

              Formats -> (list)
                 Provides the format of your subtitle files. If  your  request
                 included  both  WebVTT (vtt ) and SubRip (srt ) formats, both
                 formats are shown.

                 (string)

              SubtitleFileUris -> (list)
                 The Amazon S3 location of your transcript. You can  use  this
                 URI  to  access or download your subtitle file. Your subtitle
                 file is stored in the same location as  your  transcript.  If
                 you  specified  both  WebVTT and SubRip subtitle formats, two
                 URIs are provided.

                 If you included OutputBucketName in  your  transcription  job
                 request, this is the URI of that bucket. If you also included
                 OutputKey in your request, your output is located in the path
                 you specified in your request.

                 If  you didn't include OutputBucketName in your transcription
                 job request, your subtitle file is stored in  a  service-man-
                 aged bucket, and TranscriptFileUri provides you with a tempo-
                 rary URI you can use for secure access to your subtitle file.

                 NOTE:
                     Temporary URIs for service-managed Amazon S3 buckets  are
                     only  valid for 15 minutes. If you get an AccesDenied er-
                     ror, you can get a new temporary URI by  running  a  Get-
                     TranscriptionJob or ListTranscriptionJob request.

                 (string)

              OutputStartIndex -> (integer)
                 Provides  the  start  index value for your subtitle files. If
                 you did not specify a value  in  your  request,  the  default
                 value of 0 is used.

          LanguageIdSettings -> (map)
              Provides  the  name  and language of all custom language models,
              custom vocabularies, and custom vocabulary filters that you  in-
              cluded in your request.

              key -> (string)

              value -> (structure)
                 If  using  automatic  language identification in your request
                 and you want to apply a custom language model, a  custom  vo-
                 cabulary,  or a custom vocabulary filter, include LanguageId-
                 Settings with the relevant sub-parameters  (VocabularyName  ,
                 LanguageModelName  ,  and  VocabularyFilterName  ). Note that
                 multi-language  identification  (IdentifyMultipleLanguages  )
                 doesn't support custom language models.
                     LanguageIdSettings  supports  two to five language codes.
                     Each language code you include  can  have  an  associated
                     custom  language model, custom vocabulary, and custom vo-
                     cabulary filter. The language codes that you specify must
                     match  the  languages  of  the associated custom language
                     models, custom vocabularies, and custom  vocabulary  fil-
                     ters.

                 It's  recommended that you include LanguageOptions when using
                 LanguageIdSettings to ensure that the  correct  language  di-
                 alect is identified. For example, if you specify a custom vo-
                 cabulary that is in en-US but  Amazon  Transcribe  determines
                 that the language spoken in your media is en-AU , your custom
                 vocabulary is not applied to your transcription. If  you  in-
                 clude  LanguageOptions  and include en-US as the only English
                 language dialect, your custom vocabulary is applied  to  your
                 transcription.

                 If  you want to include a custom language model with your re-
                 quest but do not want to use automatic  language  identifica-
                 tion,  use  instead  the parameter with the LanguageModelName
                 sub-parameter. If you want to include a custom vocabulary  or
                 a custom vocabulary filter (or both) with your request but do
                 not want to use automatic language  identification,  use  in-
                 stead the parameter with the VocabularyName or VocabularyFil-
                 terName (or both) sub-parameter.

                 VocabularyName -> (string)
                     The name of the custom vocabulary you want  to  use  when
                     processing  your  transcription  job.  Custom  vocabulary
                     names are case sensitive.

                     The language of  the  specified  custom  vocabulary  must
                     match  the  language  code that you specify in your tran-
                     scription request. If the languages don't match, the cus-
                     tom  vocabulary  isn't  applied.  There  are no errors or
                     warnings associated with a language mismatch.

                 VocabularyFilterName -> (string)
                     The name of the custom vocabulary filter you want to  use
                     when processing your transcription job. Custom vocabulary
                     filter names are case sensitive.

                     The language of the specified  custom  vocabulary  filter
                     must  match  the  language  code that you specify in your
                     transcription request. If the languages don't match,  the
                     custom  vocabulary filter isn't applied. There are no er-
                     rors or warnings associated with a language mismatch.

                     Note that if you include VocabularyFilterName in your re-
                     quest, you must also include VocabularyFilterMethod .

                 LanguageModelName -> (string)
                     The  name  of  the  custom language model you want to use
                     when processing your transcription job. Note that  custom
                     language model names are case sensitive.

                     The  language of the specified custom language model must
                     match the language code that you specify  in  your  tran-
                     scription request. If the languages don't match, the cus-
                     tom language model isn't applied. There are no errors  or
                     warnings associated with a language mismatch.



                                                     START-TRANSCRIPTION-JOB()
