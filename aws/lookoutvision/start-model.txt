START-MODEL()                                                    START-MODEL()



NAME
       start-model -

DESCRIPTION
       Starts  the  running  of  the  version  of an Amazon Lookout for Vision
       model. Starting a model takes a while to complete. To check the current
       state of the model, use  DescribeModel .

       A model is ready to use when its status is HOSTED .

       Once  the  model is running, you can detect custom labels in new images
       by calling  DetectAnomalies .

       NOTE:
          You are charged for the amount of time that the model is running. To
          stop a running model, call  StopModel .

       This operation requires permissions to perform the lookoutvision:Start-
       Model operation.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            start-model
          --project-name <value>
          --model-version <value>
          --min-inference-units <value>
          [--client-token <value>]
          [--max-inference-units <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --project-name (string)
          The name of the project that contains the model  that  you  want  to
          start.

       --model-version (string)
          The version of the model that you want to start.

       --min-inference-units (integer)
          The  minimum  number  of  inference units to use. A single inference
          unit represents 1 hour of processing. Use a  higher  number  to  in-
          crease  the  TPS  throughput  of your model. You are charged for the
          number of inference units that you use.

       --client-token (string)
          ClientToken is an idempotency token that ensures a  call  to  Start-
          Model  completes  only once. You choose the value to pass. For exam-
          ple, An issue might prevent you from getting a response from  Start-
          Model  . In this case, safely retry your call to StartModel by using
          the same ClientToken parameter value.

          If you don't supply a value for ClientToken , the AWS  SDK  you  are
          using inserts a value for you. This prevents retries after a network
          error from making multiple start requests. You'll  need  to  provide
          your own value for other use cases.

          An error occurs if the other input parameters are not the same as in
          the first request. Using a different value for ClientToken  is  con-
          sidered  a  new  call to StartModel . An idempotency token is active
          for 8 hours.

       --max-inference-units (integer)
          The maximum number of inference units to use  for  auto-scaling  the
          model.  If  you  don't  specify  a  value, Amazon Lookout for Vision
          doesn't auto-scale the model.

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       Status -> (string)
          The current running status of the model.



                                                                 START-MODEL()
