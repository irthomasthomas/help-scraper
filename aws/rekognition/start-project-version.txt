START-PROJECT-VERSION()                                START-PROJECT-VERSION()



NAME
       start-project-version -

DESCRIPTION
       Starts  the running of the version of a model. Starting a model takes a
       while to complete. To check the current state of the  model,  use   De-
       scribeProjectVersions .

       Once  the  model is running, you can detect custom labels in new images
       by calling  DetectCustomLabels .

       NOTE:
          You are charged for the amount of time that the model is running. To
          stop a running model, call  StopProjectVersion .

       For  more  information, see Running a trained Amazon Rekognition Custom
       Labels model in the Amazon Rekognition Custom Labels Guide.

       This operation requires permissions to perform  the  rekognition:Start-
       ProjectVersion action.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            start-project-version
          --project-version-arn <value>
          --min-inference-units <value>
          [--max-inference-units <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --project-version-arn (string)
          The  Amazon Resource Name(ARN) of the model version that you want to
          start.

       --min-inference-units (integer)
          The minimum number of inference units to  use.  A  single  inference
          unit represents 1 hour of processing.

          For  information  about  the number of transactions per second (TPS)
          that an inference unit can support, see  Running  a  trained  Amazon
          Rekognition Custom Labels model in the Amazon Rekognition Custom La-
          bels Guide.

          Use a higher number to increase the TPS throughput  of  your  model.
          You are charged for the number of inference units that you use.

       --max-inference-units (integer)
          The  maximum  number  of inference units to use for auto-scaling the
          model. If you don't specify a value, Amazon Rekognition  Custom  La-
          bels doesn't auto-scale the model.

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       Status -> (string)
          The current running status of the model.



                                                       START-PROJECT-VERSION()
