CREATE-TRAINING-JOB()                                    CREATE-TRAINING-JOB()



NAME
       create-training-job -

DESCRIPTION
       Starts  a model training job. After training completes, SageMaker saves
       the resulting model artifacts to an Amazon S3 location that  you  spec-
       ify.

       If  you choose to host your model using SageMaker hosting services, you
       can use the resulting model artifacts as part of  the  model.  You  can
       also  use  the artifacts in a machine learning service other than Sage-
       Maker, provided that you know how to use them for inference.

       In the request body, you provide the following:

       o AlgorithmSpecification - Identifies the training algorithm to use.

       o HyperParameters - Specify these algorithm-specific parameters to  en-
         able the estimation of model parameters during training. Hyperparame-
         ters can be tuned to optimize this learning process. For  a  list  of
         hyperparameters  for  each  training algorithm provided by SageMaker,
         see Algorithms .

       WARNING:
          Do not include any security-sensitive information including  account
          access  IDs,  secrets  or tokens in any hyperparameter field. If the
          use of security-sensitive credentials are detected,  SageMaker  will
          reject your training job request and return an exception error.

       o InputDataConfig  -  Describes  the input required by the training job
         and the Amazon S3, EFS, or FSx location where it is stored.

       o OutputDataConfig - Identifies the Amazon S3  bucket  where  you  want
         SageMaker to save the results of model training.

       o ResourceConfig  - Identifies the resources, ML compute instances, and
         ML storage volumes to  deploy  for  model  training.  In  distributed
         training, you specify more than one instance.

       o EnableManagedSpotTraining  -  Optimize  the  cost of training machine
         learning models by up to 80% by using Amazon EC2 Spot instances.  For
         more information, see Managed Spot Training .

       o RoleArn  -  The  Amazon Resource Name (ARN) that SageMaker assumes to
         perform tasks on your behalf during model training.  You  must  grant
         this  role  the  necessary permissions so that SageMaker can success-
         fully complete model training.

       o StoppingCondition - To help cap training costs, use  MaxRuntimeInSec-
         onds  to  set  a time limit for training. Use MaxWaitTimeInSeconds to
         specify how long a managed spot training job has to complete.

       o Environment - The environment variables to set  in  the  Docker  con-
         tainer.

       o RetryStrategy  -  The  number  of times to retry the job when the job
         fails due to an InternalServerError .

       For more information about SageMaker, see How It Works .

       See also: AWS API Documentation

SYNOPSIS
            create-training-job
          --training-job-name <value>
          [--hyper-parameters <value>]
          --algorithm-specification <value>
          --role-arn <value>
          [--input-data-config <value>]
          --output-data-config <value>
          --resource-config <value>
          [--vpc-config <value>]
          --stopping-condition <value>
          [--tags <value>]
          [--enable-network-isolation | --no-enable-network-isolation]
          [--enable-inter-container-traffic-encryption | --no-enable-inter-container-traffic-encryption]
          [--enable-managed-spot-training | --no-enable-managed-spot-training]
          [--checkpoint-config <value>]
          [--debug-hook-config <value>]
          [--debug-rule-configurations <value>]
          [--tensor-board-output-config <value>]
          [--experiment-config <value>]
          [--profiler-config <value>]
          [--profiler-rule-configurations <value>]
          [--environment <value>]
          [--retry-strategy <value>]
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]
          [--debug]
          [--endpoint-url <value>]
          [--no-verify-ssl]
          [--no-paginate]
          [--output <value>]
          [--query <value>]
          [--profile <value>]
          [--region <value>]
          [--version <value>]
          [--color <value>]
          [--no-sign-request]
          [--ca-bundle <value>]
          [--cli-read-timeout <value>]
          [--cli-connect-timeout <value>]

OPTIONS
       --training-job-name (string)
          The name of the training job. The name must be unique within an Ama-
          zon Web Services Region in an Amazon Web Services account.

       --hyper-parameters (map)
          Algorithm-specific  parameters  that  influence  the  quality of the
          model.  You  set  hyperparameters  before  you  start  the  learning
          process.  For  a list of hyperparameters for each training algorithm
          provided by SageMaker, see Algorithms .

          You can specify a maximum of 100 hyperparameters. Each  hyperparame-
          ter  is a key-value pair. Each key and value is limited to 256 char-
          acters, as specified by the Length Constraint .

          WARNING:
              Do not include any security-sensitive information including  ac-
              count access IDs, secrets or tokens in any hyperparameter field.
              If the use of security-sensitive credentials are detected, Sage-
              Maker will reject your training job request and return an excep-
              tion error.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --algorithm-specification (structure)
          The registry path of the Docker image that contains the training al-
          gorithm  and  algorithm-specific metadata, including the input mode.
          For more information about algorithms  provided  by  SageMaker,  see
          Algorithms  .  For  information about providing your own algorithms,
          see Using Your Own Algorithms with Amazon SageMaker .

          TrainingImage -> (string)
              The registry path of the Docker image that contains the training
              algorithm. For information about docker registry paths for Sage-
              Maker built-in algorithms, see Docker Registry Paths and Example
              Code  in  the  Amazon SageMaker developer guide . SageMaker sup-
              ports  both   registry/repository[:tag]   and   registry/reposi-
              tory[@digest] image path formats. For more information about us-
              ing your custom training container, see  Using  Your  Own  Algo-
              rithms with Amazon SageMaker .

              NOTE:
                 You  must specify either the algorithm name to the Algorithm-
                 Name parameter or the image URI of the algorithm container to
                 the TrainingImage parameter.

                 For  more  information, see the note in the AlgorithmName pa-
                 rameter description.

          AlgorithmName -> (string)
              The name of the algorithm resource to use for the training  job.
              This must be an algorithm resource that you created or subscribe
              to on Amazon Web Services Marketplace.

              NOTE:
                 You must specify either the algorithm name to the  Algorithm-
                 Name parameter or the image URI of the algorithm container to
                 the TrainingImage parameter.

                 Note that the AlgorithmName parameter is  mutually  exclusive
                 with  the TrainingImage parameter. If you specify a value for
                 the AlgorithmName parameter, you can't specify  a  value  for
                 TrainingImage , and vice versa.

                 If  you  specify values for both parameters, the training job
                 might break; if you don't specify any value for both  parame-
                 ters, the training job might raise a null error.

          TrainingInputMode -> (string)
              The  training  input  mode that the algorithm supports. For more
              information about input modes, see Algorithms .
                 Pipe mode

              If an algorithm supports Pipe  mode,  Amazon  SageMaker  streams
              data directly from Amazon S3 to the container.
                 File mode

              If  an  algorithm  supports  File  mode, SageMaker downloads the
              training data from S3 to the provisioned ML storage volume,  and
              mounts  the directory to the Docker volume for the training con-
              tainer.

              You must provision the ML storage volume with sufficient  capac-
              ity  to  accommodate the data downloaded from S3. In addition to
              the training data, the ML storage volume also stores the  output
              model.  The  algorithm  container  uses the ML storage volume to
              also store intermediate information, if any.

              For distributed algorithms, training data  is  distributed  uni-
              formly.  Your training duration is predictable if the input data
              objects sizes are approximately the  same.  SageMaker  does  not
              split  the  files  any further for model training. If the object
              sizes are skewed, training won't be optimal as the data  distri-
              bution  is  also  skewed  when one host in a training cluster is
              overloaded, thus becoming a bottleneck in training.
                 FastFile mode

              If an algorithm supports FastFile mode, SageMaker  streams  data
              directly from S3 to the container with no code changes, and pro-
              vides file system access to the data.  Users  can  author  their
              training  script  to  interact  with these files as if they were
              stored on disk.
                 FastFile mode works best when the data is read  sequentially.
                 Augmented  manifest  files aren't supported. The startup time
                 is lower when there are fewer files in  the  S3  bucket  pro-
                 vided.

          MetricDefinitions -> (list)
              A  list  of metric definition objects. Each object specifies the
              metric name and regular  expressions  used  to  parse  algorithm
              logs. SageMaker publishes each metric to Amazon CloudWatch.

              (structure)
                 Specifies  a  metric  that  the  training algorithm writes to
                 stderr or stdout .  SageMakerhyperparameter  tuning  captures
                 all  defined  metrics. You specify one metric that a hyperpa-
                 rameter tuning job uses as its objective metric to choose the
                 best training job.

                 Name -> (string)
                     The name of the metric.

                 Regex -> (string)
                     A regular expression that searches the output of a train-
                     ing job and gets the value of the metric. For more infor-
                     mation about using regular expressions to define metrics,
                     see Defining Objective Metrics .

          EnableSageMakerMetricsTimeSeries -> (boolean)
              To generate and save time-series metrics during training, set to
              true  . The default is false and time-series metrics aren't gen-
              erated except in the following cases:

              o You use one of the SageMaker built-in algorithms

              o You use one of the following Prebuilt SageMaker Docker  Images
                :

                o Tensorflow (version >= 1.15)

                o MXNet (version >= 1.6)

                o PyTorch (version >= 1.3)

              o You specify at least one  MetricDefinition

          ContainerEntrypoint -> (list)
              The  entrypoint  script  for  a  Docker  container used to run a
              training job. This script  takes  precedence  over  the  default
              train  processing  instructions.  See  How Amazon SageMaker Runs
              Your Training Image for more information.

              (string)

          ContainerArguments -> (list)
              The arguments for a container used to run a  training  job.  See
              How Amazon SageMaker Runs Your Training Image for additional in-
              formation.

              (string)

          TrainingImageConfig -> (structure)
              The configuration to use an image from a private Docker registry
              for a training job.

              TrainingRepositoryAccessMode -> (string)
                 The  method that your training job will use to gain access to
                 the images in your private Docker registry. For access to  an
                 image in a private Docker registry, set to Vpc .

              TrainingRepositoryAuthConfig -> (structure)
                 An object containing authentication information for a private
                 Docker registry containing your training images.

                 TrainingRepositoryCredentialsProviderArn -> (string)
                     The Amazon Resource Name (ARN) of an Amazon Web  Services
                     Lambda function used to give SageMaker access credentials
                     to your private Docker registry.

       Shorthand Syntax:

          TrainingImage=string,AlgorithmName=string,TrainingInputMode=string,MetricDefinitions=[{Name=string,Regex=string},{Name=string,Regex=string}],EnableSageMakerMetricsTimeSeries=boolean,ContainerEntrypoint=string,string,ContainerArguments=string,string,TrainingImageConfig={TrainingRepositoryAccessMode=string,TrainingRepositoryAuthConfig={TrainingRepositoryCredentialsProviderArn=string}}

       JSON Syntax:

          {
            "TrainingImage": "string",
            "AlgorithmName": "string",
            "TrainingInputMode": "Pipe"|"File"|"FastFile",
            "MetricDefinitions": [
              {
                "Name": "string",
                "Regex": "string"
              }
              ...
            ],
            "EnableSageMakerMetricsTimeSeries": true|false,
            "ContainerEntrypoint": ["string", ...],
            "ContainerArguments": ["string", ...],
            "TrainingImageConfig": {
              "TrainingRepositoryAccessMode": "Platform"|"Vpc",
              "TrainingRepositoryAuthConfig": {
                "TrainingRepositoryCredentialsProviderArn": "string"
              }
            }
          }

       --role-arn (string)
          The Amazon Resource Name (ARN) of an IAM role that SageMaker can as-
          sume to perform tasks on your behalf.

          During model training, SageMaker needs your permission to read input
          data from an S3 bucket, download a Docker image that contains train-
          ing  code, write model artifacts to an S3 bucket, write logs to Ama-
          zon CloudWatch Logs, and publish metrics to Amazon  CloudWatch.  You
          grant  permissions  for  all of these tasks to an IAM role. For more
          information, see SageMaker Roles .

          NOTE:
              To be able to pass this role to SageMaker, the  caller  of  this
              API must have the iam:PassRole permission.

       --input-data-config (list)
          An  array  of Channel objects. Each channel is a named input source.
          InputDataConfig describes the input data and its location.

          Algorithms can accept input data from one or more channels. For  ex-
          ample,  an  algorithm  might have two channels of input data, train-
          ing_data and validation_data . The configuration  for  each  channel
          provides  the  S3,  EFS,  or  FSx  location  where the input data is
          stored. It also provides information about the stored data: the MIME
          type,  compression method, and whether the data is wrapped in Recor-
          dIO format.

          Depending on the input mode that the algorithm  supports,  SageMaker
          either  copies  input data files from an S3 bucket to a local direc-
          tory in the  Docker  container,  or  makes  it  available  as  input
          streams.  For  example,  if  you specify an EFS location, input data
          files are available as input streams. They do not need to  be  down-
          loaded.

          (structure)
              A  channel  is a named input source that training algorithms can
              consume.

              ChannelName -> (string)
                 The name of the channel.

              DataSource -> (structure)
                 The location of the channel data.

                 S3DataSource -> (structure)
                     The S3 location of the data  source  that  is  associated
                     with a channel.

                     S3DataType -> (string)
                        If  you  choose S3Prefix , S3Uri identifies a key name
                        prefix. SageMaker uses  all  objects  that  match  the
                        specified key name prefix for model training.

                        If  you  choose ManifestFile , S3Uri identifies an ob-
                        ject that is a manifest file containing a list of  ob-
                        ject  keys  that  you  want SageMaker to use for model
                        training.

                        If you choose AugmentedManifestFile , S3Uri identifies
                        an  object  that is an augmented manifest file in JSON
                        lines format. This file contains the data you want  to
                        use for model training. AugmentedManifestFile can only
                        be used if the Channel's input mode is Pipe .

                     S3Uri -> (string)
                        Depending on the value specified for the S3DataType  ,
                        identifies either a key name prefix or a manifest. For
                        example:

                        o A key name prefix might look like this: s3://bucket-
                          name/exampleprefix

                        o A manifest might look like this: s3://bucketname/ex-
                          ample.manifest   A manifest is an S3 object which is
                          a  JSON file consisting of an array of elements. The
                          first element is a prefix which is followed  by  one
                          or  more suffixes. SageMaker appends the suffix ele-
                          ments to the prefix to get a full  set  of  S3Uri  .
                          Note that the prefix must be a valid non-empty S3Uri
                          that precludes  users  from  specifying  a  manifest
                          whose  individual S3Uri is sourced from different S3
                          buckets. The following code example  shows  a  valid
                          manifest    format:      [   {"prefix":   "s3://cus-
                          tomer_bucket/some/prefix/"},                  "rela-
                          tive/path/to/custdata-1",       "relative/path/cust-
                          data-2",    ...     "relative/path/custdata-N"     ]
                          This JSON is equivalent to the following S3Uri list:
                          s3://customer_bucket/some/prefix/rela-
                          tive/path/to/custdata-1                    s3://cus-
                          tomer_bucket/some/prefix/relative/path/custdata-2
                          ...           s3://customer_bucket/some/prefix/rela-
                          tive/path/custdata-N   The complete set of S3Uri  in
                          this  manifest is the input data for the channel for
                          this data source. The object that each S3Uri  points
                          to  must  be readable by the IAM role that SageMaker
                          uses to perform tasks on your behalf.

                     S3DataDistributionType -> (string)
                        If you want SageMaker to replicate the entire  dataset
                        on each ML compute instance that is launched for model
                        training, specify FullyReplicated .

                        If you want SageMaker to replicate a subset of data on
                        each  ML  compute  instance that is launched for model
                        training, specify ShardedByS3Key . If there are  n  ML
                        compute  instances  launched  for a training job, each
                        instance gets approximately 1/n of the  number  of  S3
                        objects.  In this case, model training on each machine
                        uses only the subset of training data.

                        Don't choose more ML compute  instances  for  training
                        than available S3 objects. If you do, some nodes won't
                        get any data and you will pay for  nodes  that  aren't
                        getting  any  training data. This applies in both File
                        and Pipe modes. Keep this in mind when developing  al-
                        gorithms.

                        In  distributed  training,  where  you use multiple ML
                        compute EC2 instances, you might choose ShardedByS3Key
                        .  If  the algorithm requires copying training data to
                        the ML storage volume (when TrainingInputMode  is  set
                        to File ), this copies 1/n of the number of objects.

                     AttributeNames -> (list)
                        A  list of one or more attribute names to use that are
                        found in a specified augmented manifest file.

                        (string)

                     InstanceGroupNames -> (list)
                        A list of names of instance groups that get data  from
                        the S3 data source.

                        (string)

                 FileSystemDataSource -> (structure)
                     The file system that is associated with a channel.

                     FileSystemId -> (string)
                        The file system id.

                     FileSystemAccessMode -> (string)
                        The  access mode of the mount of the directory associ-
                        ated with the channel. A directory can be mounted  ei-
                        ther in ro (read-only) or rw (read-write) mode.

                     FileSystemType -> (string)
                        The file system type.

                     DirectoryPath -> (string)
                        The  full  path to the directory to associate with the
                        channel.

              ContentType -> (string)
                 The MIME type of the data.

              CompressionType -> (string)
                 If training data is compressed, the compression type. The de-
                 fault  value  is  None . CompressionType is used only in Pipe
                 input mode. In File mode, leave this field unset or set it to
                 None.

              RecordWrapperType -> (string)
                 Specify  RecordIO as the value when input data is in raw for-
                 mat but the training algorithm requires the RecordIO  format.
                 In  this case, SageMaker wraps each individual S3 object in a
                 RecordIO record. If the input data  is  already  in  RecordIO
                 format, you don't need to set this attribute. For more infor-
                 mation, see Create a Dataset Using RecordIO .

                 In File mode, leave this field unset or set it to None.

              InputMode -> (string)
                 (Optional) The input mode to use for the data  channel  in  a
                 training  job. If you don't set a value for InputMode , Sage-
                 Maker uses the value set for TrainingInputMode . Use this pa-
                 rameter to override the TrainingInputMode setting in a  Algo-
                 rithmSpecification request when you have a channel that needs
                 a  different  input mode from the training job's general set-
                 ting. To download the data from Amazon Simple Storage Service
                 (Amazon  S3)  to the provisioned ML storage volume, and mount
                 the directory to a Docker volume, use  File  input  mode.  To
                 stream  data directly from Amazon S3 to the container, choose
                 Pipe input mode.

                 To use a model for incremental training,  choose  File  input
                 model.

              ShuffleConfig -> (structure)
                 A  configuration  for  a  shuffle  option for input data in a
                 channel. If you use S3Prefix for S3DataType ,  this  shuffles
                 the  results  of  the S3 key prefix matches. If you use Mani-
                 festFile , the order of the S3 object references in the Mani-
                 festFile  is shuffled. If you use AugmentedManifestFile , the
                 order of the JSON lines in the AugmentedManifestFile is shuf-
                 fled. The shuffling order is determined using the Seed value.

                 For  Pipe input mode, shuffling is done at the start of every
                 epoch. With large datasets this ensures that the order of the
                 training  data  is  different for each epoch, it helps reduce
                 bias and possible overfitting. In a multi-node  training  job
                 when ShuffleConfig is combined with S3DataDistributionType of
                 ShardedByS3Key , the data is shuffled across  nodes  so  that
                 the  content  sent  to  a  particular node on the first epoch
                 might be sent to a different node on the second epoch.

                 Seed -> (long)
                     Determines the shuffling order in ShuffleConfig value.

       JSON Syntax:

          [
            {
              "ChannelName": "string",
              "DataSource": {
                "S3DataSource": {
                  "S3DataType": "ManifestFile"|"S3Prefix"|"AugmentedManifestFile",
                  "S3Uri": "string",
                  "S3DataDistributionType": "FullyReplicated"|"ShardedByS3Key",
                  "AttributeNames": ["string", ...],
                  "InstanceGroupNames": ["string", ...]
                },
                "FileSystemDataSource": {
                  "FileSystemId": "string",
                  "FileSystemAccessMode": "rw"|"ro",
                  "FileSystemType": "EFS"|"FSxLustre",
                  "DirectoryPath": "string"
                }
              },
              "ContentType": "string",
              "CompressionType": "None"|"Gzip",
              "RecordWrapperType": "None"|"RecordIO",
              "InputMode": "Pipe"|"File"|"FastFile",
              "ShuffleConfig": {
                "Seed": long
              }
            }
            ...
          ]

       --output-data-config (structure)
          Specifies the path to the S3 location where you want to store  model
          artifacts. SageMaker creates subfolders for the artifacts.

          KmsKeyId -> (string)
              The  Amazon Web Services Key Management Service (Amazon Web Ser-
              vices KMS) key that SageMaker uses to encrypt  the  model  arti-
              facts  at  rest  using  Amazon  S3  server-side  encryption. The
              KmsKeyId can be any of the following formats:

              o // KMS Key ID  "1234abcd-12ab-34cd-56ef-1234567890ab"

              o //   Amazon   Resource   Name   (ARN)    of    a    KMS    Key
                "arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"

              o // KMS Key Alias  "alias/ExampleAlias"

              o //  Amazon  Resource  Name  (ARN)   of   a   KMS   Key   Alias
                "arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"

              If  you  use a KMS key ID or an alias of your KMS key, the Sage-
              Maker execution role must include permissions  to  call  kms:En-
              crypt  .  If  you don't provide a KMS key ID, SageMaker uses the
              default KMS key for Amazon S3 for your role's account. SageMaker
              uses server-side encryption with KMS-managed keys for OutputDat-
              aConfig . If you use a bucket policy with an  s3:PutObject  per-
              mission  that  only  allows objects with server-side encryption,
              set the  condition  key  of  s3:x-amz-server-side-encryption  to
              "aws:kms"  .  For  more  information, see KMS-Managed Encryption
              Keys in the Amazon Simple Storage Service Developer Guide.

              The KMS key policy must grant permission to the  IAM  role  that
              you  specify in your CreateTrainingJob , CreateTransformJob , or
              CreateHyperParameterTuningJob requests.  For  more  information,
              see  Using Key Policies in Amazon Web Services KMS in the Amazon
              Web Services Key Management Service Developer Guide .

          S3OutputPath -> (string)
              Identifies the S3 path where you want  SageMaker  to  store  the
              model artifacts. For example, s3://bucket-name/key-name-prefix .

       Shorthand Syntax:

          KmsKeyId=string,S3OutputPath=string

       JSON Syntax:

          {
            "KmsKeyId": "string",
            "S3OutputPath": "string"
          }

       --resource-config (structure)
          The  resources,  including  the  ML compute instances and ML storage
          volumes, to use for model training.

          ML storage volumes store model  artifacts  and  incremental  states.
          Training  algorithms  might  also use ML storage volumes for scratch
          space. If you want SageMaker to use the ML storage volume  to  store
          the training data, choose File as the TrainingInputMode in the algo-
          rithm specification. For distributed training algorithms, specify an
          instance count greater than 1.

          InstanceType -> (string)
              The ML compute instance type.

              NOTE:
                 SageMaker Training on Amazon Elastic Compute Cloud (EC2) P4de
                 instances is in preview release starting December 9th, 2022.
                     Amazon EC2 P4de instances (currently in preview) are pow-
                     ered  by  8  NVIDIA  A100 GPUs with 80GB high-performance
                     HBM2e GPU memory, which accelerate the speed of  training
                     ML  models  that  need to be trained on large datasets of
                     high-resolution data. In  this  preview  release,  Amazon
                     SageMaker  supports  ML  training  jobs on P4de instances
                     (ml.p4de.24xlarge ) to reduce model  training  time.  The
                     ml.p4de.24xlarge instances are available in the following
                     Amazon Web Services Regions.

                 o US East (N. Virginia) (us-east-1)

                 o US West (Oregon) (us-west-2)

                 To request quota limit increase  and  start  using  P4de  in-
                 stances,  contact the SageMaker Training service team through
                 your account team.

          InstanceCount -> (integer)
              The number of ML  compute  instances  to  use.  For  distributed
              training, provide a value greater than 1.

          VolumeSizeInGB -> (integer)
              The size of the ML storage volume that you want to provision.

              ML storage volumes store model artifacts and incremental states.
              Training algorithms might also use the  ML  storage  volume  for
              scratch  space. If you want to store the training data in the ML
              storage volume, choose File as the TrainingInputMode in the  al-
              gorithm specification.

              When  using  an  ML  instance  with NVMe SSD volumes , SageMaker
              doesn't provision Amazon EBS General Purpose SSD (gp2)  storage.
              Available  storage  is fixed to the NVMe-type instance's storage
              capacity.  SageMaker  configures  storage  paths  for   training
              datasets,  checkpoints,  model artifacts, and outputs to use the
              entire capacity of the instance storage.  For  example,  ML  in-
              stance  families  with  the  NVMe-type  instance storage include
              ml.p4d , ml.g4dn , and ml.g5 .

              When using an ML instance with the EBS-only storage  option  and
              without instance storage, you must define the size of EBS volume
              through VolumeSizeInGB in the ResourceConfig API.  For  example,
              ML  instance  families  that  use  EBS volumes include ml.c5 and
              ml.p2 .

              To look up instance types and their instance storage  types  and
              volumes, see Amazon EC2 Instance Types .

              To  find the default local paths defined by the SageMaker train-
              ing platform, see Amazon SageMaker Training Storage Folders  for
              Training Datasets, Checkpoints, Model Artifacts, and Outputs .

          VolumeKmsKeyId -> (string)
              The  Amazon  Web Services KMS key that SageMaker uses to encrypt
              data on the storage  volume  attached  to  the  ML  compute  in-
              stance(s) that run the training job.

              NOTE:
                 Certain  Nitro-based  instances include local storage, depen-
                 dent on the instance type.  Local  storage  volumes  are  en-
                 crypted  using  a  hardware module on the instance. You can't
                 request a VolumeKmsKeyId when using an instance type with lo-
                 cal storage.

                 For  a  list  of  instance  types that support local instance
                 storage, see Instance Store Volumes .

                 For more information about local instance storage encryption,
                 see SSD Instance Store Volumes .

              The VolumeKmsKeyId can be in any of the following formats:

              o // KMS Key ID  "1234abcd-12ab-34cd-56ef-1234567890ab"

              o //    Amazon    Resource    Name    (ARN)   of   a   KMS   Key
                "arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"

          InstanceGroups -> (list)
              The configuration of a heterogeneous cluster in JSON format.

              (structure)
                 Defines an instance group for heterogeneous cluster training.
                 When requesting a training job  using  the  CreateTrainingJob
                 API, you can configure multiple instance groups .

                 InstanceType -> (string)
                     Specifies the instance type of the instance group.

                 InstanceCount -> (integer)
                     Specifies the number of instances of the instance group.

                 InstanceGroupName -> (string)
                     Specifies the name of the instance group.

          KeepAlivePeriodInSeconds -> (integer)
              The  duration  of time in seconds to retain configured resources
              in a warm pool for subsequent training jobs.

       Shorthand Syntax:

          InstanceType=string,InstanceCount=integer,VolumeSizeInGB=integer,VolumeKmsKeyId=string,InstanceGroups=[{InstanceType=string,InstanceCount=integer,InstanceGroupName=string},{InstanceType=string,InstanceCount=integer,InstanceGroupName=string}],KeepAlivePeriodInSeconds=integer

       JSON Syntax:

          {
            "InstanceType": "ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.p3dn.24xlarge"|"ml.p4d.24xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.c5n.xlarge"|"ml.c5n.2xlarge"|"ml.c5n.4xlarge"|"ml.c5n.9xlarge"|"ml.c5n.18xlarge"|"ml.g5.xlarge"|"ml.g5.2xlarge"|"ml.g5.4xlarge"|"ml.g5.8xlarge"|"ml.g5.16xlarge"|"ml.g5.12xlarge"|"ml.g5.24xlarge"|"ml.g5.48xlarge"|"ml.trn1.2xlarge"|"ml.trn1.32xlarge",
            "InstanceCount": integer,
            "VolumeSizeInGB": integer,
            "VolumeKmsKeyId": "string",
            "InstanceGroups": [
              {
                "InstanceType": "ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.p3dn.24xlarge"|"ml.p4d.24xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.c5n.xlarge"|"ml.c5n.2xlarge"|"ml.c5n.4xlarge"|"ml.c5n.9xlarge"|"ml.c5n.18xlarge"|"ml.g5.xlarge"|"ml.g5.2xlarge"|"ml.g5.4xlarge"|"ml.g5.8xlarge"|"ml.g5.16xlarge"|"ml.g5.12xlarge"|"ml.g5.24xlarge"|"ml.g5.48xlarge"|"ml.trn1.2xlarge"|"ml.trn1.32xlarge",
                "InstanceCount": integer,
                "InstanceGroupName": "string"
              }
              ...
            ],
            "KeepAlivePeriodInSeconds": integer
          }

       --vpc-config (structure)
          A  VpcConfig object that specifies the VPC that you want your train-
          ing job to connect to. Control access to and from your training con-
          tainer by configuring the VPC. For  more  information,  see  Protect
          Training Jobs by Using an Amazon Virtual Private Cloud .

          SecurityGroupIds -> (list)
              The VPC security group IDs, in the form sg-xxxxxxxx. Specify the
              security groups for the VPC that is  specified  in  the  Subnets
              field.

              (string)

          Subnets -> (list)
              The  ID  of  the subnets in the VPC to which you want to connect
              your training job or model. For information about the availabil-
              ity of specific instance types, see Supported Instance Types and
              Availability Zones .

              (string)

       Shorthand Syntax:

          SecurityGroupIds=string,string,Subnets=string,string

       JSON Syntax:

          {
            "SecurityGroupIds": ["string", ...],
            "Subnets": ["string", ...]
          }

       --stopping-condition (structure)
          Specifies a limit to how long a model training job can run. It  also
          specifies how long a managed Spot training job has to complete. When
          the job reaches the time limit, SageMaker ends the training job. Use
          this API to cap model training costs.

          To  stop  a  job,  SageMaker sends the algorithm the SIGTERM signal,
          which delays job termination for 120  seconds.  Algorithms  can  use
          this  120-second  window to save the model artifacts, so the results
          of training are not lost.

          MaxRuntimeInSeconds -> (integer)
              The maximum length of time, in seconds, that a training or  com-
              pilation job can run before it is stopped.

              For  compilation  jobs, if the job does not complete during this
              time, a TimeOut error is generated. We recommend  starting  with
              900 seconds and increasing as necessary based on your model.

              For  all  other  jobs,  if the job does not complete during this
              time, SageMaker ends the job. When RetryStrategy is specified in
              the  job request, MaxRuntimeInSeconds specifies the maximum time
              for all of the attempts in total, not each  individual  attempt.
              The default value is 1 day. The maximum value is 28 days.

              The  maximum time that a TrainingJob can run in total, including
              any time spent publishing metrics  or  archiving  and  uploading
              models after it has been stopped, is 30 days.

          MaxWaitTimeInSeconds -> (integer)
              The  maximum  length  of  time,  in seconds, that a managed Spot
              training job has to complete. It is the  amount  of  time  spent
              waiting  for  Spot  capacity plus the amount of time the job can
              run. It must be equal to or greater than  MaxRuntimeInSeconds  .
              If  the  job  does not complete during this time, SageMaker ends
              the job.

              When RetryStrategy is specified in  the  job  request,  MaxWait-
              TimeInSeconds specifies the maximum time for all of the attempts
              in total, not each individual attempt.

       Shorthand Syntax:

          MaxRuntimeInSeconds=integer,MaxWaitTimeInSeconds=integer

       JSON Syntax:

          {
            "MaxRuntimeInSeconds": integer,
            "MaxWaitTimeInSeconds": integer
          }

       --tags (list)
          An array of key-value pairs. You can use  tags  to  categorize  your
          Amazon  Web  Services  resources  in different ways, for example, by
          purpose, owner, or environment. For more  information,  see  Tagging
          Amazon Web Services Resources .

          (structure)
              A  tag object that consists of a key and an optional value, used
              to manage metadata for SageMaker Amazon Web Services resources.

              You can add tags to notebook instances, training jobs,  hyperpa-
              rameter  tuning  jobs,  batch  transform  jobs, models, labeling
              jobs, work teams, endpoint configurations,  and  endpoints.  For
              more information on adding tags to SageMaker resources, see  Ad-
              dTags .

              For more information on adding metadata to your Amazon Web  Ser-
              vices  resources  with  tagging, see Tagging Amazon Web Services
              resources . For advice on best practices for managing Amazon Web
              Services resources with tagging, see Tagging Best Practices: Im-
              plement an Effective Amazon Web Services Resource Tagging Strat-
              egy .

              Key -> (string)
                 The tag key. Tag keys must be unique per resource.

              Value -> (string)
                 The tag value.

       Shorthand Syntax:

          Key=string,Value=string ...

       JSON Syntax:

          [
            {
              "Key": "string",
              "Value": "string"
            }
            ...
          ]

       --enable-network-isolation | --no-enable-network-isolation (boolean)
          Isolates  the  training  container.  No  inbound or outbound network
          calls can be made, except for calls between peers within a  training
          cluster  for  distributed  training. If you enable network isolation
          for training jobs that are configured to use a VPC, SageMaker  down-
          loads  and  uploads  customer  data  and model artifacts through the
          specified VPC, but the training container does not have network  ac-
          cess.

       --enable-inter-container-traffic-encryption   |  --no-enable-inter-con-
       tainer-traffic-encryption (boolean)
          To encrypt all communications between ML compute instances  in  dis-
          tributed  training,  choose True . Encryption provides greater secu-
          rity for distributed training, but training might take  longer.  How
          long it takes depends on the amount of communication between compute
          instances, especially if you use a deep learning algorithm  in  dis-
          tributed  training. For more information, see Protect Communications
          Between ML Compute Instances in a Distributed Training Job .

       --enable-managed-spot-training   |    --no-enable-managed-spot-training
       (boolean)
          To  train  models using managed spot training, choose True . Managed
          spot training provides a fully managed and  scalable  infrastructure
          for  training  machine  learning  models. this option is useful when
          training jobs can be interrupted and when there is flexibility  when
          the training job is run.

          The  complete and intermediate results of jobs are stored in an Ama-
          zon S3 bucket, and can be used as a starting point to  train  models
          incrementally.  Amazon SageMaker provides metrics and logs in Cloud-
          Watch. They can be used to see when managed spot training  jobs  are
          running, interrupted, resumed, or completed.

       --checkpoint-config (structure)
          Contains  information  about  the  output  location for managed spot
          training checkpoint data.

          S3Uri -> (string)
              Identifies the S3 path where you want SageMaker to store  check-
              points. For example, s3://bucket-name/key-name-prefix .

          LocalPath -> (string)
              (Optional)  The  local  directory where checkpoints are written.
              The default directory is /opt/ml/checkpoints/ .

       Shorthand Syntax:

          S3Uri=string,LocalPath=string

       JSON Syntax:

          {
            "S3Uri": "string",
            "LocalPath": "string"
          }

       --debug-hook-config (structure)
          Configuration information for the Amazon SageMaker Debugger hook pa-
          rameters, metric and tensor collections, and storage paths. To learn
          more about how to configure the DebugHookConfig parameter,  see  Use
          the  SageMaker  and Debugger Configuration API Operations to Create,
          Update, and Debug Your Training Job .

          LocalPath -> (string)
              Path to local storage location for metrics and tensors. Defaults
              to /opt/ml/output/tensors/ .

          S3OutputPath -> (string)
              Path to Amazon S3 storage location for metrics and tensors.

          HookParameters -> (map)
              Configuration information for the Amazon SageMaker Debugger hook
              parameters.

              key -> (string)

              value -> (string)

          CollectionConfigurations -> (list)
              Configuration information for Amazon SageMaker  Debugger  tensor
              collections.  To  learn  more about how to configure the Collec-
              tionConfiguration parameter, see Use the SageMaker and  Debugger
              Configuration  API  Operations to Create, Update, and Debug Your
              Training Job .

              (structure)
                 Configuration information for the Amazon  SageMaker  Debugger
                 output tensor collections.

                 CollectionName -> (string)
                     The  name  of  the  tensor  collection.  The name must be
                     unique relative to other rule configuration names.

                 CollectionParameters -> (map)
                     Parameter values for the tensor collection.  The  allowed
                     parameters are "name" , "include_regex" , "reduction_con-
                     fig" , "save_config" , "tensor_names"  ,  and  "save_his-
                     togram" .

                     key -> (string)

                     value -> (string)

       Shorthand Syntax:

          LocalPath=string,S3OutputPath=string,HookParameters={KeyName1=string,KeyName2=string},CollectionConfigurations=[{CollectionName=string,CollectionParameters={KeyName1=string,KeyName2=string}},{CollectionName=string,CollectionParameters={KeyName1=string,KeyName2=string}}]

       JSON Syntax:

          {
            "LocalPath": "string",
            "S3OutputPath": "string",
            "HookParameters": {"string": "string"
              ...},
            "CollectionConfigurations": [
              {
                "CollectionName": "string",
                "CollectionParameters": {"string": "string"
                  ...}
              }
              ...
            ]
          }

       --debug-rule-configurations (list)
          Configuration  information  for  Amazon SageMaker Debugger rules for
          debugging output tensors.

          (structure)
              Configuration information for SageMaker Debugger rules  for  de-
              bugging.  To learn more about how to configure the DebugRuleCon-
              figuration parameter, see Use the SageMaker and Debugger Config-
              uration  API Operations to Create, Update, and Debug Your Train-
              ing Job .

              RuleConfigurationName -> (string)
                 The name of the rule configuration. It must be  unique  rela-
                 tive to other rule configuration names.

              LocalPath -> (string)
                 Path  to local storage location for output of rules. Defaults
                 to /opt/ml/processing/output/rule/ .

              S3OutputPath -> (string)
                 Path to Amazon S3 storage location for rules.

              RuleEvaluatorImage -> (string)
                 The Amazon Elastic Container (ECR) Image for the managed rule
                 evaluation.

              InstanceType -> (string)
                 The  instance  type  to  deploy a custom rule for debugging a
                 training job.

              VolumeSizeInGB -> (integer)
                 The size, in GB, of the ML storage  volume  attached  to  the
                 processing instance.

              RuleParameters -> (map)
                 Runtime configuration for rule container.

                 key -> (string)

                 value -> (string)

       Shorthand Syntax:

          RuleConfigurationName=string,LocalPath=string,S3OutputPath=string,RuleEvaluatorImage=string,InstanceType=string,VolumeSizeInGB=integer,RuleParameters={KeyName1=string,KeyName2=string} ...

       JSON Syntax:

          [
            {
              "RuleConfigurationName": "string",
              "LocalPath": "string",
              "S3OutputPath": "string",
              "RuleEvaluatorImage": "string",
              "InstanceType": "ml.t3.medium"|"ml.t3.large"|"ml.t3.xlarge"|"ml.t3.2xlarge"|"ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.r5.large"|"ml.r5.xlarge"|"ml.r5.2xlarge"|"ml.r5.4xlarge"|"ml.r5.8xlarge"|"ml.r5.12xlarge"|"ml.r5.16xlarge"|"ml.r5.24xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge",
              "VolumeSizeInGB": integer,
              "RuleParameters": {"string": "string"
                ...}
            }
            ...
          ]

       --tensor-board-output-config (structure)
          Configuration of storage locations for the Amazon SageMaker Debugger
          TensorBoard output data.

          LocalPath -> (string)
              Path to local storage location for tensorBoard output.  Defaults
              to /opt/ml/output/tensorboard .

          S3OutputPath -> (string)
              Path to Amazon S3 storage location for TensorBoard output.

       Shorthand Syntax:

          LocalPath=string,S3OutputPath=string

       JSON Syntax:

          {
            "LocalPath": "string",
            "S3OutputPath": "string"
          }

       --experiment-config (structure)
          Associates  a  SageMaker job as a trial component with an experiment
          and trial. Specified when you call the following APIs:

          o CreateProcessingJob

          o CreateTrainingJob

          o CreateTransformJob

          ExperimentName -> (string)
              The name of an existing experiment to associate with  the  trial
              component.

          TrialName -> (string)
              The  name  of an existing trial to associate the trial component
              with. If not specified, a new trial is created.

          TrialComponentDisplayName -> (string)
              The display name for the trial  component.  If  this  key  isn't
              specified, the display name is the trial component name.

          RunName -> (string)
              The  name of the experiment run to associate with the trial com-
              ponent.

       Shorthand Syntax:

          ExperimentName=string,TrialName=string,TrialComponentDisplayName=string,RunName=string

       JSON Syntax:

          {
            "ExperimentName": "string",
            "TrialName": "string",
            "TrialComponentDisplayName": "string",
            "RunName": "string"
          }

       --profiler-config (structure)
          Configuration information for Amazon SageMaker Debugger system moni-
          toring, framework profiling, and storage paths.

          S3OutputPath -> (string)
              Path to Amazon S3 storage location for system and framework met-
              rics.

          ProfilingIntervalInMilliseconds -> (long)
              A time interval for capturing system  metrics  in  milliseconds.
              Available  values  are  100,  200, 500, 1000 (1 second), 5000 (5
              seconds), and 60000 (1 minute) milliseconds. The  default  value
              is 500 milliseconds.

          ProfilingParameters -> (map)
              Configuration   information  for  capturing  framework  metrics.
              Available key strings for different profiling  options  are  De-
              tailedProfilingConfig  , PythonProfilingConfig , and DataLoader-
              ProfilingConfig . The following codes are  configuration  struc-
              tures for the ProfilingParameters parameter. To learn more about
              how to configure the ProfilingParameters parameter, see Use  the
              SageMaker  and  Debugger Configuration API Operations to Create,
              Update, and Debug Your Training Job .

              key -> (string)

              value -> (string)

          DisableProfiler -> (boolean)
              Configuration to turn off  Amazon  SageMaker  Debugger's  system
              monitoring  and  profiling functionality. To turn it off, set to
              True .

       Shorthand Syntax:

          S3OutputPath=string,ProfilingIntervalInMilliseconds=long,ProfilingParameters={KeyName1=string,KeyName2=string},DisableProfiler=boolean

       JSON Syntax:

          {
            "S3OutputPath": "string",
            "ProfilingIntervalInMilliseconds": long,
            "ProfilingParameters": {"string": "string"
              ...},
            "DisableProfiler": true|false
          }

       --profiler-rule-configurations (list)
          Configuration information for Amazon SageMaker  Debugger  rules  for
          profiling system and framework metrics.

          (structure)
              Configuration information for profiling rules.

              RuleConfigurationName -> (string)
                 The  name  of the rule configuration. It must be unique rela-
                 tive to other rule configuration names.

              LocalPath -> (string)
                 Path to local storage location for output of rules.  Defaults
                 to /opt/ml/processing/output/rule/ .

              S3OutputPath -> (string)
                 Path to Amazon S3 storage location for rules.

              RuleEvaluatorImage -> (string)
                 The  Amazon  Elastic Container Registry Image for the managed
                 rule evaluation.

              InstanceType -> (string)
                 The instance type to deploy a custom  rule  for  profiling  a
                 training job.

              VolumeSizeInGB -> (integer)
                 The  size,  in  GB,  of the ML storage volume attached to the
                 processing instance.

              RuleParameters -> (map)
                 Runtime configuration for rule container.

                 key -> (string)

                 value -> (string)

       Shorthand Syntax:

          RuleConfigurationName=string,LocalPath=string,S3OutputPath=string,RuleEvaluatorImage=string,InstanceType=string,VolumeSizeInGB=integer,RuleParameters={KeyName1=string,KeyName2=string} ...

       JSON Syntax:

          [
            {
              "RuleConfigurationName": "string",
              "LocalPath": "string",
              "S3OutputPath": "string",
              "RuleEvaluatorImage": "string",
              "InstanceType": "ml.t3.medium"|"ml.t3.large"|"ml.t3.xlarge"|"ml.t3.2xlarge"|"ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.r5.large"|"ml.r5.xlarge"|"ml.r5.2xlarge"|"ml.r5.4xlarge"|"ml.r5.8xlarge"|"ml.r5.12xlarge"|"ml.r5.16xlarge"|"ml.r5.24xlarge"|"ml.g4dn.xlarge"|"ml.g4dn.2xlarge"|"ml.g4dn.4xlarge"|"ml.g4dn.8xlarge"|"ml.g4dn.12xlarge"|"ml.g4dn.16xlarge",
              "VolumeSizeInGB": integer,
              "RuleParameters": {"string": "string"
                ...}
            }
            ...
          ]

       --environment (map)
          The environment variables to set in the Docker container.

          key -> (string)

          value -> (string)

       Shorthand Syntax:

          KeyName1=string,KeyName2=string

       JSON Syntax:

          {"string": "string"
            ...}

       --retry-strategy (structure)
          The number of times to retry the job when the job fails  due  to  an
          InternalServerError .

          MaximumRetryAttempts -> (integer)
              The  number  of times to retry the job. When the job is retried,
              it's SecondaryStatus is changed to STARTING .

       Shorthand Syntax:

          MaximumRetryAttempts=integer

       JSON Syntax:

          {
            "MaximumRetryAttempts": integer
          }

       --cli-input-json (string) Performs service operation based on the  JSON
       string  provided. The JSON string follows the format provided by --gen-
       erate-cli-skeleton. If other arguments  are  provided  on  the  command
       line,  the CLI values will override the JSON-provided values. It is not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton  (string)  Prints  a  JSON skeleton to standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for --cli-input-json. If provided with the value output,  it  validates
       the command inputs and returns a sample output JSON for that command.

GLOBAL OPTIONS
       --debug (boolean)

       Turn on debug logging.

       --endpoint-url (string)

       Override command's default URL with the given URL.

       --no-verify-ssl (boolean)

       By  default, the AWS CLI uses SSL when communicating with AWS services.
       For each SSL connection, the AWS CLI will verify SSL certificates. This
       option overrides the default behavior of verifying SSL certificates.

       --no-paginate (boolean)

       Disable automatic pagination.

       --output (string)

       The formatting style for command output.

       o json

       o text

       o table

       --query (string)

       A JMESPath query to use in filtering the response data.

       --profile (string)

       Use a specific profile from your credential file.

       --region (string)

       The region to use. Overrides config/env settings.

       --version (string)

       Display the version of this tool.

       --color (string)

       Turn on/off color output.

       o on

       o off

       o auto

       --no-sign-request (boolean)

       Do  not  sign requests. Credentials will not be loaded if this argument
       is provided.

       --ca-bundle (string)

       The CA certificate bundle to use when verifying SSL certificates. Over-
       rides config/env settings.

       --cli-read-timeout (int)

       The  maximum socket read time in seconds. If the value is set to 0, the
       socket read will be blocking and not timeout. The default value  is  60
       seconds.

       --cli-connect-timeout (int)

       The  maximum  socket connect time in seconds. If the value is set to 0,
       the socket connect will be blocking and not timeout. The default  value
       is 60 seconds.

OUTPUT
       TrainingJobArn -> (string)
          The Amazon Resource Name (ARN) of the training job.



                                                         CREATE-TRAINING-JOB()
