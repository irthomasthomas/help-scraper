DESCRIBE-AUTO-ML-JOB()                                  DESCRIBE-AUTO-ML-JOB()



NAME
       describe-auto-ml-job -

DESCRIPTION
       Returns information about an Amazon SageMaker AutoML job.

       See also: AWS API Documentation

       See 'aws help' for descriptions of global parameters.

SYNOPSIS
            describe-auto-ml-job
          --auto-ml-job-name <value>
          [--cli-input-json <value>]
          [--generate-cli-skeleton <value>]

OPTIONS
       --auto-ml-job-name (string)
          Requests information about an AutoML job using its unique name.

       --cli-input-json  (string) Performs service operation based on the JSON
       string provided. The JSON string follows the format provided by  --gen-
       erate-cli-skeleton.  If  other  arguments  are  provided on the command
       line, the CLI values will override the JSON-provided values. It is  not
       possible to pass arbitrary binary values using a JSON-provided value as
       the string will be taken literally.

       --generate-cli-skeleton (string) Prints a  JSON  skeleton  to  standard
       output without sending an API request. If provided with no value or the
       value input, prints a sample input JSON that can be used as an argument
       for  --cli-input-json.  If provided with the value output, it validates
       the command inputs and returns a sample output JSON for that command.

       See 'aws help' for descriptions of global parameters.

OUTPUT
       AutoMLJobName -> (string)
          Returns the name of the AutoML job.

       AutoMLJobArn -> (string)
          Returns the ARN of the AutoML job.

       InputDataConfig -> (list)
          Returns the input data configuration for the AutoML job..

          (structure)
              A channel is a named input source that training  algorithms  can
              consume.  The  validation dataset size is limited to less than 2
              GB. The training dataset size must be less than 100 GB. For more
              information, see .

              NOTE:
                 A  validation  dataset  must  contain the same headers as the
                 training dataset.

              DataSource -> (structure)
                 The data source for an AutoML channel.

                 S3DataSource -> (structure)
                     The Amazon S3 location of the input data.

                     S3DataType -> (string)
                        The data type.

                        A ManifestFile should have the format shown below:
                            [  {"prefix":   "s3://DOC-EXAMPLE-BUCKET/DOC-EXAM-
                            PLE-FOLDER/DOC-EXAMPLE-PREFIX/"},

                            "DOC-EXAMPLE-RELATIVE-PATH/DOC-EXAM-
                            PLE-FOLDER/DATA-1",

                            "DOC-EXAMPLE-RELATIVE-PATH/DOC-EXAM-
                            PLE-FOLDER/DATA-2",

                            ...           "DOC-EXAMPLE-RELATIVE-PATH/DOC-EXAM-
                            PLE-FOLDER/DATA-N" ]

                        An S3Prefix should have the following format:
                            s3://DOC-EXAMPLE-BUCKET/DOC-EXAMPLE-FOLDER-OR-FILE

                     S3Uri -> (string)
                        The URL to the Amazon S3 data source.

              CompressionType -> (string)
                 You can use Gzip or None . The default value is None .

              TargetAttributeName -> (string)
                 The name of the target variable in supervised learning,  usu-
                 ally represented by 'y'.

              ContentType -> (string)
                 The  content  type of the data from the input source. You can
                 use text/csv;header=present or  x-application/vnd.amazon+par-
                 quet . The default value is text/csv;header=present .

              ChannelType -> (string)
                 The  channel  type  (optional) is an enum string. The default
                 value is training . Channels for training and validation must
                 share  the same ContentType and TargetAttributeName . For in-
                 formation  on  specifying  training  and  validation  channel
                 types,  see ` How to specify training and validation datasets
                 https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-datasets-problem-types.html#autopilot-data-sources-training-or-validation`__
                 .

       OutputDataConfig -> (structure)
          Returns the job's output data config.

          KmsKeyId -> (string)
              The Amazon Web Services KMS encryption key ID.

          S3OutputPath -> (string)
              The Amazon S3 output path. Must be 128 characters or less.

       RoleArn -> (string)
          The  Amazon  Resource Name (ARN) of the Amazon Web Services Identity
          and Access Management (IAM) role that has read permission to the in-
          put  data  location and write permission to the output data location
          in Amazon S3.

       AutoMLJobObjective -> (structure)
          Returns the job's objective.

          MetricName -> (string)
              The name of the objective metric used to measure the  predictive
              quality  of  a machine learning system. This metric is optimized
              during training to provide the best estimate for model parameter
              values from data.

              Here are the options:

              o MSE  :  The  mean  squared  error  (MSE) is the average of the
                squared differences between the predicted and  actual  values.
                It is used for regression. MSE values are always positive: the
                better a model is at predicting the actual values, the smaller
                the  MSE  value is. When the data contains outliers, they tend
                to dominate the MSE, which might cause subpar prediction  per-
                formance.

              o Accuracy  :  The  ratio  of the number of correctly classified
                items to the total number of (correctly and incorrectly) clas-
                sified items. It is used for binary and multiclass classifica-
                tion. It measures how close the predicted class values are  to
                the  actual values. Accuracy values vary between zero and one:
                one indicates perfect accuracy and zero indicates perfect  in-
                accuracy.

              o F1  :  The  F1 score is the harmonic mean of the precision and
                recall. It is used for binary classification into classes tra-
                ditionally  referred  to as positive and negative. Predictions
                are said to be true when they  match  their  actual  (correct)
                class  and  false  when they do not. Precision is the ratio of
                the true positive predictions to all positive predictions (in-
                cluding  the  false  positives) in a data set and measures the
                quality of the prediction when it predicts the positive class.
                Recall (or sensitivity) is the ratio of the true positive pre-
                dictions to all actual positive  instances  and  measures  how
                completely a model predicts the actual class members in a data
                set.  The  standard  F1  score  weighs  precision  and  recall
                equally.  But  which  metric is paramount typically depends on
                specific aspects of a problem. F1 scores vary between zero and
                one:  one indicates the best possible performance and zero the
                worst.

              o AUC : The area under the curve (AUC) metric is used to compare
                and  evaluate  binary classification by algorithms such as lo-
                gistic regression that return probabilities.  A  threshold  is
                needed to map the probabilities into classifications. The rel-
                evant curve is the  receiver  operating  characteristic  curve
                that plots the true positive rate (TPR) of predictions (or re-
                call) against the false positive rate (FPR) as a  function  of
                the  threshold  value,  above which a prediction is considered
                positive. Increasing the threshold results in fewer false pos-
                itives  but  more  false negatives. AUC is the area under this
                receiver operating characteristic curve and so provides an ag-
                gregated  measure of the model performance across all possible
                classification thresholds. The AUC score can  also  be  inter-
                preted  as  the  probability that a randomly selected positive
                data point is more likely to be predicted positive than a ran-
                domly  selected negative example. AUC scores vary between zero
                and one: a score of one indicates perfect accuracy and a score
                of one half indicates that the prediction is not better than a
                random classifier. Values under one half  predict  less  accu-
                rately than a random predictor. But such consistently bad pre-
                dictors can simply be inverted to obtain  better  than  random
                predictors.

              o F1macro  :  The F1macro score applies F1 scoring to multiclass
                classification. In this context, you have multiple classes  to
                predict.  You just calculate the precision and recall for each
                class as you did for the positive class in binary  classifica-
                tion.  Then,  use  these  values to calculate the F1 score for
                each class and average  them  to  obtain  the  F1macro  score.
                F1macro  scores  vary  between zero and one: one indicates the
                best possible performance and zero the worst.

              If you do not specify a metric explicitly, the default  behavior
              is to automatically use:

              o MSE : for regression.

              o F1 : for binary classification

              o Accuracy : for multiclass classification.

       ProblemType -> (string)
          Returns the job's problem type.

       AutoMLJobConfig -> (structure)
          Returns the configuration for the AutoML job.

          CompletionCriteria -> (structure)
              How long an AutoML job is allowed to run, or how many candidates
              a job is allowed to generate.

              MaxCandidates -> (integer)
                 The maximum number of times a training job is allowed to run.

              MaxRuntimePerTrainingJobInSeconds -> (integer)
                 The maximum time, in seconds, that each training job  is  al-
                 lowed to run as part of a hyperparameter tuning job. For more
                 information, see the used by the action.

              MaxAutoMLJobRuntimeInSeconds -> (integer)
                 The maximum runtime, in seconds, an AutoML job  has  to  com-
                 plete.

                 If  an  AutoML  job  exceeds  the maximum runtime, the job is
                 stopped automatically and its processing is ended gracefully.
                 The  AutoML  job identifies the best model whose training was
                 completed and marks it as the best-performing model. Any  un-
                 finished  steps  of  the job, such as automatic one-click Au-
                 topilot model deployment, will not be completed.

          SecurityConfig -> (structure)
              The security configuration for traffic encryption or Amazon  VPC
              settings.

              VolumeKmsKeyId -> (string)
                 The key used to encrypt stored data.

              EnableInterContainerTrafficEncryption -> (boolean)
                 Whether  to use traffic encryption between the container lay-
                 ers.

              VpcConfig -> (structure)
                 The VPC configuration.

                 SecurityGroupIds -> (list)
                     The VPC security group  IDs,  in  the  form  sg-xxxxxxxx.
                     Specify the security groups for the VPC that is specified
                     in the Subnets field.

                     (string)

                 Subnets -> (list)
                     The ID of the subnets in the VPC to  which  you  want  to
                     connect your training job or model. For information about
                     the  availability  of  specific   instance   types,   see
                     Supported Instance Types and Availability Zones .

                     (string)

          DataSplitConfig -> (structure)
              The configuration for splitting the input training dataset.

              Type: AutoMLDataSplitConfig

              ValidationFraction -> (float)
                 The  validation fraction (optional) is a float that specifies
                 the portion of the training dataset to be  used  for  valida-
                 tion.  The  default  value is 0.2, and values must be greater
                 than 0 and less than 1. We recommend setting this value to be
                 less than 0.5.

          CandidateGenerationConfig -> (structure)
              The  configuration  for generating a candidate for an AutoML job
              (optional).

              FeatureSpecificationS3Uri -> (string)
                 A URL to the Amazon S3 data source containing  selected  fea-
                 tures from the input data source to run an Autopilot job (op-
                 tional). This file should be in json format as shown below:
                     { "FeatureAttributeNames":["col1", "col2", ...] } .

                 The key  name  FeatureAttributeNames  is  fixed.  The  values
                 listed  in ["col1", "col2", ...] is case sensitive and should
                 be a list of strings containing unique values that are a sub-
                 set  of  the column names in the input data. The list of col-
                 umns provided must not include the target column.

       CreationTime -> (timestamp)
          Returns the creation time of the AutoML job.

       EndTime -> (timestamp)
          Returns the end time of the AutoML job.

       LastModifiedTime -> (timestamp)
          Returns the job's last modified time.

       FailureReason -> (string)
          Returns the failure reason for an AutoML job, when applicable.

       PartialFailureReasons -> (list)
          Returns a list of reasons for partial failures within an AutoML job.

          (structure)
              The reason for a partial failure of an AutoML job.

              PartialFailureMessage -> (string)
                 The message containing the reason for a partial failure of an
                 AutoML job.

       BestCandidate -> (structure)
          Returns the job's best AutoMLCandidate .

          CandidateName -> (string)
              The name of the candidate.

          FinalAutoMLJobObjectiveMetric -> (structure)
              The best candidate result from an AutoML training job.

              Type -> (string)
                 The type of metric with the best result.

              MetricName -> (string)
                 The  name  of the metric with the best result. For a descrip-
                 tion of the possible objective metrics, see   AutoMLJobObjec-
                 tive$MetricName .

              Value -> (float)
                 The value of the metric with the best result.

          ObjectiveStatus -> (string)
              The objective's status.

          CandidateSteps -> (list)
              Information about the candidate's steps.

              (structure)
                 Information  about the steps for a candidate and what step it
                 is working on.

                 CandidateStepType -> (string)
                     Whether the candidate is at the transform,  training,  or
                     processing step.

                 CandidateStepArn -> (string)
                     The ARN for the candidate's step.

                 CandidateStepName -> (string)
                     The name for the candidate's step.

          CandidateStatus -> (string)
              The candidate's status.

          InferenceContainers -> (list)
              Information about the inference container definitions.

              (structure)
                 A  list  of container definitions that describe the different
                 containers that make up an AutoML candidate. For more  infor-
                 mation, see .

                 Image -> (string)
                     The  Amazon  Elastic Container Registry (Amazon ECR) path
                     of the container. For more information, see .

                 ModelDataUrl -> (string)
                     The location of the model artifacts.  For  more  informa-
                     tion, see .

                 Environment -> (map)
                     The  environment  variables  to set in the container. For
                     more information, see .

                     key -> (string)

                     value -> (string)

          CreationTime -> (timestamp)
              The creation time.

          EndTime -> (timestamp)
              The end time.

          LastModifiedTime -> (timestamp)
              The last modified time.

          FailureReason -> (string)
              The failure reason.

          CandidateProperties -> (structure)
              The properties of an AutoML candidate job.

              CandidateArtifactLocations -> (structure)
                 The Amazon S3 prefix to the artifacts generated for an AutoML
                 candidate.

                 Explainability -> (string)
                     The Amazon S3 prefix to the explainability artifacts gen-
                     erated for the AutoML candidate.

                 ModelInsights -> (string)
                     The Amazon S3 prefix to the model insight artifacts  gen-
                     erated for the AutoML candidate.

              CandidateMetrics -> (list)
                 Information about the candidate metrics for an AutoML job.

                 (structure)
                     Information  about the metric for a candidate produced by
                     an AutoML job.

                     MetricName -> (string)
                        The name of the metric.

                     Value -> (float)
                        The value of the metric.

                     Set -> (string)
                        The dataset split from which the AutoML  job  produced
                        the metric.

                     StandardMetricName -> (string)
                        The name of the standard metric.

                        NOTE:
                            For definitions of the standard metrics, see ` Au-
                            topilot             candidate              metrics
                            https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-model-support-validation.html#autopilot-metrics`__
                            .

       AutoMLJobStatus -> (string)
          Returns the status of the AutoML job.

       AutoMLJobSecondaryStatus -> (string)
          Returns the secondary status of the AutoML job.

       GenerateCandidateDefinitionsOnly -> (boolean)
          Indicates whether the output for an AutoML job  generates  candidate
          definitions only.

       AutoMLJobArtifacts -> (structure)
          Returns  information  on the job's artifacts found in AutoMLJobArti-
          facts .

          CandidateDefinitionNotebookLocation -> (string)
              The URL of the notebook location.

          DataExplorationNotebookLocation -> (string)
              The URL of the notebook location.

       ResolvedAttributes -> (structure)
          This contains ProblemType , AutoMLJobObjective , and  CompletionCri-
          teria  . If you do not provide these values, they are auto-inferred.
          If you do provide them, the values used are the ones you provide.

          AutoMLJobObjective -> (structure)
              Specifies a metric to minimize or maximize as the objective of a
              job.

              MetricName -> (string)
                 The  name of the objective metric used to measure the predic-
                 tive quality of a machine learning system. This metric is op-
                 timized  during  training  to  provide  the best estimate for
                 model parameter values from data.

                 Here are the options:

                 o MSE : The mean squared error (MSE) is the  average  of  the
                   squared  differences  between the predicted and actual val-
                   ues. It is used for regression. MSE values are always posi-
                   tive:  the  better a model is at predicting the actual val-
                   ues, the smaller the MSE value is. When the  data  contains
                   outliers,  they tend to dominate the MSE, which might cause
                   subpar prediction performance.

                 o Accuracy : The ratio of the number of correctly  classified
                   items  to  the  total number of (correctly and incorrectly)
                   classified items. It is  used  for  binary  and  multiclass
                   classification.  It  measures how close the predicted class
                   values are to the actual values. Accuracy values  vary  be-
                   tween zero and one: one indicates perfect accuracy and zero
                   indicates perfect inaccuracy.

                 o F1 : The F1 score is the harmonic mean of the precision and
                   recall.  It  is used for binary classification into classes
                   traditionally referred to as positive and negative. Predic-
                   tions  are  said  to  be  true when they match their actual
                   (correct) class and false when they do  not.  Precision  is
                   the  ratio of the true positive predictions to all positive
                   predictions (including the false positives) in a  data  set
                   and measures the quality of the prediction when it predicts
                   the positive class. Recall (or sensitivity) is the ratio of
                   the  true  positive  predictions to all actual positive in-
                   stances and measures how completely a  model  predicts  the
                   actual  class  members in a data set. The standard F1 score
                   weighs precision and recall equally. But  which  metric  is
                   paramount  typically depends on specific aspects of a prob-
                   lem. F1 scores vary between zero and one: one indicates the
                   best possible performance and zero the worst.

                 o AUC : The area under the curve (AUC) metric is used to com-
                   pare and evaluate binary classification by algorithms  such
                   as logistic regression that return probabilities. A thresh-
                   old is needed to map  the  probabilities  into  classifica-
                   tions. The relevant curve is the receiver operating charac-
                   teristic curve that plots the true positive rate  (TPR)  of
                   predictions  (or  recall)  against  the false positive rate
                   (FPR) as a function of the threshold value, above  which  a
                   prediction is considered positive. Increasing the threshold
                   results in fewer false positives but more false  negatives.
                   AUC  is the area under this receiver operating characteris-
                   tic curve and so provides  an  aggregated  measure  of  the
                   model   performance   across  all  possible  classification
                   thresholds. The AUC score can also be  interpreted  as  the
                   probability that a randomly selected positive data point is
                   more likely to be predicted positive than  a  randomly  se-
                   lected  negative  example. AUC scores vary between zero and
                   one: a score of one indicates perfect accuracy and a  score
                   of  one  half  indicates  that the prediction is not better
                   than a random classifier. Values  under  one  half  predict
                   less  accurately  than a random predictor. But such consis-
                   tently bad predictors can simply be inverted to obtain bet-
                   ter than random predictors.

                 o F1macro  :  The  F1macro score applies F1 scoring to multi-
                   class classification. In this context,  you  have  multiple
                   classes  to  predict.  You just calculate the precision and
                   recall for each class as you did for the positive class  in
                   binary  classification. Then, use these values to calculate
                   the F1 score for each class and average them to obtain  the
                   F1macro  score.  F1macro  scores vary between zero and one:
                   one indicates the best possible performance  and  zero  the
                   worst.

                 If you do not specify a metric explicitly, the default behav-
                 ior is to automatically use:

                 o MSE : for regression.

                 o F1 : for binary classification

                 o Accuracy : for multiclass classification.

          ProblemType -> (string)
              The problem type.

          CompletionCriteria -> (structure)
              How long a job is allowed to run, or how many candidates  a  job
              is allowed to generate.

              MaxCandidates -> (integer)
                 The maximum number of times a training job is allowed to run.

              MaxRuntimePerTrainingJobInSeconds -> (integer)
                 The  maximum  time, in seconds, that each training job is al-
                 lowed to run as part of a hyperparameter tuning job. For more
                 information, see the used by the action.

              MaxAutoMLJobRuntimeInSeconds -> (integer)
                 The  maximum  runtime,  in seconds, an AutoML job has to com-
                 plete.

                 If an AutoML job exceeds the  maximum  runtime,  the  job  is
                 stopped automatically and its processing is ended gracefully.
                 The AutoML job identifies the best model whose  training  was
                 completed  and marks it as the best-performing model. Any un-
                 finished steps of the job, such as  automatic  one-click  Au-
                 topilot model deployment, will not be completed.

       ModelDeployConfig -> (structure)
          Indicates  whether  the  model was deployed automatically to an end-
          point and the name of that endpoint if deployed automatically.

          AutoGenerateEndpointName -> (boolean)
              Set to True to automatically generate an  endpoint  name  for  a
              one-click  Autopilot  model  deployment; set to False otherwise.
              The default value is False .

              NOTE:
                 If you set AutoGenerateEndpointName to True , do not  specify
                 the EndpointName ; otherwise a 400 error is thrown.

          EndpointName -> (string)
              Specifies  the  endpoint  name  to use for a one-click Autopilot
              model deployment if the endpoint name is not generated automati-
              cally.

              NOTE:
                 Specify  the  EndpointName if and only if you set AutoGenera-
                 teEndpointName to False ; otherwise a 400 error is thrown.

       ModelDeployResult -> (structure)
          Provides information about endpoint for the model deployment.

          EndpointName -> (string)
              The name of the endpoint to which the model has been deployed.

              NOTE:
                 If model deployment fails, this field is omitted from the re-
                 sponse.



                                                        DESCRIBE-AUTO-ML-JOB()
